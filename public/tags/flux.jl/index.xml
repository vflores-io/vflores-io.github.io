<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Flux.jl on Victor Flores</title>
    <link>http://localhost:1313/tags/flux.jl/</link>
    <description>Recent content in Flux.jl on Victor Flores</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 21 May 2024 22:38:29 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/flux.jl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transfer Learning Classifier Again... with Julia!</title>
      <link>http://localhost:1313/posts/20240521_julia_transfer_learning_v5/20240521_julia_transfer_learning_v5/</link>
      <pubDate>Tue, 21 May 2024 22:38:29 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240521_julia_transfer_learning_v5/20240521_julia_transfer_learning_v5/</guid>
      <description>Replicating the cat mood classifier, this time using Julia and Flux.jl.</description>
      <content:encoded><![CDATA[<hr>
<p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/intro.png" type="" alt="image"  /></p>
<h2 id="introduction">Introduction</h2>
<p>This guide demonstrates how to apply transfer learning using a pre-trained vision model to classify cat moods based on their facila expressions. We&rsquo;ll learn how to handle custom data setups.</p>
<p>In this demonstration, we recreate the exercise done in PyTorch, <a href="https://vflores-io.github.io/posts/20240515_cat_mood_classification/">available here</a>. Since that demonstration is quite detailed, we keep it pretty straightforward here.</p>
<h4 id="motivation--credit">Motivation &amp; Credit</h4>
<p>When I thought about learning how to implement a computer vision classification model for transfer learning in Julia and <code>Flux</code>, I immediately came upon two roadblocks:</p>
<ol>
<li>Since I am not an expert in Julia, I found the documentation to be a bit difficult to access (again, this is just me!).</li>
<li>There are not many tutorials or resources to illustrate this particular case.</li>
</ol>
<p>Therefore I took it upon myself to put things together and make a demonstration that would hopefully be useful for someone who might not be an expert in Flux (or Julia).</p>
<p>This particular demo was inspired by a combination of the following resources:</p>
<ul>
<li><a href="https://towardsdatascience.com/transfer-learning-and-twin-network-for-image-classification-using-flux-jl-cbe012ced146">Transfer Learning and Twin Network for Image Classification using <code>Flux.jl</code></a></li>
<li><a href="https://github.com/FluxML/model-zoo/tree/master/tutorials/transfer_learning"><code>Flux.jl</code>&rsquo;s Model Zoo Tutorial</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"><code>PyTorch</code> Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<h2 id="getting-started">Getting Started</h2>
<p>We will use a pre-trained <code>ResNet18</code> model, initially trained on a general dataset, and fine-tune it for our specific task of classifying cat moods.</p>
<h3 id="initialization">Initialization</h3>
<p>First, we activate the current directory as our project environment by calling the package manager <code>Pkg</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Pkg</span>
</span></span><span class="line"><span class="cl"><span class="n">Pkg</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="s">&#34;.&#34;</span><span class="p">)</span> 
</span></span></code></pre></div><p>Then we will import the required packages. Of course, this is also assuming that one has already added the relevant packages into the environment.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Pkg</span>
</span></span><span class="line"><span class="cl"><span class="n">Pkg</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="s">&#34;.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Random</span><span class="o">:</span> <span class="n">shuffle!</span>
</span></span><span class="line"><span class="cl"><span class="k">import</span> <span class="n">Base</span><span class="o">:</span> <span class="n">length</span><span class="p">,</span> <span class="n">getindex</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Images</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Flux</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Flux</span><span class="o">:</span> <span class="n">update!</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">DataAugmentation</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Metalhead</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">MLUtils</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">CSV</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Plots</span>
</span></span></code></pre></div><pre><code>[32m[1m  Activating[22m[39m project at `H:\My Drive\Projects\Coding\Portfolio\Machine Learning\Julia\Transfer Learning with Flux`
</code></pre>
<h3 id="retrieve-the-data-and-initial-setup">Retrieve the Data and Initial Setup</h3>
<p>First, we specify the paths to the dataset and labels CSV files for training, validation, and test sets. Then, we load these CSV files into <code>DataFrames</code>. Finally, we create vectors of absolute file paths for each image in the dataset.</p>
<p>This setup is essential for organizing the data and ensuring that our model can access the correct images and labels during training and evaluation.</p>
<h4 id="label-structure">Label Structure</h4>
<p>The data set we are using consists of three folders: <code>train</code>, <code>val</code>, <code>test</code>. Each of them contain a set of images of cats. The labels in this case, are in the form of a CSV file that maps the filename with a one-hot encoding to label the classification of the image, i.e. the cat&rsquo;s mood - alarmed, angry, calm, pleased.</p>
<p>The dataset was obtained <a href="https://universe.roboflow.com/mubbarryz/domestic-cats-facial-expressions">here</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># specify the paths to the dataset and labels CSV</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/train&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/train/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">val_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/val&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">val_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/val/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/test&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">test_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/test/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># load the CSV file containing the labels</span>
</span></span><span class="line"><span class="cl"><span class="n">train_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">train_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">test_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">val_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">val_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># setup filepaths to the files as vectors</span>
</span></span><span class="line"><span class="cl"><span class="n">train_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">train_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">test_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">test_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">test_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">val_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">val_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span></code></pre></div><pre><code>110-element Vector{String}:
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;18cd56a2ae74d2ffc8fdc89cbb.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;6625698d9d2166cdafe47e6d17.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;99a04518d4d80adea474bbe89a.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;97c687e09bf5981b9bb729304f.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;be307e32ffc3c27ee7f49305b6.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;fabcbee5c45195a0e34918a0a1.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;d2b7179bdf5554ea40998d9d93.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;bae261f0ca148e055d0935580e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 102 bytes ⋯ [22m[39m&quot;a84e5fa1564b409f26ea9ed0c9.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;4664e5d811b55a69cac9823a87.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;7fccb36f778a5cae5eda1e6cfc.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;824395bcb65dc5b8ecd013ab0d.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;4e1297350b8f05b54f387e002a.jpg&quot;
 ⋮
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;59f6a427983efd9308ddddeea7.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;8768c7f0096dc16431b41c8367.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;aa5d35bce083f1505a7b1e727e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;5c4e68b8fba7c493f0b8bfd7bc.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;05ac086aa8b99cb8b942b1af16.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 102 bytes ⋯ [22m[39m&quot;db819e63e4b80c5caed5a07c47.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;b96481186b7376b108e9546306.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;d5aaf15e5d105aa82e24a85eff.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;5e29bd734c42a6b7b2267fb31e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;0628948e8f68a77c821746f0b3.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;4dee18ead713b297b872642c25.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;eeffac7d65a76096d457bd5949.jpg&quot;
</code></pre>
<h3 id="data-exploration">Data Exploration</h3>
<p>As usual, we take a look at the data to understand what we are working with.</p>
<p>Below we make a couple of functions to visualize the data.</p>
<p>Note that the helper function <code>label_from_row</code> will come in handy later on.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># -----------------------------------------------------------------------#</span>
</span></span><span class="line"><span class="cl"><span class="c"># helper function to extract label from the DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c"># retrieve the label for the image from the DataFrame</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_row</span> <span class="o">=</span> <span class="n">filter</span><span class="p">(</span><span class="n">row</span> <span class="o">-&gt;</span> <span class="n">row</span><span class="o">.</span><span class="n">filename</span> <span class="o">==</span> <span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_index</span> <span class="o">=</span> <span class="n">findfirst</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">label_row</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">names</span><span class="p">(</span><span class="n">labels_df</span><span class="p">)[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">label_dict</span><span class="p">[</span><span class="n">label_index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="c"># -----------------------------------------------------------------------#</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># function to display a selection of images and their labels</span>
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">show_sample_images_and_labels</span><span class="p">(</span><span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">;</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c"># randomly pick indices for sampling images</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample_indices</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">labels_df</span><span class="p">),</span> <span class="n">num_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample_filenames</span> <span class="o">=</span> <span class="n">labels_df</span><span class="o">.</span><span class="n">filename</span><span class="p">[</span><span class="n">sample_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c"># calculate number of rows and columns for the grid layuot</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_cols</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="kt">Int</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_rows</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c"># prepare a plot with a grid layout for the images</span>
</span></span><span class="line"><span class="cl">    <span class="n">p</span> <span class="o">=</span> <span class="n">plot</span><span class="p">(</span><span class="n">layout</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span> <span class="n">size</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c"># load and plot each sampled image</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">sample_filenames</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">img_path</span> <span class="o">=</span> <span class="n">joinpath</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>   <span class="c"># load the image from the file</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c"># retrieve the label for the image from the DataFrame</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">plot!</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">img</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="n">label</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">display</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>   <span class="c"># display the plot</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define a dictionary for label descriptions:</span>
</span></span><span class="line"><span class="cl"><span class="n">label_dict</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">(</span><span class="mi">1</span> <span class="o">=&gt;</span> <span class="s">&#34;alarmed&#34;</span><span class="p">,</span> <span class="mi">2</span> <span class="o">=&gt;</span> <span class="s">&#34;angry&#34;</span><span class="p">,</span> <span class="mi">3</span> <span class="o">=&gt;</span> <span class="s">&#34;calm&#34;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">=&gt;</span> <span class="s">&#34;pleased&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># run the function to show images</span>
</span></span><span class="line"><span class="cl"><span class="n">show_sample_images_and_labels</span><span class="p">(</span><span class="n">train_labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/output_6_0.svg" type="" alt="svg"  /></p>
<h3 id="working-with-custom-datasets">Working with Custom Datasets</h3>
<p>When working with custom datasets in Julia, the concepts are similar as in PyTorch, but obviously following Julia&rsquo;s syntax.</p>
<p>In essence, we read the CSV files containing image file paths and their corresponding labels into DataFrames. We then create functions to handle data loading and transformations, such as resizing and normalizing images. This approach is similar to PyTorch&rsquo;s <code>Dataset</code>.</p>
<p>Let&rsquo;s have a quick look.</p>
<h3 id="create-a-custom-dataset">Create a Custom Dataset</h3>
<p>We define a custom dataset using a <code>struct</code>, which is similar to using a <code>class</code> in Python. The <code>ImageContainer</code> struct stores the image file paths and their corresponding labels in a DataFrame. We then create instances of this <code>struct</code> for the training, validation, and test datasets.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">struct</span> <span class="kt">ImageContainer</span><span class="p">{</span><span class="kt">T</span><span class="o">&lt;:</span><span class="kt">Vector</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">img</span><span class="o">::</span><span class="kt">T</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels_df</span><span class="o">::</span><span class="kt">DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># generate dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">train_filepaths</span><span class="p">,</span> <span class="n">train_labels_df</span><span class="p">);</span>   
</span></span><span class="line"><span class="cl"><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">val_filepaths</span><span class="p">,</span> <span class="n">val_labels_df</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">test_filepaths</span><span class="p">,</span> <span class="n">test_labels_df</span><span class="p">);</span>
</span></span></code></pre></div><h4 id="create-the-data-loaders">Create the Data Loaders</h4>
<p>In this section, we set up data loaders for our custom dataset in Julia, similar to how data loaders are used in PyTorch to manage batching and shuffling of data.</p>
<ol>
<li>
<p>Call helper Function: <code>label_from_row()</code> : This function extracts the label from the DataFrame for a given image file. It finds the index of the column with a value of 1, indicating the class.</p>
</li>
<li>
<p>Length and Indexing:</p>
</li>
</ol>
<ul>
<li><code>length(data::ImageContainer)</code>: Defines the length method to return the number of images in the dataset. Similar to PyTorch&rsquo;s <code>__len__</code>.</li>
<li><code>getindex(data::ImageContainer, idx::Int)</code>: This method is similar to PyTorch’s <code>__getitem__</code>. It loads an image, applies transformations, and returns the processed image along with its label.</li>
</ul>
<ol start="3">
<li>Data Augmentation and Transformations:</li>
</ol>
<ul>
<li>pipeline: Defines a transformation pipeline for scaling and cropping images.</li>
<li>transforms(image, labels_df): Inside getindex, this function applies the transformations to the image and normalizes it using the predefined mean and standard deviation values.</li>
</ul>
<ol start="4">
<li>DataLoaders:</li>
</ol>
<ul>
<li><code>train_loader</code> and <code>val_loader</code>: These DataLoader objects manage batching, shuffling, and parallel processing of the training and validation datasets, similar to <code>torch.utils.data.DataLoader</code> in PyTorch</li>
</ul>
<h5 id="notes-on-implementing-custom-data-containers">Notes on Implementing Custom Data Containers</h5>
<p>According to the documentation for MLUtils.DataLoader (<a href="https://fluxml.ai/Flux.jl/stable/data/mlutils/">see here</a>), custom data containers should implement Base.length instead of  <code>numobs</code>, and Base.getindex instead of <code>getobs</code>, unless there&rsquo;s a difference between these functions and the base methods for multi-dimensional arrays.</p>
<p>Base.length: Should be implemented to return the number of observations. This is akin to PyTorch&rsquo;s <code>__len__</code>.
Base.getindex: Should be implemented to handle indexing of the dataset, similar to PyTorch&rsquo;s <code>__getitem__</code>.
These methods ensure that the data is returned in a form suitable for the learning algorithm, maintaining consistency whether the index is a scalar or vector.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">length</span><span class="p">(</span><span class="n">data</span><span class="o">::</span><span class="kt">ImageContainer</span><span class="p">)</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">im_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">DATA_MEAN</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485f0</span><span class="p">,</span> <span class="mf">0.456f0</span><span class="p">,</span> <span class="mf">0.406f0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">DATA_STD</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229f0</span><span class="p">,</span> <span class="mf">0.224f0</span><span class="p">,</span> <span class="mf">0.225f0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define a transformation pipeline</span>
</span></span><span class="line"><span class="cl"><span class="n">pipeline</span> <span class="o">=</span> <span class="n">DataAugmentation</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">ScaleKeepAspect</span><span class="p">(</span><span class="n">im_size</span><span class="p">),</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="n">im_size</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">getindex</span><span class="p">(</span><span class="n">data</span><span class="o">::</span><span class="kt">ImageContainer</span><span class="p">,</span> <span class="n">idx</span><span class="o">::</span><span class="kt">Int</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">img</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels_df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">labels_df</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">function</span> <span class="n">transforms</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">ScaleKeepAspect</span><span class="p">(</span><span class="n">im_size</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="n">im_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_img</span> <span class="o">=</span> <span class="n">Images</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_img</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">Image</span><span class="p">(</span><span class="n">_img</span><span class="p">))</span> <span class="o">|&gt;</span> <span class="n">itemdata</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">collect</span><span class="p">(</span><span class="n">channelview</span><span class="p">(</span><span class="n">float32</span><span class="o">.</span><span class="p">(</span><span class="n">RGB</span><span class="o">.</span><span class="p">(</span><span class="n">_img</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">permutedims</span><span class="p">((</span><span class="n">img</span> <span class="o">.-</span> <span class="n">DATA_MEAN</span><span class="p">)</span> <span class="o">./</span> <span class="n">DATA_STD</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">labels_df</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">transforms</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dataset</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_dataset</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">);</span>
</span></span></code></pre></div><h2 id="model-definition">Model Definition</h2>
<p>Here we will load the model with <code>Metalhead.jl</code> and change the classifier &ldquo;head&rdquo; of the architecture to suit our classification need.</p>
<p>We will use this to select the classifier head of the model and change it.</p>
<p>For the fine-tuning portion of this exercise will follow the <a href="https://github.com/FluxML/model-zoo/tree/master/tutorials%2Ftransfer_learning">model zoo documentation</a>:</p>
<hr>
<p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/109ebfef-0cea-49b5-98d5-fcd19f0f9596.png" type="" alt="image.png"  /></p>
<hr>
<p>Let&rsquo;s try it out with the <code>ResNet18</code> model.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># load the pre-trained model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">(</span><span class="mi">18</span><span class="p">;</span> <span class="n">pretrain</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span><span class="o">.</span><span class="n">layers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># let&#39;s look at the model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_model</span>
</span></span></code></pre></div><pre><code>Chain(
  Chain(
    Chain(
      Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  [90m# 9_408 parameters[39m
      BatchNorm(64, relu),              [90m# 128 parameters[39m[90m, plus 128[39m
      MaxPool((3, 3), pad=1, stride=2),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
          NNlib.relu,
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
          NNlib.relu,
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  [90m# 8_192 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
        Chain(
          Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  [90m# 73_728 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
          NNlib.relu,
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
          NNlib.relu,
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  [90m# 32_768 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
        Chain(
          Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  [90m# 294_912 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
          NNlib.relu,
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
          NNlib.relu,
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 256 =&gt; 512, stride=2, bias=false),  [90m# 131_072 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
        Chain(
          Conv((3, 3), 256 =&gt; 512, pad=1, stride=2, bias=false),  [90m# 1_179_648 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
          NNlib.relu,
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
          NNlib.relu,
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
      ),
    ),
  ),
  Chain(
    AdaptiveMeanPool((1, 1)),
    MLUtils.flatten,
    Dense(512 =&gt; 1000),                 [90m# 513_000 parameters[39m
  ),
) [90m        # Total: 62 trainable arrays, [39m11_689_512 parameters,
[90m          # plus 40 non-trainable, 9_600 parameters, summarysize [39m44.654 MiB.
</code></pre>
<p>Now we modify the head, by chaning the last <code>Chain</code> in the model. We change the last layer to output 4 classes (as opposed to the original 1000 classes).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># modify the model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_infer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">resnet_model</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_tune</span> <span class="o">=</span> <span class="n">Chain</span><span class="p">(</span><span class="n">AdaptiveMeanPool</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Flux</span><span class="o">.</span><span class="n">flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span> <span class="o">=&gt;</span> <span class="mi">4</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>Chain(
  AdaptiveMeanPool((1, 1)),
  Flux.flatten,
  Dense(512 =&gt; 4),                      [90m# 2_052 parameters[39m
) 
</code></pre>
<p><strong>And that&rsquo;s it!</strong> Now, let&rsquo;s just explore both portions of the model.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_infer</span>
</span></span></code></pre></div><pre><code>Chain(
  Chain(
    Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  [90m# 9_408 parameters[39m
    BatchNorm(64, relu),                [90m# 128 parameters[39m[90m, plus 128[39m
    MaxPool((3, 3), pad=1, stride=2),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
        NNlib.relu,
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
        NNlib.relu,
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  [90m# 8_192 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
      Chain(
        Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  [90m# 73_728 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
        NNlib.relu,
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
        NNlib.relu,
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  [90m# 32_768 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
      Chain(
        Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  [90m# 294_912 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
        NNlib.relu,
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
        NNlib.relu,
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 256 =&gt; 512, stride=2, bias=false),  [90m# 131_072 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
      Chain(
        Conv((3, 3), 256 =&gt; 512, pad=1, stride=2, bias=false),  [90m# 1_179_648 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        NNlib.relu,
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        NNlib.relu,
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
    ),
  ),
) [90m        # Total: 60 trainable arrays, [39m11_176_512 parameters,
[90m          # plus 40 non-trainable, 9_600 parameters, summarysize [39m42.693 MiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_tune</span>
</span></span></code></pre></div><pre><code>Chain(
  AdaptiveMeanPool((1, 1)),
  Flux.flatten,
  Dense(512 =&gt; 4),                      [90m# 2_052 parameters[39m
) 
</code></pre>
<h3 id="define-evaluation-and-training-functions">Define evaluation and training functions</h3>
<p>Again, will follow the model zoo documentation. Small adaptations will be needed. (These two functions were taken directly from the documentation).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">m_infer</span><span class="p">,</span> <span class="n">m_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">good</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">in</span> <span class="n">val_loader</span>
</span></span><span class="line"><span class="cl">        <span class="n">good</span> <span class="o">+=</span> <span class="n">sum</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">onecold</span><span class="p">(</span><span class="n">m_tune</span><span class="p">(</span><span class="n">m_infer</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="o">.==</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">count</span> <span class="o">+=</span> <span class="n">length</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="n">round</span><span class="p">(</span><span class="n">good</span> <span class="o">/</span> <span class="n">count</span><span class="p">,</span> <span class="n">digits</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>eval_f (generic function with 1 method)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">model_infer</span><span class="p">,</span> <span class="n">model_tune</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">in</span> <span class="n">loader</span>
</span></span><span class="line"><span class="cl">        <span class="n">infer</span> <span class="o">=</span> <span class="n">model_infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">grads</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">model_tune</span><span class="p">)</span> <span class="k">do</span> <span class="n">m</span>
</span></span><span class="line"><span class="cl">            <span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">logitcrossentropy</span><span class="p">(</span><span class="n">m</span><span class="p">(</span><span class="n">infer</span><span class="p">),</span> <span class="n">Flux</span><span class="o">.</span><span class="n">onehotbatch</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">end</span>
</span></span><span class="line"><span class="cl">        <span class="n">update!</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">model_tune</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>train_epoch! (generic function with 1 method)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_opt</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Optimisers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span> <span class="n">resnet_tune</span><span class="p">);</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@time</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">resnet_opt</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_train</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_eval</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;train&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_train</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;eval&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_eval</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>176.283332 seconds (37.11 M allocations: 98.153 GiB, 6.06% gc time, 143.87% compilation time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.5744
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.5455


 70.815518 seconds (2.42 M allocations: 95.936 GiB, 11.25% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.6823
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


 90.463025 seconds (2.42 M allocations: 95.936 GiB, 11.21% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7032
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6455


 94.362892 seconds (2.42 M allocations: 95.936 GiB, 10.91% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7433
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6727


116.526515 seconds (2.42 M allocations: 95.936 GiB, 9.62% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7885
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6909
</code></pre>
<hr>
<h2 id="vision-transformers">Vision Transformers</h2>
<hr>
<p>Similar to the PyTorch demonstration, we can do transfer learning by changing a different computer vision model (Vision Transformer).</p>
<p>Let&rsquo;s get into it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">vit_model</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">(</span><span class="ss">:base</span><span class="p">;</span> <span class="n">pretrain</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span><span class="o">.</span><span class="n">layers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># let&#39;s have a look at the model head, to see how many inputs the head needs</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_model</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</span></span></code></pre></div><pre><code>Chain(
  LayerNorm(768),                       [90m# 1_536 parameters[39m
  Dense(768 =&gt; 1000),                   [90m# 769_000 parameters[39m
) [90m                  # Total: 4 arrays, [39m770_536 parameters, 2.940 MiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># modify the head</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_infer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vit_model</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># notice how we keep the input to the model head</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_tune</span> <span class="o">=</span> <span class="n">Chain</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">LayerNorm</span><span class="p">(</span><span class="mi">768</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Dense</span><span class="p">(</span><span class="mi">768</span> <span class="o">=&gt;</span> <span class="mi">4</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><pre><code>Chain(
  LayerNorm(768),                       [90m# 1_536 parameters[39m
  Dense(768 =&gt; 4),                      [90m# 3_076 parameters[39m
) [90m                  # Total: 4 arrays, [39m4_612 parameters, 18.352 KiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">vit_opt</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Optimisers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span> <span class="n">vit_tune</span><span class="p">);</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@time</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">vit_opt</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_train</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_eval</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;train&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_train</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;eval&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_eval</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>627.303072 seconds (17.32 M allocations: 291.924 GiB, 4.61% gc time, 3.66% compilation time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7058
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


565.986959 seconds (2.54 M allocations: 291.028 GiB, 4.71% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.8042
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


516.041945 seconds (2.54 M allocations: 291.028 GiB, 4.92% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.866
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6818


515.415614 seconds (2.54 M allocations: 291.028 GiB, 4.80% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.8973
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6818


427.423410 seconds (2.54 M allocations: 291.028 GiB, 5.01% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.9199
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6727
</code></pre>
<h3 id="save-the-models">Save the Models</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">JLD2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">resnet_model_state</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">resnet_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_model_state</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">vit_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">jldsave</span><span class="p">(</span><span class="s">&#34;resnet_model.jld2&#34;</span><span class="p">;</span> <span class="n">resnet_model_state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">jldsave</span><span class="p">(</span><span class="s">&#34;vit_model.jld2&#34;</span><span class="p">;</span> <span class="n">vit_model_state</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[33m[1m┌ [22m[39m[33m[1mWarning: [22m[39mOpening file with JLD2.MmapIO failed, falling back to IOStream
[33m[1m└ [22m[39m[90m@ JLD2 C:\Users\ingvi\.julia\packages\JLD2\7uAqU\src\JLD2.jl:300[39m
[33m[1m┌ [22m[39m[33m[1mWarning: [22m[39mOpening file with JLD2.MmapIO failed, falling back to IOStream
[33m[1m└ [22m[39m[90m@ JLD2 C:\Users\ingvi\.julia\packages\JLD2\7uAqU\src\JLD2.jl:300[39m
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">BSON</span><span class="o">:</span> <span class="nd">@save</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@save</span> <span class="s">&#34;resnet_model_sate.bson&#34;</span> <span class="n">resnet_model</span>
</span></span><span class="line"><span class="cl"><span class="nd">@save</span> <span class="s">&#34;vit_model_state.bson&#34;</span> <span class="n">vit_model</span>
</span></span></code></pre></div><h2 id="thank-you">Thank you!</h2>
<p>I hope this demonstration on using Julia and <code>Flux</code> for transfer learning was helpful!</p>
<p>Victor</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
