<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Time Series on Victor Flores, PhD</title>
    <link>http://localhost:1313/tags/time-series/</link>
    <description>Recent content in Time Series on Victor Flores, PhD</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 02 Mar 2024 16:57:07 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/time-series/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bayesian Time Series Analysis with Julia and Turing.jl</title>
      <link>http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/</link>
      <pubDate>Sat, 02 Mar 2024 16:57:07 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/</guid>
      <description>This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning.</description>
      <content:encoded><![CDATA[<hr>
<h2 id="introduction">Introduction</h2>
<p>In this tutorial, an AR(p) (Autoregressive model of order <em>p</em>) is employed to analyze the trneds of a time series and forecast the behavior of the signal.</p>
<p>Auto-regressive models are based on the assumption the behavior of a time series or signal depends on past values. The order of the AR model tells &ldquo;how far back&rdquo; the past values will affect the current value.</p>
<h4 id="credits">Credits</h4>
<p>This exercise is mostly following <a href="https://youtu.be/vfTYCm_Fr8I?si=D3Grgk82tV_Qzdxw">this tutorial</a>.</p>
<h3 id="definition">Definition</h3>
<p>The <em>AR(p)</em> model is defined as:</p>
<p>$$
X_t = \sum_{i=1}^{p} \phi_i X_{t-i} + \varepsilon_t
$$</p>
<p>where $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ is the model uncertainty represented as white Gaussian noise, i.e. it follows a normal distribution of mean $\mu=0$ and standard deviation $\sigma$.</p>
<p>It follows that an <em>AR(2)</em> model is defined as:</p>
<p>$$
X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \varepsilon_t
$$</p>
<p>Naturally, we want to find the parameters $\theta={\phi_1, \phi_2,\sigma}$. Since these are unobserved quantities of interest, we need to use an inference method to reveal these parameters. We will use Bayesian inference to achieve this goal.</p>
<h2 id="data-exploration">Data Exploration</h2>
<p>For this example, I will generate artificial data. This will be done by first defining some values for the parameters $\theta$ and then we will generate random data using those parameters by initializing the $X_1, X_2$ values, and then applying the AR(2) equation to generate the subsequent values.</p>
<p>First, we import the relevant packages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">StatsPlots</span><span class="p">,</span> <span class="n">Turing</span><span class="p">,</span> <span class="n">LaTeXStrings</span><span class="p">,</span> <span class="n">Random</span><span class="p">,</span> <span class="n">DataFrames</span>
</span></span><span class="line"><span class="cl"><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>TaskLocalRNG()
</code></pre>
<p>Now we create some artificial data. The steps involved in this are as follows:</p>
<ol>
<li>Define some values for the parameters $\theta$</li>
<li>Set the number of timesteps <em>t</em></li>
<li>Initialize an empty vector of size $\mathbb{R}^{t+p}$</li>
<li>Initialize the first two $X$ values with randomly generated numbers using <code>rand</code></li>
<li>Populate the vector by using the equation for $X_t$</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># define true values for Î¸</span>
</span></span><span class="line"><span class="cl"><span class="n">true_phi_1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.4</span>
</span></span><span class="line"><span class="cl"><span class="n">true_phi_2</span> <span class="o">=</span> <span class="mf">0.3</span>
</span></span><span class="line"><span class="cl"><span class="n">true_sigma</span> <span class="o">=</span> <span class="mf">0.12</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define the time steps</span>
</span></span><span class="line"><span class="cl"><span class="n">time</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="c"># create an empty X vector</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># initialize the X vector with two random values at time steps 1 and 2</span>
</span></span><span class="line"><span class="cl"><span class="c"># to do this, use a random normally distributed number with mean zero and standard deviation Ïƒ, i.e., Îµ~N(0, Ïƒ)</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># populate vector X</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">t</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_phi_1</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">	<span class="n">true_phi_2</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">	<span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>	
</span></span></code></pre></div><h3 id="visualize-the-artificial-data">Visualize the (Artificial) Data</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">p_data</span> <span class="o">=</span> <span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="o">:</span><span class="k">end</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c"># xlims = (0, 60),</span>
</span></span><span class="line"><span class="cl">    <span class="c"># ylims = (-0.6, 0.6),</span>
</span></span><span class="line"><span class="cl">    <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Bayesian Autoregressive AR(2) Model&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">xlabel</span> <span class="o">=</span> <span class="sa">L</span><span class="s">&#34;t&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ylabel</span> <span class="o">=</span> <span class="sa">L</span><span class="s">&#34;X_t&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">widen</span> <span class="o">=</span> <span class="nb">true</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_5_0.svg" type="" alt="svg"  /></p>
<h2 id="modeling">Modeling</h2>
<p>The next step is to construct our probabilistic model. Again, the goal here is to infer the values of the model parameters $\theta$. Once we have inferred these parameters, we can make probabilistic predictions on the future behavior of the signal $X$.</p>
<h3 id="bayesian-model">Bayesian model</h3>
<p>Since we are using a Bayesian approach, our goal, in Bayesian terms, is to find the <em>posterior distribution</em> of the parameters $\theta$, given a prior distribution, or prior knowledge, of the parameters before making any observations, i.e., seeing any data, and also a likelihood function, which reflects what kind of distribution (we assume) that the data is sourced from. Another way of understanding the likelihood function is the probability of making a set of observations $X$ given the parameters $\theta$.</p>
<p>This relationship is established by Bayes&rsquo; Theorem:</p>
<p>$$
P(\theta | X) \propto P(X | \theta)P(\theta)
$$</p>
<p>In summary, constructing the Bayesian model in this case comprises a selection of prior distributions for our unknown parameters $\theta$ and a likelihood function. We will do this using the <code>Turing.jl</code> package.</p>
<p>The model therefore will consist of the prior distributions:</p>
<p>$$
\begin{align*}
\phi_1 &amp; \sim \mathcal{N}(0, 1) \
\phi_2 &amp; \sim \mathcal{N}(0, 1) \
\sigma &amp; \sim \text{Exp}(1)
\end{align*}
$$</p>
<p>And the likelihood:</p>
<p>$$
X_t \sim \mathcal{N}(\mu_t, \sigma)
$$</p>
<p>where $\mu_t = \sum_{i=1}^{p} \phi_i X_{t-i}$ is the mean function of the distribution that governs X_t.</p>
<h4 id="a-comment-on-the-choice-of-priors">A comment on the choice of priors</h4>
<p>For autoregressive parameters, using a normal distribution is a common choice. This is because the normal distribution is convenient and allows for a range of plausible values.</p>
<p>For the prior on the model uncertainty, the exponential distribution is sometimes used for non-negative parameters and has a similar role to the inverse gamma.</p>
<p>Furthermore, the inverse gamma distribution is often chosen as a prior for the standard deviation because it is conjugate to the normal likelihood. This means that the posterior distribution will have a known form, making computations more tractable.</p>
<h3 id="bayesian-model-using-turingjl">Bayesian model using <code>Turing.jl</code></h3>
<p>Now we proceed to set up the model using the <code>Turing.jl</code> package.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">ar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>    <span class="c"># pass the data X and the time vector</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># priors</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">		<span class="n">phi_1</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">phi_2</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">sigma</span> <span class="o">~</span> <span class="n">Exponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># likelihood</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># initialize with random initial values</span>
</span></span><span class="line"><span class="cl">		<span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># populate with samples</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">			<span class="n">mu</span> <span class="o">=</span> <span class="n">phi_1</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">phi_2</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">end</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span></code></pre></div><pre><code>ar (generic function with 2 methods)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">ar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="mi">1_000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[36m[1mâ”Œ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1mâ”” [22m[39m  Ïµ = 0.4
[32mSampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[39m





Chains MCMC chain (1000Ã—15Ã—1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 11.59 seconds
Compute duration  = 11.59 seconds
parameters        = phi_1, phi_2, sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m â‹¯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m â‹¯

       phi_1   -0.3830    0.1047    0.0036   836.6151   762.4445    0.9996     â‹¯
       phi_2    0.1587    0.1012    0.0035   838.3014   749.6718    1.0002     â‹¯
       sigma    0.1083    0.0079    0.0003   755.4034   743.3822    1.0014     â‹¯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

       phi_1   -0.5733   -0.4562   -0.3858   -0.3141   -0.1771
       phi_2   -0.0339    0.0913    0.1562    0.2256    0.3549
       sigma    0.0943    0.1030    0.1079    0.1130    0.1257
</code></pre>
<h3 id="visualize-and-summarize-the-results">Visualize and Summarize the Results</h3>
<p>Next we can access the MCMC Diagnostics and generate a summary of the results.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_10_0.svg" type="" alt="svg"  /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">DataFrame</span><span class="p">(</span><span class="n">summarystats</span><span class="p">(</span><span class="n">chain</span><span class="p">))</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>3Ã—8 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameters</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">std</th><th style = "text-align: left;">mcse</th><th style = "text-align: left;">ess_bulk</th><th style = "text-align: left;">ess_tail</th><th style = "text-align: left;">rhat</th><th style = "text-align: left;">ess_per_sec</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">phi_1</td><td style = "text-align: right;">-0.383019</td><td style = "text-align: right;">0.104695</td><td style = "text-align: right;">0.00361324</td><td style = "text-align: right;">836.615</td><td style = "text-align: right;">762.444</td><td style = "text-align: right;">0.999585</td><td style = "text-align: right;">72.1655</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">phi_2</td><td style = "text-align: right;">0.158661</td><td style = "text-align: right;">0.101196</td><td style = "text-align: right;">0.00351463</td><td style = "text-align: right;">838.301</td><td style = "text-align: right;">749.672</td><td style = "text-align: right;">1.00021</td><td style = "text-align: right;">72.311</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">sigma</td><td style = "text-align: right;">0.108342</td><td style = "text-align: right;">0.00788622</td><td style = "text-align: right;">0.000291067</td><td style = "text-align: right;">755.403</td><td style = "text-align: right;">743.382</td><td style = "text-align: right;">1.00145</td><td style = "text-align: right;">65.1603</td></tr></tbody></table></div>
<h2 id="predictions">Predictions</h2>
<h3 id="making-predictions">Making Predictions</h3>
<p>To make predictions, the following steps are taken:</p>
<ol>
<li>Set the number of time steps into the future, $t_f$</li>
<li>Initialize an empty matrix for the forecasted $X$ values - This will be a matrix because it will be a collection of vectors. Each vector will represent one sample forecast</li>
<li>Initialize two steps of each of the sample vectors to be generated - In practical terms, initialize the first number of each column; each <em>column</em> will represent a forecast time series</li>
</ol>
<p>Keep in mind that what will be done here is to create samples of the future behavior of the signal $t_f$ number of time steps into the future. To do this, we will generate signals that use the posterior distributions of the parameters $\theta$ by calling the function <code>rand(chain[:,Z,Z])</code> which will randomly pick a number out of the sample pool, effectively &ldquo;sampling&rdquo; from that posterior distribution (sample pool).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">time_future</span> <span class="o">=</span> <span class="mi">15</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_future</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># Initialize the first two time steps for every forecast</span>
</span></span><span class="line"><span class="cl"><span class="n">X_future</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span> <span class="o">.=</span> <span class="n">X</span><span class="p">[</span><span class="n">time</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">X_future</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span> <span class="o">.=</span> <span class="n">X</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># populate the forecast vectors by sampling from the posterior sample pool of the parameters Î¸</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">col</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">	<span class="n">phi_1_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">phi_2_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">error_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">noise_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">error_future</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">row</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> 
</span></span><span class="line"><span class="cl">			<span class="n">phi_1_future</span> <span class="o">*</span> <span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">+</span> 
</span></span><span class="line"><span class="cl">			<span class="n">phi_2_future</span> <span class="o">*</span> <span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">			<span class="n">noise_future</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><h4 id="visualize-the-forecast">Visualize the forecast</h4>
<p>Now that we <em>propagated the uncertainty</em> of in the posterior distribution of the parameters $\theta$, we can plot the posterior predictive distribution of $X$, $P(X^*|\theta)$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">time_predict</span> <span class="o">=</span> <span class="n">time</span><span class="o">:</span><span class="p">(</span><span class="n">time</span> <span class="o">+</span> <span class="n">time_future</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">	<span class="n">plot!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="n">time_predict</span><span class="p">,</span> <span class="n">X_future</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="c"># predictions</span>
</span></span><span class="line"><span class="cl">	<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="ss">:green</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></span><span class="line"><span class="cl">	<span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># visualize mean values for predictions</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_future_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">mean</span><span class="p">(</span><span class="n">X_future</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="p">(</span><span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="n">time_predict</span><span class="p">,</span> <span class="n">X_future_mean</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">color</span> <span class="o">=</span> <span class="ss">:red</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">linestyle</span> <span class="o">=</span> <span class="ss">:dot</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_15_0.svg" type="" alt="svg"  /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"></code></pre></div>]]></content:encoded>
    </item>
    
  </channel>
</rss>
