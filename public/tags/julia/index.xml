<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Julia on Victor Flores</title>
    <link>http://localhost:1313/tags/julia/</link>
    <description>Recent content in Julia on Victor Flores</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 21 May 2024 22:38:29 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/julia/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transfer Learning Classifier Again... with Julia!</title>
      <link>http://localhost:1313/posts/20240521_julia_transfer_learning_v5/20240521_julia_transfer_learning_v5/</link>
      <pubDate>Tue, 21 May 2024 22:38:29 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240521_julia_transfer_learning_v5/20240521_julia_transfer_learning_v5/</guid>
      <description>Replicating the cat mood classifier, this time using Julia and Flux.jl.</description>
      <content:encoded><![CDATA[<hr>
<p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/intro.png" type="" alt="image"  /></p>
<h2 id="introduction">Introduction</h2>
<p>This guide demonstrates how to apply transfer learning using a pre-trained vision model to classify cat moods based on their facila expressions. We&rsquo;ll learn how to handle custom data setups.</p>
<p>In this demonstration, we recreate the exercise done in PyTorch, <a href="https://vflores-io.github.io/posts/20240515_cat_mood_classification/">available here</a>. Since that demonstration is quite detailed, we keep it pretty straightforward here.</p>
<h4 id="motivation--credit">Motivation &amp; Credit</h4>
<p>When I thought about learning how to implement a computer vision classification model for transfer learning in Julia and <code>Flux</code>, I immediately came upon two roadblocks:</p>
<ol>
<li>Since I am not an expert in Julia, I found the documentation to be a bit difficult to access (again, this is just me!).</li>
<li>There are not many tutorials or resources to illustrate this particular case.</li>
</ol>
<p>Therefore I took it upon myself to put things together and make a demonstration that would hopefully be useful for someone who might not be an expert in Flux (or Julia).</p>
<p>This particular demo was inspired by a combination of the following resources:</p>
<ul>
<li><a href="https://towardsdatascience.com/transfer-learning-and-twin-network-for-image-classification-using-flux-jl-cbe012ced146">Transfer Learning and Twin Network for Image Classification using <code>Flux.jl</code></a></li>
<li><a href="https://github.com/FluxML/model-zoo/tree/master/tutorials/transfer_learning"><code>Flux.jl</code>&rsquo;s Model Zoo Tutorial</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"><code>PyTorch</code> Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<h2 id="getting-started">Getting Started</h2>
<p>We will use a pre-trained <code>ResNet18</code> model, initially trained on a general dataset, and fine-tune it for our specific task of classifying cat moods.</p>
<h3 id="initialization">Initialization</h3>
<p>First, we activate the current directory as our project environment by calling the package manager <code>Pkg</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Pkg</span>
</span></span><span class="line"><span class="cl"><span class="n">Pkg</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="s">&#34;.&#34;</span><span class="p">)</span> 
</span></span></code></pre></div><p>Then we will import the required packages. Of course, this is also assuming that one has already added the relevant packages into the environment.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Pkg</span>
</span></span><span class="line"><span class="cl"><span class="n">Pkg</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="s">&#34;.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Random</span><span class="o">:</span> <span class="n">shuffle!</span>
</span></span><span class="line"><span class="cl"><span class="k">import</span> <span class="n">Base</span><span class="o">:</span> <span class="n">length</span><span class="p">,</span> <span class="n">getindex</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Images</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Flux</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Flux</span><span class="o">:</span> <span class="n">update!</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">DataAugmentation</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Metalhead</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">MLUtils</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">CSV</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Plots</span>
</span></span></code></pre></div><pre><code>[32m[1m  Activating[22m[39m project at `H:\My Drive\Projects\Coding\Portfolio\Machine Learning\Julia\Transfer Learning with Flux`
</code></pre>
<h3 id="retrieve-the-data-and-initial-setup">Retrieve the Data and Initial Setup</h3>
<p>First, we specify the paths to the dataset and labels CSV files for training, validation, and test sets. Then, we load these CSV files into <code>DataFrames</code>. Finally, we create vectors of absolute file paths for each image in the dataset.</p>
<p>This setup is essential for organizing the data and ensuring that our model can access the correct images and labels during training and evaluation.</p>
<h4 id="label-structure">Label Structure</h4>
<p>The data set we are using consists of three folders: <code>train</code>, <code>val</code>, <code>test</code>. Each of them contain a set of images of cats. The labels in this case, are in the form of a CSV file that maps the filename with a one-hot encoding to label the classification of the image, i.e. the cat&rsquo;s mood - alarmed, angry, calm, pleased.</p>
<p>The dataset was obtained <a href="https://universe.roboflow.com/mubbarryz/domestic-cats-facial-expressions">here</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># specify the paths to the dataset and labels CSV</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/train&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/train/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">val_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/val&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">val_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/val/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_data_path</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/test&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">test_data_csv</span> <span class="o">=</span> <span class="s">&#34;data/cat_expression_data/test/_classes.csv&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># load the CSV file containing the labels</span>
</span></span><span class="line"><span class="cl"><span class="n">train_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">train_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">test_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">val_labels_df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">val_data_csv</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># setup filepaths to the files as vectors</span>
</span></span><span class="line"><span class="cl"><span class="n">train_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">train_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">test_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">test_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">test_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="n">abspath</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="n">val_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span> <span class="k">in</span> <span class="n">val_labels_df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
</span></span></code></pre></div><pre><code>110-element Vector{String}:
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;18cd56a2ae74d2ffc8fdc89cbb.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;6625698d9d2166cdafe47e6d17.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;99a04518d4d80adea474bbe89a.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;97c687e09bf5981b9bb729304f.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;be307e32ffc3c27ee7f49305b6.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;fabcbee5c45195a0e34918a0a1.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;d2b7179bdf5554ea40998d9d93.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;bae261f0ca148e055d0935580e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 102 bytes ⋯ [22m[39m&quot;a84e5fa1564b409f26ea9ed0c9.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;4664e5d811b55a69cac9823a87.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;7fccb36f778a5cae5eda1e6cfc.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;824395bcb65dc5b8ecd013ab0d.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 106 bytes ⋯ [22m[39m&quot;4e1297350b8f05b54f387e002a.jpg&quot;
 ⋮
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;59f6a427983efd9308ddddeea7.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;8768c7f0096dc16431b41c8367.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;aa5d35bce083f1505a7b1e727e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;5c4e68b8fba7c493f0b8bfd7bc.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;05ac086aa8b99cb8b942b1af16.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 102 bytes ⋯ [22m[39m&quot;db819e63e4b80c5caed5a07c47.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;b96481186b7376b108e9546306.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 105 bytes ⋯ [22m[39m&quot;d5aaf15e5d105aa82e24a85eff.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;5e29bd734c42a6b7b2267fb31e.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;0628948e8f68a77c821746f0b3.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 103 bytes ⋯ [22m[39m&quot;4dee18ead713b297b872642c25.jpg&quot;
 &quot;H:\\My Drive\\Projects\\Coding\\Por&quot;[93m[1m ⋯ 104 bytes ⋯ [22m[39m&quot;eeffac7d65a76096d457bd5949.jpg&quot;
</code></pre>
<h3 id="data-exploration">Data Exploration</h3>
<p>As usual, we take a look at the data to understand what we are working with.</p>
<p>Below we make a couple of functions to visualize the data.</p>
<p>Note that the helper function <code>label_from_row</code> will come in handy later on.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># -----------------------------------------------------------------------#</span>
</span></span><span class="line"><span class="cl"><span class="c"># helper function to extract label from the DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c"># retrieve the label for the image from the DataFrame</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_row</span> <span class="o">=</span> <span class="n">filter</span><span class="p">(</span><span class="n">row</span> <span class="o">-&gt;</span> <span class="n">row</span><span class="o">.</span><span class="n">filename</span> <span class="o">==</span> <span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_index</span> <span class="o">=</span> <span class="n">findfirst</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">label_row</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">names</span><span class="p">(</span><span class="n">labels_df</span><span class="p">)[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">label_dict</span><span class="p">[</span><span class="n">label_index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="c"># -----------------------------------------------------------------------#</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># function to display a selection of images and their labels</span>
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">show_sample_images_and_labels</span><span class="p">(</span><span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">;</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c"># randomly pick indices for sampling images</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample_indices</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">labels_df</span><span class="p">),</span> <span class="n">num_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample_filenames</span> <span class="o">=</span> <span class="n">labels_df</span><span class="o">.</span><span class="n">filename</span><span class="p">[</span><span class="n">sample_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c"># calculate number of rows and columns for the grid layuot</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_cols</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="kt">Int</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_rows</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c"># prepare a plot with a grid layout for the images</span>
</span></span><span class="line"><span class="cl">    <span class="n">p</span> <span class="o">=</span> <span class="n">plot</span><span class="p">(</span><span class="n">layout</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span> <span class="n">size</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c"># load and plot each sampled image</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">sample_filenames</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">img_path</span> <span class="o">=</span> <span class="n">joinpath</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>   <span class="c"># load the image from the file</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c"># retrieve the label for the image from the DataFrame</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">plot!</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">img</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="n">label</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">display</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>   <span class="c"># display the plot</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define a dictionary for label descriptions:</span>
</span></span><span class="line"><span class="cl"><span class="n">label_dict</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">(</span><span class="mi">1</span> <span class="o">=&gt;</span> <span class="s">&#34;alarmed&#34;</span><span class="p">,</span> <span class="mi">2</span> <span class="o">=&gt;</span> <span class="s">&#34;angry&#34;</span><span class="p">,</span> <span class="mi">3</span> <span class="o">=&gt;</span> <span class="s">&#34;calm&#34;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">=&gt;</span> <span class="s">&#34;pleased&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># run the function to show images</span>
</span></span><span class="line"><span class="cl"><span class="n">show_sample_images_and_labels</span><span class="p">(</span><span class="n">train_labels_df</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/output_6_0.svg" type="" alt="svg"  /></p>
<h3 id="working-with-custom-datasets">Working with Custom Datasets</h3>
<p>When working with custom datasets in Julia, the concepts are similar as in PyTorch, but obviously following Julia&rsquo;s syntax.</p>
<p>In essence, we read the CSV files containing image file paths and their corresponding labels into DataFrames. We then create functions to handle data loading and transformations, such as resizing and normalizing images. This approach is similar to PyTorch&rsquo;s <code>Dataset</code>.</p>
<p>Let&rsquo;s have a quick look.</p>
<h3 id="create-a-custom-dataset">Create a Custom Dataset</h3>
<p>We define a custom dataset using a <code>struct</code>, which is similar to using a <code>class</code> in Python. The <code>ImageContainer</code> struct stores the image file paths and their corresponding labels in a DataFrame. We then create instances of this <code>struct</code> for the training, validation, and test datasets.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">struct</span> <span class="kt">ImageContainer</span><span class="p">{</span><span class="kt">T</span><span class="o">&lt;:</span><span class="kt">Vector</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">img</span><span class="o">::</span><span class="kt">T</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels_df</span><span class="o">::</span><span class="kt">DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># generate dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">train_filepaths</span><span class="p">,</span> <span class="n">train_labels_df</span><span class="p">);</span>   
</span></span><span class="line"><span class="cl"><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">val_filepaths</span><span class="p">,</span> <span class="n">val_labels_df</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ImageContainer</span><span class="p">(</span><span class="n">test_filepaths</span><span class="p">,</span> <span class="n">test_labels_df</span><span class="p">);</span>
</span></span></code></pre></div><h4 id="create-the-data-loaders">Create the Data Loaders</h4>
<p>In this section, we set up data loaders for our custom dataset in Julia, similar to how data loaders are used in PyTorch to manage batching and shuffling of data.</p>
<ol>
<li>
<p>Call helper Function: <code>label_from_row()</code> : This function extracts the label from the DataFrame for a given image file. It finds the index of the column with a value of 1, indicating the class.</p>
</li>
<li>
<p>Length and Indexing:</p>
</li>
</ol>
<ul>
<li><code>length(data::ImageContainer)</code>: Defines the length method to return the number of images in the dataset. Similar to PyTorch&rsquo;s <code>__len__</code>.</li>
<li><code>getindex(data::ImageContainer, idx::Int)</code>: This method is similar to PyTorch’s <code>__getitem__</code>. It loads an image, applies transformations, and returns the processed image along with its label.</li>
</ul>
<ol start="3">
<li>Data Augmentation and Transformations:</li>
</ol>
<ul>
<li>pipeline: Defines a transformation pipeline for scaling and cropping images.</li>
<li>transforms(image, labels_df): Inside getindex, this function applies the transformations to the image and normalizes it using the predefined mean and standard deviation values.</li>
</ul>
<ol start="4">
<li>DataLoaders:</li>
</ol>
<ul>
<li><code>train_loader</code> and <code>val_loader</code>: These DataLoader objects manage batching, shuffling, and parallel processing of the training and validation datasets, similar to <code>torch.utils.data.DataLoader</code> in PyTorch</li>
</ul>
<h5 id="notes-on-implementing-custom-data-containers">Notes on Implementing Custom Data Containers</h5>
<p>According to the documentation for MLUtils.DataLoader (<a href="https://fluxml.ai/Flux.jl/stable/data/mlutils/">see here</a>), custom data containers should implement Base.length instead of  <code>numobs</code>, and Base.getindex instead of <code>getobs</code>, unless there&rsquo;s a difference between these functions and the base methods for multi-dimensional arrays.</p>
<p>Base.length: Should be implemented to return the number of observations. This is akin to PyTorch&rsquo;s <code>__len__</code>.
Base.getindex: Should be implemented to handle indexing of the dataset, similar to PyTorch&rsquo;s <code>__getitem__</code>.
These methods ensure that the data is returned in a form suitable for the learning algorithm, maintaining consistency whether the index is a scalar or vector.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">length</span><span class="p">(</span><span class="n">data</span><span class="o">::</span><span class="kt">ImageContainer</span><span class="p">)</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">im_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">DATA_MEAN</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485f0</span><span class="p">,</span> <span class="mf">0.456f0</span><span class="p">,</span> <span class="mf">0.406f0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">DATA_STD</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229f0</span><span class="p">,</span> <span class="mf">0.224f0</span><span class="p">,</span> <span class="mf">0.225f0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define a transformation pipeline</span>
</span></span><span class="line"><span class="cl"><span class="n">pipeline</span> <span class="o">=</span> <span class="n">DataAugmentation</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">ScaleKeepAspect</span><span class="p">(</span><span class="n">im_size</span><span class="p">),</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="n">im_size</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">function</span> <span class="n">getindex</span><span class="p">(</span><span class="n">data</span><span class="o">::</span><span class="kt">ImageContainer</span><span class="p">,</span> <span class="n">idx</span><span class="o">::</span><span class="kt">Int</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">img</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels_df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">labels_df</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">function</span> <span class="n">transforms</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">ScaleKeepAspect</span><span class="p">(</span><span class="n">im_size</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="n">im_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_img</span> <span class="o">=</span> <span class="n">Images</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_img</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">Image</span><span class="p">(</span><span class="n">_img</span><span class="p">))</span> <span class="o">|&gt;</span> <span class="n">itemdata</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">collect</span><span class="p">(</span><span class="n">channelview</span><span class="p">(</span><span class="n">float32</span><span class="o">.</span><span class="p">(</span><span class="n">RGB</span><span class="o">.</span><span class="p">(</span><span class="n">_img</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">        <span class="n">img</span> <span class="o">=</span> <span class="n">permutedims</span><span class="p">((</span><span class="n">img</span> <span class="o">.-</span> <span class="n">DATA_MEAN</span><span class="p">)</span> <span class="o">./</span> <span class="n">DATA_STD</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">label_from_row</span><span class="p">(</span><span class="n">labels_df</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">transforms</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">labels_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dataset</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_dataset</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">);</span>
</span></span></code></pre></div><h2 id="model-definition">Model Definition</h2>
<p>Here we will load the model with <code>Metalhead.jl</code> and change the classifier &ldquo;head&rdquo; of the architecture to suit our classification need.</p>
<p>We will use this to select the classifier head of the model and change it.</p>
<p>For the fine-tuning portion of this exercise will follow the <a href="https://github.com/FluxML/model-zoo/tree/master/tutorials%2Ftransfer_learning">model zoo documentation</a>:</p>
<hr>
<p><img loading="lazy" src="/images/20240521_julia_transfer_learning_v5/109ebfef-0cea-49b5-98d5-fcd19f0f9596.png" type="" alt="image.png"  /></p>
<hr>
<p>Let&rsquo;s try it out with the <code>ResNet18</code> model.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># load the pre-trained model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">(</span><span class="mi">18</span><span class="p">;</span> <span class="n">pretrain</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span><span class="o">.</span><span class="n">layers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># let&#39;s look at the model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_model</span>
</span></span></code></pre></div><pre><code>Chain(
  Chain(
    Chain(
      Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  [90m# 9_408 parameters[39m
      BatchNorm(64, relu),              [90m# 128 parameters[39m[90m, plus 128[39m
      MaxPool((3, 3), pad=1, stride=2),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
          NNlib.relu,
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
          NNlib.relu,
          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
          BatchNorm(64),                [90m# 128 parameters[39m[90m, plus 128[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  [90m# 8_192 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
        Chain(
          Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  [90m# 73_728 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
          NNlib.relu,
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
          NNlib.relu,
          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
          BatchNorm(128),               [90m# 256 parameters[39m[90m, plus 256[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  [90m# 32_768 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
        Chain(
          Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  [90m# 294_912 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
          NNlib.relu,
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
          NNlib.relu,
          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
          BatchNorm(256),               [90m# 512 parameters[39m[90m, plus 512[39m
        ),
      ),
    ),
    Chain(
      Parallel(
        addact(NNlib.relu, ...),
        Chain(
          Conv((1, 1), 256 =&gt; 512, stride=2, bias=false),  [90m# 131_072 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
        Chain(
          Conv((3, 3), 256 =&gt; 512, pad=1, stride=2, bias=false),  [90m# 1_179_648 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
          NNlib.relu,
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
      ),
      Parallel(
        addact(NNlib.relu, ...),
        identity,
        Chain(
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
          NNlib.relu,
          Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
          BatchNorm(512),               [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        ),
      ),
    ),
  ),
  Chain(
    AdaptiveMeanPool((1, 1)),
    MLUtils.flatten,
    Dense(512 =&gt; 1000),                 [90m# 513_000 parameters[39m
  ),
) [90m        # Total: 62 trainable arrays, [39m11_689_512 parameters,
[90m          # plus 40 non-trainable, 9_600 parameters, summarysize [39m44.654 MiB.
</code></pre>
<p>Now we modify the head, by chaning the last <code>Chain</code> in the model. We change the last layer to output 4 classes (as opposed to the original 1000 classes).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># modify the model</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_infer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">resnet_model</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet_tune</span> <span class="o">=</span> <span class="n">Chain</span><span class="p">(</span><span class="n">AdaptiveMeanPool</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Flux</span><span class="o">.</span><span class="n">flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span> <span class="o">=&gt;</span> <span class="mi">4</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>Chain(
  AdaptiveMeanPool((1, 1)),
  Flux.flatten,
  Dense(512 =&gt; 4),                      [90m# 2_052 parameters[39m
) 
</code></pre>
<p><strong>And that&rsquo;s it!</strong> Now, let&rsquo;s just explore both portions of the model.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_infer</span>
</span></span></code></pre></div><pre><code>Chain(
  Chain(
    Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  [90m# 9_408 parameters[39m
    BatchNorm(64, relu),                [90m# 128 parameters[39m[90m, plus 128[39m
    MaxPool((3, 3), pad=1, stride=2),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
        NNlib.relu,
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
        NNlib.relu,
        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  [90m# 36_864 parameters[39m
        BatchNorm(64),                  [90m# 128 parameters[39m[90m, plus 128[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  [90m# 8_192 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
      Chain(
        Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  [90m# 73_728 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
        NNlib.relu,
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
        NNlib.relu,
        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  [90m# 147_456 parameters[39m
        BatchNorm(128),                 [90m# 256 parameters[39m[90m, plus 256[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  [90m# 32_768 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
      Chain(
        Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  [90m# 294_912 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
        NNlib.relu,
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
        NNlib.relu,
        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  [90m# 589_824 parameters[39m
        BatchNorm(256),                 [90m# 512 parameters[39m[90m, plus 512[39m
      ),
    ),
  ),
  Chain(
    Parallel(
      addact(NNlib.relu, ...),
      Chain(
        Conv((1, 1), 256 =&gt; 512, stride=2, bias=false),  [90m# 131_072 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
      Chain(
        Conv((3, 3), 256 =&gt; 512, pad=1, stride=2, bias=false),  [90m# 1_179_648 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        NNlib.relu,
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
    ),
    Parallel(
      addact(NNlib.relu, ...),
      identity,
      Chain(
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
        NNlib.relu,
        Conv((3, 3), 512 =&gt; 512, pad=1, bias=false),  [90m# 2_359_296 parameters[39m
        BatchNorm(512),                 [90m# 1_024 parameters[39m[90m, plus 1_024[39m
      ),
    ),
  ),
) [90m        # Total: 60 trainable arrays, [39m11_176_512 parameters,
[90m          # plus 40 non-trainable, 9_600 parameters, summarysize [39m42.693 MiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_tune</span>
</span></span></code></pre></div><pre><code>Chain(
  AdaptiveMeanPool((1, 1)),
  Flux.flatten,
  Dense(512 =&gt; 4),                      [90m# 2_052 parameters[39m
) 
</code></pre>
<h3 id="define-evaluation-and-training-functions">Define evaluation and training functions</h3>
<p>Again, will follow the model zoo documentation. Small adaptations will be needed. (These two functions were taken directly from the documentation).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">m_infer</span><span class="p">,</span> <span class="n">m_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">good</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">in</span> <span class="n">val_loader</span>
</span></span><span class="line"><span class="cl">        <span class="n">good</span> <span class="o">+=</span> <span class="n">sum</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">onecold</span><span class="p">(</span><span class="n">m_tune</span><span class="p">(</span><span class="n">m_infer</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="o">.==</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">count</span> <span class="o">+=</span> <span class="n">length</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="n">round</span><span class="p">(</span><span class="n">good</span> <span class="o">/</span> <span class="n">count</span><span class="p">,</span> <span class="n">digits</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>eval_f (generic function with 1 method)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">model_infer</span><span class="p">,</span> <span class="n">model_tune</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">in</span> <span class="n">loader</span>
</span></span><span class="line"><span class="cl">        <span class="n">infer</span> <span class="o">=</span> <span class="n">model_infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">grads</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">model_tune</span><span class="p">)</span> <span class="k">do</span> <span class="n">m</span>
</span></span><span class="line"><span class="cl">            <span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">logitcrossentropy</span><span class="p">(</span><span class="n">m</span><span class="p">(</span><span class="n">infer</span><span class="p">),</span> <span class="n">Flux</span><span class="o">.</span><span class="n">onehotbatch</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">end</span>
</span></span><span class="line"><span class="cl">        <span class="n">update!</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">model_tune</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>train_epoch! (generic function with 1 method)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">resnet_opt</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Optimisers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span> <span class="n">resnet_tune</span><span class="p">);</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@time</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">resnet_opt</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_train</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_eval</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">resnet_infer</span><span class="p">,</span> <span class="n">resnet_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;train&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_train</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;eval&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_eval</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>176.283332 seconds (37.11 M allocations: 98.153 GiB, 6.06% gc time, 143.87% compilation time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.5744
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.5455


 70.815518 seconds (2.42 M allocations: 95.936 GiB, 11.25% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.6823
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


 90.463025 seconds (2.42 M allocations: 95.936 GiB, 11.21% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7032
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6455


 94.362892 seconds (2.42 M allocations: 95.936 GiB, 10.91% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7433
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6727


116.526515 seconds (2.42 M allocations: 95.936 GiB, 9.62% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7885
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6909
</code></pre>
<hr>
<h2 id="vision-transformers">Vision Transformers</h2>
<hr>
<p>Similar to the PyTorch demonstration, we can do transfer learning by changing a different computer vision model (Vision Transformer).</p>
<p>Let&rsquo;s get into it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">vit_model</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">(</span><span class="ss">:base</span><span class="p">;</span> <span class="n">pretrain</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span><span class="o">.</span><span class="n">layers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># let&#39;s have a look at the model head, to see how many inputs the head needs</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_model</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</span></span></code></pre></div><pre><code>Chain(
  LayerNorm(768),                       [90m# 1_536 parameters[39m
  Dense(768 =&gt; 1000),                   [90m# 769_000 parameters[39m
) [90m                  # Total: 4 arrays, [39m770_536 parameters, 2.940 MiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># modify the head</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_infer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vit_model</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># notice how we keep the input to the model head</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_tune</span> <span class="o">=</span> <span class="n">Chain</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">LayerNorm</span><span class="p">(</span><span class="mi">768</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Dense</span><span class="p">(</span><span class="mi">768</span> <span class="o">=&gt;</span> <span class="mi">4</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><pre><code>Chain(
  LayerNorm(768),                       [90m# 1_536 parameters[39m
  Dense(768 =&gt; 4),                      [90m# 3_076 parameters[39m
) [90m                  # Total: 4 arrays, [39m4_612 parameters, 18.352 KiB.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">vit_opt</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Optimisers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span> <span class="n">vit_tune</span><span class="p">);</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@time</span> <span class="n">train_epoch!</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">vit_opt</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_train</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_eval</span> <span class="o">=</span> <span class="n">eval_f</span><span class="p">(</span><span class="n">vit_infer</span><span class="p">,</span> <span class="n">vit_tune</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;train&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_train</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@info</span> <span class="s">&#34;eval&#34;</span> <span class="n">metric</span> <span class="o">=</span> <span class="n">metric_eval</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>627.303072 seconds (17.32 M allocations: 291.924 GiB, 4.61% gc time, 3.66% compilation time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.7058
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


565.986959 seconds (2.54 M allocations: 291.028 GiB, 4.71% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.8042
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6273


516.041945 seconds (2.54 M allocations: 291.028 GiB, 4.92% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.866
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6818


515.415614 seconds (2.54 M allocations: 291.028 GiB, 4.80% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.8973
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6818


427.423410 seconds (2.54 M allocations: 291.028 GiB, 5.01% gc time)


[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mtrain
[36m[1m└ [22m[39m  metric = 0.9199
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39meval
[36m[1m└ [22m[39m  metric = 0.6727
</code></pre>
<h3 id="save-the-models">Save the Models</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">JLD2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">resnet_model_state</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">resnet_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vit_model_state</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="n">vit_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">jldsave</span><span class="p">(</span><span class="s">&#34;resnet_model.jld2&#34;</span><span class="p">;</span> <span class="n">resnet_model_state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">jldsave</span><span class="p">(</span><span class="s">&#34;vit_model.jld2&#34;</span><span class="p">;</span> <span class="n">vit_model_state</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[33m[1m┌ [22m[39m[33m[1mWarning: [22m[39mOpening file with JLD2.MmapIO failed, falling back to IOStream
[33m[1m└ [22m[39m[90m@ JLD2 C:\Users\ingvi\.julia\packages\JLD2\7uAqU\src\JLD2.jl:300[39m
[33m[1m┌ [22m[39m[33m[1mWarning: [22m[39mOpening file with JLD2.MmapIO failed, falling back to IOStream
[33m[1m└ [22m[39m[90m@ JLD2 C:\Users\ingvi\.julia\packages\JLD2\7uAqU\src\JLD2.jl:300[39m
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">BSON</span><span class="o">:</span> <span class="nd">@save</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@save</span> <span class="s">&#34;resnet_model_sate.bson&#34;</span> <span class="n">resnet_model</span>
</span></span><span class="line"><span class="cl"><span class="nd">@save</span> <span class="s">&#34;vit_model_state.bson&#34;</span> <span class="n">vit_model</span>
</span></span></code></pre></div><h2 id="thank-you">Thank you!</h2>
<p>I hope this demonstration on using Julia and <code>Flux</code> for transfer learning was helpful!</p>
<p>Victor</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Bayesian Time Series Analysis with Julia and Turing.jl</title>
      <link>http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/</link>
      <pubDate>Sat, 02 Mar 2024 16:57:07 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/</guid>
      <description>This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning.</description>
      <content:encoded><![CDATA[<hr>
<h2 id="introduction">Introduction</h2>
<p>In this tutorial, an AR(p) (Autoregressive model of order <em>p</em>) is employed to analyze the trneds of a time series and forecast the behavior of the signal.</p>
<p>Auto-regressive models are based on the assumption the behavior of a time series or signal depends on past values. The order of the AR model tells &ldquo;how far back&rdquo; the past values will affect the current value.</p>
<h4 id="credits">Credits</h4>
<p>This exercise is mostly following <a href="https://youtu.be/vfTYCm_Fr8I?si=D3Grgk82tV_Qzdxw">this tutorial</a>.</p>
<h3 id="definition">Definition</h3>
<p>The <em>AR(p)</em> model is defined as:</p>
<p>$$
X_t = \sum_{i=1}^{p} \phi_i X_{t-i} + \varepsilon_t
$$</p>
<p>where $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ is the model uncertainty represented as white Gaussian noise, i.e. it follows a normal distribution of mean $\mu=0$ and standard deviation $\sigma$.</p>
<p>It follows that an <em>AR(2)</em> model is defined as:</p>
<p>$$
X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \varepsilon_t
$$</p>
<p>Naturally, we want to find the parameters $\theta={\phi_1, \phi_2,\sigma}$. Since these are unobserved quantities of interest, we need to use an inference method to reveal these parameters. We will use Bayesian inference to achieve this goal.</p>
<h2 id="data-exploration">Data Exploration</h2>
<p>For this example, I will generate artificial data. This will be done by first defining some values for the parameters $\theta$ and then we will generate random data using those parameters by initializing the $X_1, X_2$ values, and then applying the AR(2) equation to generate the subsequent values.</p>
<p>First, we import the relevant packages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">StatsPlots</span><span class="p">,</span> <span class="n">Turing</span><span class="p">,</span> <span class="n">LaTeXStrings</span><span class="p">,</span> <span class="n">Random</span><span class="p">,</span> <span class="n">DataFrames</span>
</span></span><span class="line"><span class="cl"><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>TaskLocalRNG()
</code></pre>
<p>Now we create some artificial data. The steps involved in this are as follows:</p>
<ol>
<li>Define some values for the parameters $\theta$</li>
<li>Set the number of timesteps <em>t</em></li>
<li>Initialize an empty vector of size $\mathbb{R}^{t+p}$</li>
<li>Initialize the first two $X$ values with randomly generated numbers using <code>rand</code></li>
<li>Populate the vector by using the equation for $X_t$</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># define true values for θ</span>
</span></span><span class="line"><span class="cl"><span class="n">true_phi_1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.4</span>
</span></span><span class="line"><span class="cl"><span class="n">true_phi_2</span> <span class="o">=</span> <span class="mf">0.3</span>
</span></span><span class="line"><span class="cl"><span class="n">true_sigma</span> <span class="o">=</span> <span class="mf">0.12</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define the time steps</span>
</span></span><span class="line"><span class="cl"><span class="n">time</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="c"># create an empty X vector</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># initialize the X vector with two random values at time steps 1 and 2</span>
</span></span><span class="line"><span class="cl"><span class="c"># to do this, use a random normally distributed number with mean zero and standard deviation σ, i.e., ε~N(0, σ)</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># populate vector X</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">t</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_phi_1</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">	<span class="n">true_phi_2</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">	<span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_sigma</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>	
</span></span></code></pre></div><h3 id="visualize-the-artificial-data">Visualize the (Artificial) Data</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">p_data</span> <span class="o">=</span> <span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="o">:</span><span class="k">end</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c"># xlims = (0, 60),</span>
</span></span><span class="line"><span class="cl">    <span class="c"># ylims = (-0.6, 0.6),</span>
</span></span><span class="line"><span class="cl">    <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Bayesian Autoregressive AR(2) Model&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">xlabel</span> <span class="o">=</span> <span class="sa">L</span><span class="s">&#34;t&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ylabel</span> <span class="o">=</span> <span class="sa">L</span><span class="s">&#34;X_t&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">widen</span> <span class="o">=</span> <span class="nb">true</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_5_0.svg" type="" alt="svg"  /></p>
<h2 id="modeling">Modeling</h2>
<p>The next step is to construct our probabilistic model. Again, the goal here is to infer the values of the model parameters $\theta$. Once we have inferred these parameters, we can make probabilistic predictions on the future behavior of the signal $X$.</p>
<h3 id="bayesian-model">Bayesian model</h3>
<p>Since we are using a Bayesian approach, our goal, in Bayesian terms, is to find the <em>posterior distribution</em> of the parameters $\theta$, given a prior distribution, or prior knowledge, of the parameters before making any observations, i.e., seeing any data, and also a likelihood function, which reflects what kind of distribution (we assume) that the data is sourced from. Another way of understanding the likelihood function is the probability of making a set of observations $X$ given the parameters $\theta$.</p>
<p>This relationship is established by Bayes&rsquo; Theorem:</p>
<p>$$
P(\theta | X) \propto P(X | \theta)P(\theta)
$$</p>
<p>In summary, constructing the Bayesian model in this case comprises a selection of prior distributions for our unknown parameters $\theta$ and a likelihood function. We will do this using the <code>Turing.jl</code> package.</p>
<p>The model therefore will consist of the prior distributions:</p>
<p>$$
\begin{align*}
\phi_1 &amp; \sim \mathcal{N}(0, 1) \
\phi_2 &amp; \sim \mathcal{N}(0, 1) \
\sigma &amp; \sim \text{Exp}(1)
\end{align*}
$$</p>
<p>And the likelihood:</p>
<p>$$
X_t \sim \mathcal{N}(\mu_t, \sigma)
$$</p>
<p>where $\mu_t = \sum_{i=1}^{p} \phi_i X_{t-i}$ is the mean function of the distribution that governs X_t.</p>
<h4 id="a-comment-on-the-choice-of-priors">A comment on the choice of priors</h4>
<p>For autoregressive parameters, using a normal distribution is a common choice. This is because the normal distribution is convenient and allows for a range of plausible values.</p>
<p>For the prior on the model uncertainty, the exponential distribution is sometimes used for non-negative parameters and has a similar role to the inverse gamma.</p>
<p>Furthermore, the inverse gamma distribution is often chosen as a prior for the standard deviation because it is conjugate to the normal likelihood. This means that the posterior distribution will have a known form, making computations more tractable.</p>
<h3 id="bayesian-model-using-turingjl">Bayesian model using <code>Turing.jl</code></h3>
<p>Now we proceed to set up the model using the <code>Turing.jl</code> package.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">ar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>    <span class="c"># pass the data X and the time vector</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># priors</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">		<span class="n">phi_1</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">phi_2</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">sigma</span> <span class="o">~</span> <span class="n">Exponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># likelihood</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># initialize with random initial values</span>
</span></span><span class="line"><span class="cl">		<span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># populate with samples</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">			<span class="n">mu</span> <span class="o">=</span> <span class="n">phi_1</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">phi_2</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">end</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span></code></pre></div><pre><code>ar (generic function with 2 methods)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">ar</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="mi">1_000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.4
[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:01[39m





Chains MCMC chain (1000×15×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 11.59 seconds
Compute duration  = 11.59 seconds
parameters        = phi_1, phi_2, sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m ⋯

       phi_1   -0.3830    0.1047    0.0036   836.6151   762.4445    0.9996     ⋯
       phi_2    0.1587    0.1012    0.0035   838.3014   749.6718    1.0002     ⋯
       sigma    0.1083    0.0079    0.0003   755.4034   743.3822    1.0014     ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

       phi_1   -0.5733   -0.4562   -0.3858   -0.3141   -0.1771
       phi_2   -0.0339    0.0913    0.1562    0.2256    0.3549
       sigma    0.0943    0.1030    0.1079    0.1130    0.1257
</code></pre>
<h3 id="visualize-and-summarize-the-results">Visualize and Summarize the Results</h3>
<p>Next we can access the MCMC Diagnostics and generate a summary of the results.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_10_0.svg" type="" alt="svg"  /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">DataFrame</span><span class="p">(</span><span class="n">summarystats</span><span class="p">(</span><span class="n">chain</span><span class="p">))</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>3×8 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameters</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">std</th><th style = "text-align: left;">mcse</th><th style = "text-align: left;">ess_bulk</th><th style = "text-align: left;">ess_tail</th><th style = "text-align: left;">rhat</th><th style = "text-align: left;">ess_per_sec</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">phi_1</td><td style = "text-align: right;">-0.383019</td><td style = "text-align: right;">0.104695</td><td style = "text-align: right;">0.00361324</td><td style = "text-align: right;">836.615</td><td style = "text-align: right;">762.444</td><td style = "text-align: right;">0.999585</td><td style = "text-align: right;">72.1655</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">phi_2</td><td style = "text-align: right;">0.158661</td><td style = "text-align: right;">0.101196</td><td style = "text-align: right;">0.00351463</td><td style = "text-align: right;">838.301</td><td style = "text-align: right;">749.672</td><td style = "text-align: right;">1.00021</td><td style = "text-align: right;">72.311</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">sigma</td><td style = "text-align: right;">0.108342</td><td style = "text-align: right;">0.00788622</td><td style = "text-align: right;">0.000291067</td><td style = "text-align: right;">755.403</td><td style = "text-align: right;">743.382</td><td style = "text-align: right;">1.00145</td><td style = "text-align: right;">65.1603</td></tr></tbody></table></div>
<h2 id="predictions">Predictions</h2>
<h3 id="making-predictions">Making Predictions</h3>
<p>To make predictions, the following steps are taken:</p>
<ol>
<li>Set the number of time steps into the future, $t_f$</li>
<li>Initialize an empty matrix for the forecasted $X$ values - This will be a matrix because it will be a collection of vectors. Each vector will represent one sample forecast</li>
<li>Initialize two steps of each of the sample vectors to be generated - In practical terms, initialize the first number of each column; each <em>column</em> will represent a forecast time series</li>
</ol>
<p>Keep in mind that what will be done here is to create samples of the future behavior of the signal $t_f$ number of time steps into the future. To do this, we will generate signals that use the posterior distributions of the parameters $\theta$ by calling the function <code>rand(chain[:,Z,Z])</code> which will randomly pick a number out of the sample pool, effectively &ldquo;sampling&rdquo; from that posterior distribution (sample pool).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">time_future</span> <span class="o">=</span> <span class="mi">15</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_future</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span> <span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># Initialize the first two time steps for every forecast</span>
</span></span><span class="line"><span class="cl"><span class="n">X_future</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span> <span class="o">.=</span> <span class="n">X</span><span class="p">[</span><span class="n">time</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">X_future</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span> <span class="o">.=</span> <span class="n">X</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># populate the forecast vectors by sampling from the posterior sample pool of the parameters θ</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">col</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">	<span class="n">phi_1_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">phi_2_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">error_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="n">noise_future</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">error_future</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">row</span> <span class="k">in</span> <span class="mi">3</span><span class="o">:</span><span class="p">(</span><span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> 
</span></span><span class="line"><span class="cl">			<span class="n">phi_1_future</span> <span class="o">*</span> <span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">+</span> 
</span></span><span class="line"><span class="cl">			<span class="n">phi_2_future</span> <span class="o">*</span> <span class="n">X_future</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">			<span class="n">noise_future</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><h4 id="visualize-the-forecast">Visualize the forecast</h4>
<p>Now that we <em>propagated the uncertainty</em> of in the posterior distribution of the parameters $\theta$, we can plot the posterior predictive distribution of $X$, $P(X^*|\theta)$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">time_predict</span> <span class="o">=</span> <span class="n">time</span><span class="o">:</span><span class="p">(</span><span class="n">time</span> <span class="o">+</span> <span class="n">time_future</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">	<span class="n">plot!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="n">time_predict</span><span class="p">,</span> <span class="n">X_future</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="c"># predictions</span>
</span></span><span class="line"><span class="cl">	<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="ss">:green</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></span><span class="line"><span class="cl">	<span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># visualize mean values for predictions</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_future_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">mean</span><span class="p">(</span><span class="n">X_future</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="p">(</span><span class="n">time_future</span><span class="o">+</span><span class="mi">2</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="n">time_predict</span><span class="p">,</span> <span class="n">X_future_mean</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">color</span> <span class="o">=</span> <span class="ss">:red</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	<span class="n">linestyle</span> <span class="o">=</span> <span class="ss">:dot</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240222_Bayesian_Time_Series_Analysis/output_15_0.svg" type="" alt="svg"  /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"></code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>Bayesian Poisson Regression with Julia and Turing.jl</title>
      <link>http://localhost:1313/posts/20240217_bayesian_poisson_regression/20240217_bayesian_poisson_regression/</link>
      <pubDate>Sat, 17 Feb 2024 11:57:07 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240217_bayesian_poisson_regression/20240217_bayesian_poisson_regression/</guid>
      <description>Explore Bayesian Poisson regression for modeling count data with Julia and Turing.jl. This tutorial includes model setup, implementation, and performance assessment with a practical example.</description>
      <content:encoded><![CDATA[<hr>
<p>In this example, I am following the tutorials found in:</p>
<ul>
<li><a href="https://turinglang.org/dev/tutorials/07-poisson-regression/">Turing.jl - Bayesian Poisson Regression</a></li>
<li><a href="https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-poisson-regression.html">PyMC - GLM: Poisson Regression</a></li>
</ul>
<p>Both examples show the interaction between some variables and a discrete outcome. In this case, the outcome is the number of sneezes per day (i.e. a discrete outcome) in some study subjects, and whether or not they take antihistamine medicine and whether or not they drink alcohol.</p>
<p>This example explores how these factors, and more specifically, the combination of these factors, affect the number of times a person sneezes.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">CSV</span><span class="p">,</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">Turing</span><span class="p">,</span> <span class="n">StatsPlots</span><span class="p">,</span> <span class="n">Plots</span><span class="p">,</span> <span class="n">Random</span>
</span></span><span class="line"><span class="cl"><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>TaskLocalRNG()
</code></pre>
<h2 id="collect-generate-the-data">Collect (generate) the data</h2>
<p>In this example, we will generate the data in the same way as in the tutorials:</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:center">No Alcohol</th>
<th style="text-align:center">Alcohol</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>No Meds</strong></td>
<td style="text-align:center">6</td>
<td style="text-align:center">36</td>
</tr>
<tr>
<td style="text-align:left"><strong>Meds</strong></td>
<td style="text-align:center">1</td>
<td style="text-align:center">3</td>
</tr>
</tbody>
</table>
<p>Those values will be used to create the artificial data by generating Poisson-distributed random samples.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">theta_noalc_nomed</span> <span class="o">=</span> <span class="mi">6</span>
</span></span><span class="line"><span class="cl"><span class="n">theta_noalc_med</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">theta_alc_nomed</span> <span class="o">=</span> <span class="mi">36</span>
</span></span><span class="line"><span class="cl"><span class="n">theta_alc_med</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">ns</span> <span class="o">=</span> <span class="mi">500</span>    <span class="c"># number of samples</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># create a data frame</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">hcat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">vcat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">rand</span><span class="p">(</span><span class="n">Poisson</span><span class="p">(</span><span class="n">theta_noalc_med</span><span class="p">),</span> <span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">rand</span><span class="p">(</span><span class="n">Poisson</span><span class="p">(</span><span class="n">theta_alc_med</span><span class="p">),</span> <span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">rand</span><span class="p">(</span><span class="n">Poisson</span><span class="p">(</span><span class="n">theta_noalc_nomed</span><span class="p">),</span> <span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">rand</span><span class="p">(</span><span class="n">Poisson</span><span class="p">(</span><span class="n">theta_alc_nomed</span><span class="p">),</span> <span class="n">ns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">vcat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">falses</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">trues</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">falses</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">trues</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">vcat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">falses</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">falses</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">trues</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">trues</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span> <span class="ss">:auto</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># assign names to headers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">head_names</span> <span class="o">=</span> <span class="p">[</span><span class="ss">:n_sneezes</span><span class="p">,</span> <span class="ss">:alcohol</span><span class="p">,</span> <span class="ss">:nomeds</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sneeze_data</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">head_names</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">first</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>10×3 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">n_sneezes</th><th style = "text-align: left;">alcohol</th><th style = "text-align: left;">nomeds</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">6</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">7</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">8</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">9</td><td style = "text-align: right;">2</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">10</td><td style = "text-align: right;">2</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td></tr></tbody></table></div>
<h3 id="visualize-the-data">Visualize the data</h3>
<p>Now that we have &ldquo;collected&rdquo; some data on the number of sneezes per day from a number of people, we visualize the data.</p>
<p>The way we are collecting and plotting these data sub-sets is as follows:</p>
<ol>
<li>Call the histogram function</li>
<li>Create a histogram of the dataframe &ldquo;sneeze_data&rdquo; we &ldquo;collected&rdquo; previously</li>
<li>Select a subset of that dataframe</li>
<li>All the rows of the columns where alcohol is <code>false</code> i.e. 0 AND all the rows where no medicine was taken is also <code>false</code></li>
<li>All the rows of the columns where alcohol is <code>false</code> AND all the rows of where medicine is <code>true</code></li>
<li>&hellip; and so on</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># create separate histograms for each case</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p1</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">[(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:alcohol</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">.&amp;</span> <span class="p">(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:nomeds</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">0</span><span class="p">),</span> <span class="ss">:n_sneezes</span><span class="p">];</span> <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;No alcohol + No Meds&#34;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">&#34;People Count&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p2</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">[(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:alcohol</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">.&amp;</span> <span class="p">(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:nomeds</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">0</span><span class="p">),</span> <span class="ss">:n_sneezes</span><span class="p">];</span> <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;No alcohol + Meds&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p3</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">[(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:alcohol</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">.&amp;</span> <span class="p">(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:nomeds</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">1</span><span class="p">),</span> <span class="ss">:n_sneezes</span><span class="p">];</span> <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Alcohol + No Meds&#34;</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s">&#34;Sneezes/Day&#34;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">&#34;People Count&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p4</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">[(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:alcohol</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">.&amp;</span> <span class="p">(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:nomeds</span><span class="p">]</span> <span class="o">.==</span> <span class="mi">1</span><span class="p">),</span> <span class="ss">:n_sneezes</span><span class="p">];</span> <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Alcohol + Meds&#34;</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s">&#34;Sneezes/Day&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">p3</span><span class="p">,</span> <span class="n">p4</span><span class="p">;</span> <span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240217_Bayesian_Poisson_Regression/output_5_0.svg" type="" alt="svg"  /></p>
<h3 id="interpreting-the-data">Interpreting the data</h3>
<p>The histograms show that the data from the &ldquo;study&rdquo; resembles a Poisson distribution (as mentioned in the PyMC tutorial, this is obvious, because that&rsquo;s how the data is generated!). Furthermore, the data is telling us something:</p>
<ul>
<li>Looking at the plot for &ldquo;no alcohol and medicine&rdquo; it is clear that most people reported very few sneezes; notice how the histogram skews towards large counts (of people) for very few sneezes</li>
<li>On the other hand, notice how the &ldquo;alcohol and <em>no</em> medicine&rdquo; seems to tell us that many reported somewhere around 35 sneezes per day</li>
</ul>
<p>Again, we can start thinking of a pattern just by looking at the data, and it seems like the data is telling us that if you don&rsquo;t drink alcohol and take antihistamines, you are less likely to be sneezing around than if you drink alcohol and don&rsquo;t take any allergy meds. Makes sense, right?</p>
<h2 id="model">Model</h2>
<p>We established that the data looks like it could be modelled as a Poisson distribution. Thus, we can define our probabilistic model as follows:</p>
<p>$$Y_{obs} \sim Poisson(\lambda)$$</p>
<p>$$\log(\lambda) = \theta&rsquo;\mathbf{x} = \alpha + \beta&rsquo; \mathbf{x}$$</p>
<p>What the above means is that we assume that the observed data outcomes, i.e., the number of sneezes per day, follow a Poisson distribution, which is a discrete probability distribution that models the number of events that occur in a fixed interval of time or space. The rate or intensity of the events, $\lambda$, depends on the predictor variables (the input data) $\mathcal{x}$, such as the season, the temperature, or, in our case, whether a person ingested alcohol and whether the person took antihistamines.</p>
<p>The linear predictor $\theta&rsquo; \mathcal{x}$ is the function that links the predictor variables to the rate parameter, where $\theta = {\alpha, \beta&rsquo;}$ are the parameters of the model.</p>
<p>Looking at the structure of the linear relationship between the paramters of the model, and the predictors:</p>
<p>$$\log(\lambda) = \alpha + \beta&rsquo; \mathcal{x}$$</p>
<p>we can understand that the parameter $\alpha$ is the intercept, which is the expected number of sneezes when all the predictor variables are zero. The parameter $\beta&rsquo;$ is a vector of coefficients, which measure the effect of each predictor variable $\mathcal{x}$ on the number of sneezes. The log link function ensures that the rate parameter $\lambda$ is always positive and allows for multiplicative effects of the predictor variables on the response variable.</p>
<h3 id="define-the-model-with-turingjl">Define the model with <code>Turing.jl</code></h3>
<p>Now that we know how we are modeling our data, we use the package <code>Turing.jl</code> to define the model. <code>Turing.jl</code> is a tool that helps us write models in Julia and find the best parameters for them.</p>
<p>The model has two parts: the prior and the likelihood. The prior is what we think or guess about the parameters before we see the data. The likelihood is how likely the data is under the parameters. The parameters are the numbers that control the model, such as the rate of sneezes.</p>
<p>We use the Poisson distribution for the likelihood, because it is good for counting things, like sneezes. The Poisson distribution has one parameter, the rate of sneezes. The higher the rate, the more sneezes we expect.</p>
<p>We use any distribution for the prior, depending on how much we know about the parameters. If we know nothing, we use a flat prior, which does not favor any value. The prior affects the final answer, because it is our starting point.</p>
<p>We use Bayes’ theorem to combine the prior and the likelihood and get the final answer. The final answer is the posterior, which is what we believe about the parameters after we see the data. The posterior is the best fit for the model and the data.</p>
<p><strong>Let&rsquo;s crank up the Bayes!</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">poisson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># define the priors</span>
</span></span><span class="line"><span class="cl">		<span class="n">alpha</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">alcohol</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">nomeds</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="c"># alc_med ~ Normal(0,1)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c"># define the likelihood</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	        <span class="n">log_lambda</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">alcohol</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">nomeds</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> 
</span></span><span class="line"><span class="cl">	        <span class="n">lambda</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">log_lambda</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	    <span class="k">end</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span></code></pre></div><pre><code>poisson (generic function with 2 methods)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># pass the data to the model function</span>
</span></span><span class="line"><span class="cl">	<span class="c"># pass the predictor data as a Matrix for efficiency</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">poisson</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">sneeze_data</span><span class="p">[</span><span class="o">!</span><span class="p">,[</span><span class="ss">:alcohol</span><span class="p">,</span> <span class="ss">:nomeds</span><span class="p">]</span> <span class="p">]),</span> <span class="n">sneeze_data</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="ss">:n_sneezes</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># select the sampler</span>
</span></span><span class="line"><span class="cl"><span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># define the number of sampler</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># set number of chains</span>
</span></span><span class="line"><span class="cl"><span class="n">num_chains</span> <span class="o">=</span> <span class="mi">8</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="c"># crank up the Bayes!</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">MCMCThreads</span><span class="p">(),</span> <span class="n">samples</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.00625
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.00625
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.00625
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.00625
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[32mSampling (8 threads): 100%|█████████████████████████████| Time: 0:00:00[39m





Chains MCMC chain (1000×15×8 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 8
Samples per chain = 1000
Wall duration     = 13.66 seconds
Compute duration  = 100.67 seconds
parameters        = alpha, alcohol, nomeds
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m  ess_tail [0m [1m    rhat [0m [1m[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m   Float64 [0m [90m Float64 [0m [90m[0m ⋯

       alpha   -0.5025    0.0277    0.0005   2943.5608   2841.2874    1.0030   ⋯
     alcohol    1.7333    0.0186    0.0003   3801.1996   3652.2403    1.0022   ⋯
      nomeds    2.3348    0.0236    0.0004   2901.3750   3410.6453    1.0020   ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

       alpha   -0.5568   -0.5212   -0.5023   -0.4839   -0.4486
     alcohol    1.6974    1.7205    1.7331    1.7458    1.7698
      nomeds    2.2891    2.3189    2.3346    2.3506    2.3824
</code></pre>
<p><strong>NOTE:</strong> The above routine employs the MCMCThreads method to sample multiple chains. However, in order to implement this, one needs to change the environment variables for the number of threads Julia can use. These two threads might shed some light as to how to achieve this:</p>
<ol>
<li><a href="https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading">https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading</a></li>
<li><a href="https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794">https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794</a></li>
</ol>
<p>Of course, if you don&rsquo;t want to bother, then just change the last two functional lines in the cell above so that they read:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl">	<span class="c"># set number of chains - comment this out:</span>
</span></span><span class="line"><span class="cl">	<span class="c"># num_chains = 8</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c"># crank up the Bayes! - delete MCMCThreads() and num_chains</span>
</span></span><span class="line"><span class="cl">	<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="visualize-the-results">Visualize the results</h3>
<p>We can see above that we have obtained a sample pool of the posterior distribution of the parameters. This is what we were looking for. What this means is that now we have a posterior distribution (in the form of a sample pool), which we can also summarize with summary statistics.</p>
<p>Let&rsquo;s look at the diagnostics plots and the summary statistics.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240217_Bayesian_Poisson_Regression/output_13_0.svg" type="" alt="svg"  /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">DataFrame</span><span class="p">(</span><span class="n">summarystats</span><span class="p">(</span><span class="n">chain</span><span class="p">))</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>3×8 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">parameters</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">std</th><th style = "text-align: left;">mcse</th><th style = "text-align: left;">ess_bulk</th><th style = "text-align: left;">ess_tail</th><th style = "text-align: left;">rhat</th><th style = "text-align: left;">ess_per_sec</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">alpha</td><td style = "text-align: right;">-0.502519</td><td style = "text-align: right;">0.0276553</td><td style = "text-align: right;">0.000511069</td><td style = "text-align: right;">2943.56</td><td style = "text-align: right;">2841.29</td><td style = "text-align: right;">1.00298</td><td style = "text-align: right;">29.2397</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">alcohol</td><td style = "text-align: right;">1.7333</td><td style = "text-align: right;">0.0186097</td><td style = "text-align: right;">0.000301611</td><td style = "text-align: right;">3801.2</td><td style = "text-align: right;">3652.24</td><td style = "text-align: right;">1.00224</td><td style = "text-align: right;">37.759</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">nomeds</td><td style = "text-align: right;">2.3348</td><td style = "text-align: right;">0.0236269</td><td style = "text-align: right;">0.000436385</td><td style = "text-align: right;">2901.38</td><td style = "text-align: right;">3410.65</td><td style = "text-align: right;">1.00197</td><td style = "text-align: right;">28.8207</td></tr></tbody></table></div>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># taking the first chain</span>
</span></span><span class="line"><span class="cl"><span class="n">c1</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="o">:</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># Calculating the exponentiated means</span>
</span></span><span class="line"><span class="cl"><span class="n">b0_exp</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">c1</span><span class="p">[</span><span class="ss">:alpha</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="n">b1_exp</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">c1</span><span class="p">[</span><span class="ss">:alcohol</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="n">b2_exp</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">c1</span><span class="p">[</span><span class="ss">:nomeds</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">println</span><span class="p">(</span><span class="s">&#34;The exponent of the mean of the weights (or coefficients) are: </span><span class="se">\n</span><span class="s">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">println</span><span class="p">(</span><span class="s">&#34;b0: &#34;</span><span class="p">,</span> <span class="n">b0_exp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">println</span><span class="p">(</span><span class="s">&#34;b1: &#34;</span><span class="p">,</span> <span class="n">b1_exp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">println</span><span class="p">(</span><span class="s">&#34;b2: &#34;</span><span class="p">,</span> <span class="n">b2_exp</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>The exponent of the mean of the weights (or coefficients) are: 

b0: 0.604415461752317
b1: 5.658573583760772
b2: 10.342642711232362
</code></pre>
<p>Notice how we are <strong>not</strong> recovering the original $\lambda$ values that were used to create this data set, i.e.:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl">	<span class="n">theta_noalc_nomed</span> <span class="o">=</span> <span class="mi">6</span>
</span></span><span class="line"><span class="cl">	<span class="n">theta_noalc_med</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">	<span class="n">theta_alc_nomed</span> <span class="o">=</span> <span class="mi">36</span>
</span></span><span class="line"><span class="cl">	<span class="n">theta_alc_med</span> <span class="o">=</span> <span class="mi">3</span>
</span></span></code></pre></div><p>Instead, we are recovering <em>the parameters of the linear function</em>, in other words, $\theta = {\alpha, \beta&rsquo;}$ in the linear relation:</p>
<p>$$\log(\lambda) = \alpha + \beta_1 x_{alc} + \beta_2 x_{meds}$$</p>
<p>where $x_{(\cdot)}$ represents the binary variable of whether the subject took alcohol/medicine or not.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This tutorial shows how to perform Bayesian inference on <em>discrete</em> data, e.g. the record of how many sneezes per day a group of people had, and classified according to their alcohol and medication consumption.</p>
<p>In real-world scenarios, we would obviously not know the parameter values, since this is precisely what we want to find out by incorporating whatever we knew about them into what we observed.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Bayesian Logistic Regression with Julia and Turing.jl</title>
      <link>http://localhost:1313/posts/20240109_bayesian-logistic-regression/20240109_bayesian-logistic-regression/</link>
      <pubDate>Tue, 09 Jan 2024 11:57:07 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20240109_bayesian-logistic-regression/20240109_bayesian-logistic-regression/</guid>
      <description>Applying Turing.jl package in Julia for a probabilistic approach to a classification problem on a real-world dataset.</description>
      <content:encoded><![CDATA[<hr>
<h2 id="problem-statement">Problem Statement</h2>
<p>You are interested in studying the factors that influence the likelihood of heart disease among patients.</p>
<p>You have a dataset of 303 patients, each with 14 variables: age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise induced angina, oldpeak, slope, number of major vessels, thalassemia, and diagnosis of heart disease.</p>
<p>You want to use Bayesian logistic regression to model the probability of heart disease (the outcome variable) as a function of some or all of the other variables (the predictor variables).</p>
<p>You also want to compare different models and assess their fit and predictive performance.</p>
<h2 id="bayesian-workflow">Bayesian Workflow</h2>
<p>For this project, I will try to follow this workflow:</p>
<ol>
<li>
<p>Data exploration: Explore the data using descriptive statistics and visualizations to get a sense of the distribution, range, and correlation of the variables. Identify any outliers, missing values, or potential errors in the data. Transform or standardize the variables if needed.</p>
</li>
<li>
<p>Model specification: Specify a probabilistic model that relates the outcome variable to the predictor variables using a logistic regression equation. Choose appropriate priors for the model parameters, such as normal, student-t, or Cauchy distributions. You can use the <code>brms</code> package in Julia to define and fit Bayesian models using a formula syntax similar to <code>lme4</code>. However, try to use <code>Turing.jl</code></p>
</li>
<li>
<p>Model fitting: Fit the model using a sampling algorithm such as Hamiltonian Monte Carlo (HMC) or No-U-Turn Sampler (NUTS). You can use the <code>DynamicHMC</code> or <code>Turing.jl</code> package in Julia to implement these algorithms. Check the convergence and mixing of the chains using diagnostics such as trace plots, autocorrelation plots, effective sample size, and potential scale reduction factor. You can use the <code>MCMCDiagnostics</code> or the included diagnostics features in <code>Turing.jl</code> package in Julia to compute these diagnostics.</p>
</li>
<li>
<p>Model checking: Check the fit and validity of the model using posterior predictive checks, residual analysis, and sensitivity analysis. You can use the <code>PPCheck</code> package in Julia to perform posterior predictive checks, which compare the observed data to data simulated from the posterior predictive distribution. You can use the <code>BayesianRidgeRegression</code> package in Julia to perform residual analysis, which plots the residuals against the fitted values and the predictor variables. You can use the <code>Sensitivity</code> package in Julia to perform sensitivity analysis, which measures how the posterior distribution changes with respect to the prior distribution or the likelihood function.</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># import packages</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">CSV</span><span class="p">,</span> <span class="n">Turing</span><span class="p">,</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">StatsPlots</span><span class="p">,</span> <span class="n">LaTeXStrings</span><span class="p">,</span> <span class="n">Distributions</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Images</span><span class="p">,</span> <span class="n">ImageIO</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">Random</span><span class="o">:</span> <span class="n">seed!</span>
</span></span><span class="line"><span class="cl"><span class="n">seed!</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Random.TaskLocalRNG()
</code></pre>
<h2 id="data-exploration">Data Exploration</h2>
<p>After &ldquo;collecting&rdquo; the data, we may import it and arrange it so we can use it further.</p>
<p>The data set can be found in this <a href="https://www.kaggle.com/datasets/aavigan/cleveland-clinic-heart-disease-dataset">Kaggle link</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s">&#34;data/processed_cleveland.csv&#34;</span><span class="p">,</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">map!</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">!=</span> <span class="mi">0</span> <span class="o">?</span> <span class="mi">1</span> <span class="o">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">num</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">num</span><span class="p">);</span> <span class="c"># make the outcome binary</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>303×14 DataFrame</span></div><div style = "float: right;"><span style = "font-style: italic;">278 rows omitted</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">age</th><th style = "text-align: left;">sex</th><th style = "text-align: left;">cp</th><th style = "text-align: left;">trestbps</th><th style = "text-align: left;">chol</th><th style = "text-align: left;">fbs</th><th style = "text-align: left;">restecg</th><th style = "text-align: left;">thalach</th><th style = "text-align: left;">exang</th><th style = "text-align: left;">oldpeak</th><th style = "text-align: left;">slope</th><th style = "text-align: left;">ca</th><th style = "text-align: left;">thal</th><th style = "text-align: left;">num</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "String1" style = "text-align: left;">String1</th><th title = "String1" style = "text-align: left;">String1</th><th title = "Int64" style = "text-align: left;">Int64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">63</td><td style = "text-align: right;">1</td><td style = "text-align: right;">1</td><td style = "text-align: right;">145</td><td style = "text-align: right;">233</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">150</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2.3</td><td style = "text-align: right;">3</td><td style = "text-align: left;">0</td><td style = "text-align: left;">6</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">67</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">160</td><td style = "text-align: right;">286</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">108</td><td style = "text-align: right;">1</td><td style = "text-align: right;">1.5</td><td style = "text-align: right;">2</td><td style = "text-align: left;">3</td><td style = "text-align: left;">3</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">67</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">120</td><td style = "text-align: right;">229</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">129</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2.6</td><td style = "text-align: right;">2</td><td style = "text-align: left;">2</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: right;">37</td><td style = "text-align: right;">1</td><td style = "text-align: right;">3</td><td style = "text-align: right;">130</td><td style = "text-align: right;">250</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">187</td><td style = "text-align: right;">0</td><td style = "text-align: right;">3.5</td><td style = "text-align: right;">3</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: right;">41</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">130</td><td style = "text-align: right;">204</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">172</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.4</td><td style = "text-align: right;">1</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">6</td><td style = "text-align: right;">56</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">120</td><td style = "text-align: right;">236</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">178</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0.8</td><td style = "text-align: right;">1</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">7</td><td style = "text-align: right;">62</td><td style = "text-align: right;">0</td><td style = "text-align: right;">4</td><td style = "text-align: right;">140</td><td style = "text-align: right;">268</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">160</td><td style = "text-align: right;">0</td><td style = "text-align: right;">3.6</td><td style = "text-align: right;">3</td><td style = "text-align: left;">2</td><td style = "text-align: left;">3</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">8</td><td style = "text-align: right;">57</td><td style = "text-align: right;">0</td><td style = "text-align: right;">4</td><td style = "text-align: right;">120</td><td style = "text-align: right;">354</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">163</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0.6</td><td style = "text-align: right;">1</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">9</td><td style = "text-align: right;">63</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">130</td><td style = "text-align: right;">254</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">147</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.4</td><td style = "text-align: right;">2</td><td style = "text-align: left;">1</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">10</td><td style = "text-align: right;">53</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">140</td><td style = "text-align: right;">203</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">155</td><td style = "text-align: right;">1</td><td style = "text-align: right;">3.1</td><td style = "text-align: right;">3</td><td style = "text-align: left;">0</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">11</td><td style = "text-align: right;">57</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">140</td><td style = "text-align: right;">192</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">148</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0.4</td><td style = "text-align: right;">2</td><td style = "text-align: left;">0</td><td style = "text-align: left;">6</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">12</td><td style = "text-align: right;">56</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">140</td><td style = "text-align: right;">294</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">153</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.3</td><td style = "text-align: right;">2</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">13</td><td style = "text-align: right;">56</td><td style = "text-align: right;">1</td><td style = "text-align: right;">3</td><td style = "text-align: right;">130</td><td style = "text-align: right;">256</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">142</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0.6</td><td style = "text-align: right;">2</td><td style = "text-align: left;">1</td><td style = "text-align: left;">6</td><td style = "text-align: right;">1</td></tr><tr><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td><td style = "text-align: right;">&vellip;</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">292</td><td style = "text-align: right;">55</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">132</td><td style = "text-align: right;">342</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">166</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.2</td><td style = "text-align: right;">1</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">293</td><td style = "text-align: right;">44</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">120</td><td style = "text-align: right;">169</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">144</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2.8</td><td style = "text-align: right;">3</td><td style = "text-align: left;">0</td><td style = "text-align: left;">6</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">294</td><td style = "text-align: right;">63</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">140</td><td style = "text-align: right;">187</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">144</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4.0</td><td style = "text-align: right;">1</td><td style = "text-align: left;">2</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">295</td><td style = "text-align: right;">63</td><td style = "text-align: right;">0</td><td style = "text-align: right;">4</td><td style = "text-align: right;">124</td><td style = "text-align: right;">197</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">136</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0.0</td><td style = "text-align: right;">2</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">296</td><td style = "text-align: right;">41</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">120</td><td style = "text-align: right;">157</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">182</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0.0</td><td style = "text-align: right;">1</td><td style = "text-align: left;">0</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">297</td><td style = "text-align: right;">59</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">164</td><td style = "text-align: right;">176</td><td style = "text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">90</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.0</td><td style = "text-align: right;">2</td><td style = "text-align: left;">2</td><td style = "text-align: left;">6</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">298</td><td style = "text-align: right;">57</td><td style = "text-align: right;">0</td><td style = "text-align: right;">4</td><td style = "text-align: right;">140</td><td style = "text-align: right;">241</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">123</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0.2</td><td style = "text-align: right;">2</td><td style = "text-align: left;">0</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">299</td><td style = "text-align: right;">45</td><td style = "text-align: right;">1</td><td style = "text-align: right;">1</td><td style = "text-align: right;">110</td><td style = "text-align: right;">264</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">132</td><td style = "text-align: right;">0</td><td style = "text-align: right;">1.2</td><td style = "text-align: right;">2</td><td style = "text-align: left;">0</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">300</td><td style = "text-align: right;">68</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">144</td><td style = "text-align: right;">193</td><td style = "text-align: right;">1</td><td style = "text-align: right;">0</td><td style = "text-align: right;">141</td><td style = "text-align: right;">0</td><td style = "text-align: right;">3.4</td><td style = "text-align: right;">2</td><td style = "text-align: left;">2</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">301</td><td style = "text-align: right;">57</td><td style = "text-align: right;">1</td><td style = "text-align: right;">4</td><td style = "text-align: right;">130</td><td style = "text-align: right;">131</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">115</td><td style = "text-align: right;">1</td><td style = "text-align: right;">1.2</td><td style = "text-align: right;">2</td><td style = "text-align: left;">1</td><td style = "text-align: left;">7</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">302</td><td style = "text-align: right;">57</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">130</td><td style = "text-align: right;">236</td><td style = "text-align: right;">0</td><td style = "text-align: right;">2</td><td style = "text-align: right;">174</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0.0</td><td style = "text-align: right;">2</td><td style = "text-align: left;">1</td><td style = "text-align: left;">3</td><td style = "text-align: right;">1</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">303</td><td style = "text-align: right;">38</td><td style = "text-align: right;">1</td><td style = "text-align: right;">3</td><td style = "text-align: right;">138</td><td style = "text-align: right;">175</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0</td><td style = "text-align: right;">173</td><td style = "text-align: right;">0</td><td style = "text-align: right;">0.0</td><td style = "text-align: right;">1</td><td style = "text-align: left;">?</td><td style = "text-align: left;">3</td><td style = "text-align: right;">0</td></tr></tbody></table></div>
<p>In the above data frame, the attributes are as follows:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Variable Name</th>
<th style="text-align:center">Role</th>
<th style="text-align:center">Type</th>
<th style="text-align:center">Demographic</th>
<th style="text-align:center">Description</th>
<th style="text-align:center">Units</th>
<th style="text-align:center">Missing Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">age</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Integer</td>
<td style="text-align:center">Age</td>
<td style="text-align:center"></td>
<td style="text-align:center">years</td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">sex</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Categorical</td>
<td style="text-align:center">Sex</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">cp</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Categorical</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">trestbps</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Integer</td>
<td style="text-align:center"></td>
<td style="text-align:center">resting blood pressure (on admission to the hospital)</td>
<td style="text-align:center">mm Hg</td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">chol</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Integer</td>
<td style="text-align:center"></td>
<td style="text-align:center">serum cholestoral</td>
<td style="text-align:center">mg/dl</td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">fbs</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Categorical</td>
<td style="text-align:center"></td>
<td style="text-align:center">fasting blood sugar &gt; 120 mg/dl</td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">restecg</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Categorical</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">thalach</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Integer</td>
<td style="text-align:center"></td>
<td style="text-align:center">maximum heart rate achieved</td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">exang</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Categorical</td>
<td style="text-align:center"></td>
<td style="text-align:center">exercise induced angina</td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td style="text-align:center">oldpeak</td>
<td style="text-align:center">Feature</td>
<td style="text-align:center">Integer</td>
<td style="text-align:center"></td>
<td style="text-align:center">ST depression induced by exercise relative to rest</td>
<td style="text-align:center"></td>
<td style="text-align:center">no</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Complete attribute documentation:</p>
<pre><code>1. age: age in years
2. sex: sex (1 = male; 0 = female)
3. cp: chest pain type
	- Value 1: typical angina
	- Value 2: atypical angina
	- Value 3: non-anginal pain
	- Value 4: asymptomatic
4. trestbps: resting blood pressure (in mm Hg on admission to the
hospital)
5. chol: serum cholestoral in mg/dl
6.fbs: fasting blood sugar &gt; 120 mg/dl (1 = true; 0 = false)
7. restecg: resting electrocardiographic results
	- Value 0: normal
	- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV)
	- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
8. thalach: maximum heart rate achieved
9. exang: exercise induced angina (1 = yes; 0 = no)
10. oldpeak: ST depression induced by exercise relative to rest
11. slope: the slope of the peak exercise ST segment
	- Value 1: upsloping
	- Value 2: flat
	- Value 3: downsloping
12. ca: number of major vessels (0-3) colored by flourosopy (for calcification of vessels)
13. thal: results of nuclear stress test (3 = normal; 6 = fixed defect; 7 = reversable defect)
14. num: target variable representing diagnosis of heart disease (angiographic disease status) in any major vessel
	- Value 0: &lt; 50% diameter narrowing
	- Value 1: &gt; 50% diameter narrowing
</code></pre>
<h2 id="data-interpretation">Data Interpretation</h2>
<p>After collecting the data, it has been imported as a Data Frame. Now, to understand what we will do with this exercise, we need to analyze the data by means of Bayesian Logistic Regression.</p>
<p>With this type of analysis, we can make predictions on (typically) binary outcomes, based on a set of parameters. In this particular case, we are interested in predicting whether a patient will have heart disease based on a set of parameters such as age, chest pain, blood pressure, etc.</p>
<p>In terms of the data available, we have a set of 303 observations (303 patients) whose symptoms and circumstances have been recorded, and the <strong>outcome</strong> is the heart disease diagnosis. To simplify things, this data set has a binary outcome, i.e. heart disease <em>present/not present</em>.</p>
<p>Additionally, this study is divided in two parts: first, I will set up the logistic regression model to include only one predictor, i.e., <strong>age</strong>. Afterwards, an analysis will be performed including two or more predictors.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># find the range for the age, to set the plot limits below</span>
</span></span><span class="line"><span class="cl"><span class="c"># min_age = minimum(df.age)</span>
</span></span><span class="line"><span class="cl"><span class="n">min_age</span> <span class="o">=</span> <span class="mi">15</span> 
</span></span><span class="line"><span class="cl"><span class="n">max_age</span> <span class="o">=</span> <span class="mi">85</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># visualize data</span>
</span></span><span class="line"><span class="cl"><span class="n">p_data</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">num</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">xlims</span> <span class="o">=</span> <span class="p">(</span><span class="n">min_age</span><span class="p">,</span> <span class="n">max_age</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">	<span class="n">color</span> <span class="o">=</span> <span class="ss">:red</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">markersize</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Probability of Heart Disease&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">xlabel</span> <span class="o">=</span> <span class="s">&#34;Age (years)&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">ylabel</span> <span class="o">=</span> <span class="s">&#34;Probability of Heart Disease&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">widen</span> <span class="o">=</span> <span class="nb">true</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">dpi</span> <span class="o">=</span> <span class="mi">150</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240109_Bayesian_Logistic_Regression/output_7_0.svg" type="" alt="svg"  /></p>
<h2 id="model-specification">Model Specification</h2>
<p>In this stage of the workflow, we will specify the Bayesian model and then use <code>Turing.jl</code> to program it in Julia.</p>
<p>The model I will use for this analysis is a Bayesian Logistic Regression model, which relates the probability of heart disease to a <em>linear combination of the predictor variables</em>, using a logistic function. The model can be written as:</p>
<p>$$\begin{aligned}
y_i &amp;\sim Bernoulli(p_i) \\
p_i &amp;= \frac{1}{1+e^{-\eta_i}} \\
\eta_i &amp;= \alpha + {\beta_1 x_{i,1}} + {\beta_2 x_{i,2}} + \ldots + {\beta_{13} x_{i,13}} \\
\alpha &amp;\sim \mathcal{N}(\mu_\alpha,\sigma_\sigma) \\
\beta_j &amp;\sim \mathcal{N}(\mu_{\beta},\sigma_{\beta}) \\
\end{aligned}$$</p>
<p>where $y_i$ is the outcome for the <em>i-th</em> patient, $p_i$ is the probability of heart disease for the <em>i-th</em> patient, $\eta_i$ is the linear predictor for the <em>i-th</em> patient, $\alpha$ and $\beta_j$ are the intercept and coefficient for the <em>j-th</em> predictor variable, respectively, and $x_{ij}$ is the value of the <em>j-th</em> predictor variable for the <em>i-th</em> patient.</p>
<p>The assumptions that I am making are:</p>
<ol>
<li>The outcome variable follows a Bernoulli distribution, i.e. $y_i \sim Bernoulli(p_i)$, which is appropriate for binary outcomes</li>
<li>The predictor variables are linearly related to the log-odds of the outcome variable, i.e. $\log(\frac{p}{1-p})$ which is a common assumption for logistic regression models</li>
<li>The prior distributions for the model parameters are uniform, which are weakly informative and reflect my prior beliefs about the plausible range of the parameters</li>
</ol>
<p>Regarding point (2):</p>
<p>That statement means that the log-odds of the outcome variable (the log of the odds ratio) can be expressed as a linear function of the predictor variables. Mathematically, this can be written as:</p>
<p>$$\log(\frac{p}{1-p}) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k$$</p>
<p>where $p$ is the probability of the outcome variable being 1, $x_1, x_2, \ldots, x_k$ are the predictor variables, and $\alpha, \beta_1, \beta_2, \ldots, \beta_k$ are the coefficients (parameters).</p>
<p>This assumption implies that the effect of each predictor variable on the log-odds of the outcome variable is contant, regardless of the values of the other predictor variables. It also implies that the relationship between the predictor variables and the probability of the outcome variable is non-linear, as the probability is obtained by applying the inverse of the log-odds function, which is the logistic function:</p>
<p>$$p = \frac{1}{1+e^{-(\alpha + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k)}}$$</p>
<p>The logistic function is an S-shaped curve that maps any real number to a value between 0 and 1. It has the property that as the linear predictor increases, the probability approaches 1, and as the linear predictor decreases, the probability approaches 0.</p>
<h3 id="model-specification-using-turingjl">Model Specification Using <code>Turing.jl</code></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># define the Bayesian model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">logit_model</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">disease</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># priors</span>
</span></span><span class="line"><span class="cl">	<span class="n">α</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">β</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># likelihood</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">η</span> <span class="o">=</span> <span class="n">α</span> <span class="o">.+</span> <span class="n">β</span><span class="o">.*</span><span class="n">predictors</span>
</span></span><span class="line"><span class="cl">	<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">./</span> <span class="p">(</span><span class="mi">1</span> <span class="o">.+</span> <span class="n">exp</span><span class="o">.</span><span class="p">(</span><span class="o">-</span><span class="n">η</span><span class="p">))</span>     <span class="c"># remember to include the &#34;.&#34;!</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">disease</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>logit_model (generic function with 2 methods)
</code></pre>
<h4 id="crank-up-the-bayes">Crank up the Bayes!</h4>
<p>Run the model using <code>sample(model, sampler, opt_argument, samples, chains)</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># infer posterior probability</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">logit_model</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">num</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="mi">1_000</span>
</span></span><span class="line"><span class="cl"><span class="n">num_chains</span> <span class="o">=</span> <span class="mi">8</span> 		<span class="c"># set the number of chains</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">MCMCThreads</span><span class="p">(),</span> <span class="n">samples</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.025
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.025
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.0125
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.025
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.05
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.025
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.025
[32mSampling (8 threads): 100%|█████████████████████████████| Time: 0:00:01[39m





Chains MCMC chain (1000×14×8 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 8
Samples per chain = 1000
Wall duration     = 13.18 seconds
Compute duration  = 100.1 seconds
parameters        = α, β
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m  ess_tail [0m [1m    rhat [0m [1m[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m   Float64 [0m [90m Float64 [0m [90m[0m ⋯

           α   -3.0326    0.7453    0.0210   1242.6057   1246.3034    1.0043   ⋯
           β    0.0524    0.0134    0.0004   1224.4182   1259.7727    1.0037   ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

           α   -4.4814   -3.5432   -3.0127   -2.5183   -1.5973
           β    0.0264    0.0432    0.0521    0.0617    0.0789
</code></pre>
<p><strong>NOTE</strong>: The above routine employs the <code>MCMCThreads()</code> method to sample multiple chains. However, to implement this, one needs to change the environment variables for the number of threads Julia can use. These two discussions might shed some light as to how to achieve this:</p>
<ol>
<li><a href="https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading">https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading</a></li>
<li><a href="https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794">https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794</a></li>
</ol>
<p>Of course, if you don&rsquo;t want to bother, then just change the last two functional lines in the cell above so that they read:</p>
<pre><code># set number of chains - comment this out:
# num_chains = 8

# crank up the Bayes! - delete MCMCThreads() and num_chains
chain = sample(model, sampler, samples)
</code></pre>
<h4 id="plot-the-mcmc-diagnostics">Plot the MCMC Diagnostics</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">150</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240109_Bayesian_Logistic_Regression/output_15_0.svg" type="" alt="png"  /></p>
<h4 id="get-the-summary-statistics">Get the Summary Statistics</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">summarystats</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m  ess_tail [0m [1m    rhat [0m [1m[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m   Float64 [0m [90m Float64 [0m [90m[0m ⋯

           α   -3.0326    0.7453    0.0210   1242.6057   1246.3034    1.0043   ⋯
           β    0.0524    0.0134    0.0004   1224.4182   1259.7727    1.0037   ⋯
[36m                                                                1 column omitted[0m
</code></pre>
<h3 id="plot-and-interpret-the-results">Plot and Interpret the Results</h3>
<p>Ok, how do we interpret the results from a Bayesian approach? Let&rsquo;s start by plotting the results. This will help us understand not only the results, but really grasp the power of a Bayesian model in action.</p>
<p>From a frequentist or a machine learning approach, we would expect to find a function that models the data the best possible way, i.e. fit a model. If we were to visualize it, we would see one single sigmoid curve trying its best to explain the data.</p>
<p>How about this chart here, though? This chart is a collection of possible outcomes given that the <em>parameters</em> $\alpha$ and $\beta$ in this case, are modeled as random variables with some probability distribution. Therefore, there is an uncertainty associated with them. This uncertainty is naturally <em>propagated</em> onto the sigmoid function. Therefore, there is also an uncertainty associated with that sigmoid curve that we are trying to model.</p>
<p>Again, below we can see a collection of possible outcomes given the parameter sample space. There is a darker region where most sigmoid functions turned out, and these tend to be the most probable sigmoid functions, or, in other words, these sigmoid functions are the most probable functions that could fit the data, considering the distributions of the parameters too!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="kt">Int</span><span class="p">(</span><span class="n">samples</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>100
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">x_line</span> <span class="o">=</span> <span class="mi">15</span><span class="o">:</span><span class="mi">1</span><span class="o">:</span><span class="n">max_age</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">    <span class="n">b</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">m</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">line</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span><span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">line</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">plot!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="n">x_line</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span> <span class="ss">:blue</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">150</span>
</span></span><span class="line"><span class="cl">	<span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p_data</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240109_Bayesian_Logistic_Regression/output_20_0.svg" type="" alt="png"  /></p>
<h3 id="making-predictions">Making Predictions</h3>
<p>So why go through all this trouble, you might be asking. Well, one of the reasons we want to use probabilistic models is, first, to make predictions. But I would go further than that: these models are useful when making informed decisions. Let&rsquo;s try this out.</p>
<p>Let&rsquo;s make predictions for different arbitrary ages (50, 60, 70, 80, 20):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">new_Age</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">p_disease</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="nb">missing</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">new_Age</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">logit_model</span><span class="p">(</span><span class="n">new_Age</span><span class="p">,</span> <span class="n">p_disease</span><span class="p">),</span> <span class="n">chain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">summarystats</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m [0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m [0m ⋯

  disease[1]    0.3855    0.4867    0.0055   7711.3762        NaN    0.9998    ⋯
  disease[2]    0.5258    0.4994    0.0055   8284.1301        NaN    0.9998    ⋯
  disease[3]    0.6432    0.4791    0.0056   7441.4457        NaN    1.0002    ⋯
  disease[4]    0.7555    0.4298    0.0050   7352.4368        NaN    0.9998    ⋯
  disease[5]    0.1224    0.3277    0.0039   7016.6404        NaN    1.0004    ⋯
[36m                                                                1 column omitted[0m
</code></pre>
<h4 id="interpreting-the-predictions">Interpreting the predictions</h4>
<p>The last operations make predictions of heart diseased based <em>on age only</em>. What the predictions mean is that, given the data, the probability distribution of an individual of age 50 to have heart disease has a mean of 0.379, and a standard deviation of 0.485 (this is highly uncertain, by the way).</p>
<p>Similarly, a 20-year-old individual has a probability with a mean of 0.13 and standard deviation of 0.336 of having heart disease.</p>
<p>These statistics are extremely powerful when you are trying to make decisions, such as when diagnosing Heart Disease. It stands to reason that, if you were a physician, you want to know what your model says might be wrong (or not) with your patient, but you also want to know how much you can trust that prediction.</p>
<p>If your model classifies Patient X as having heart disease, you would probably want to know how sure you are of this. And this certainty comes partially from&hellip; you guessed it: your priors <em>and</em> the data.</p>
<p>In the plot below, we can see the where the predictions lie. Note that these probabilities are on a continuum given by the sigmoid function. But we want our final decision to be a yes or a no. To do that, we need to set a decision threshold.</p>
<p>We will do that at the end of the next section.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">new_Age</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">pred_mean</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">pred_plot</span> <span class="o">=</span> <span class="n">scatter!</span><span class="p">(</span><span class="n">p_data</span><span class="p">,</span> <span class="p">(</span><span class="n">new_Age</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pred_mean</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p_data</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240109_Bayesian_Logistic_Regression/output_24_0.svg" type="" alt="png"  /></p>
<h2 id="model-specification-using-multiple-predictors">Model Specification Using Multiple Predictors</h2>
<h3 id="some-data-cleaning">Some Data Cleaning</h3>
<p>In this part, I am using the <code>Turing.jl</code> documentation tutorial found in <a href="https://turinglang.org/dev/tutorials/02-logistic-regression/">https://turinglang.org/dev/tutorials/02-logistic-regression/</a>.</p>
<p>In the tutorial, they quite rightly incorporate a train/test split, and data normalization, which is the recommended practice. I didn&rsquo;t do it in the first part of this tutorial to keep things simple!</p>
<p>Here is how they handle the split and the data normalization using <code>MLUtils</code>.</p>
<pre><code>function split_data(df, target; at=0.70)
    shuffled = shuffleobs(df)
    return trainset, testset = stratifiedobs(row -&gt; row[target], shuffled; p=at)
end

features = [:StudentNum, :Balance, :Income]
numerics = [:Balance, :Income]
target = :DefaultNum

trainset, testset = split_data(data, target; at=0.05)
for feature in numerics
    μ, σ = rescale!(trainset[!, feature]; obsdim=1)
    rescale!(testset[!, feature], μ, σ; obsdim=1)
end

# Turing requires data in matrix form, not dataframe
train = Matrix(trainset[:, features])
test = Matrix(testset[:, features])
train_label = trainset[:, target]
test_label = testset[:, target];
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">MLDataUtils</span><span class="o">:</span> <span class="n">shuffleobs</span><span class="p">,</span> <span class="n">stratifiedobs</span><span class="p">,</span> <span class="n">rescale!</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="n">StatsFuns</span> <span class="c"># we introduce this package so we can later call the </span>
</span></span><span class="line"><span class="cl">                <span class="c"># logistic function directly instead of defining it manually as before</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">function</span> <span class="n">split_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">;</span> <span class="n">at</span><span class="o">=</span><span class="mf">0.70</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">shuffled</span> <span class="o">=</span> <span class="n">shuffleobs</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">stratifiedobs</span><span class="p">(</span><span class="n">row</span> <span class="o">-&gt;</span> <span class="n">row</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">shuffled</span><span class="p">;</span> <span class="n">p</span><span class="o">=</span><span class="n">at</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="ss">:age</span><span class="p">,</span> <span class="ss">:cp</span><span class="p">,</span> <span class="ss">:chol</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">target</span> <span class="o">=</span> <span class="ss">:num</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># convert the feature columns to float64 to ensure compatibility with rescale!</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">feature</span> <span class="k">in</span> <span class="n">features</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">float</span><span class="o">.</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">feature</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">feature</span> <span class="k">in</span> <span class="n">features</span>
</span></span><span class="line"><span class="cl">    <span class="n">μ</span><span class="p">,</span> <span class="n">σ</span> <span class="o">=</span> <span class="n">rescale!</span><span class="p">(</span><span class="n">trainset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">feature</span><span class="p">];</span> <span class="n">obsdim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rescale!</span><span class="p">(</span><span class="n">testset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">feature</span><span class="p">],</span> <span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">;</span> <span class="n">obsdim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="c"># Turing requires data in matrix form, not dataframe</span>
</span></span><span class="line"><span class="cl"><span class="n">train</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">(</span><span class="n">trainset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">features</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">test</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">(</span><span class="n">testset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">features</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">train_label</span> <span class="o">=</span> <span class="n">trainset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">target</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">test_label</span> <span class="o">=</span> <span class="n">testset</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="n">target</span><span class="p">];</span>
</span></span></code></pre></div><h3 id="inference">Inference</h3>
<p>Now that our data is formatted, we can perform our Bayesian logistic regression with multiple predictors: using chest pain (cp), age (age), resting bloodpressure (tresttbps) and cholesterol (chol) levels.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">logreg_multi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># priors</span>
</span></span><span class="line"><span class="cl">	<span class="n">intercept</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">age</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">cp</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">chol</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">n</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">n</span>
</span></span><span class="line"><span class="cl">		<span class="c"># call the logistic function directly, instead of manually</span>
</span></span><span class="line"><span class="cl">		<span class="n">v</span> <span class="o">=</span> <span class="n">logistic</span><span class="p">(</span><span class="n">intercept</span> <span class="o">+</span> <span class="n">age</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">cp</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">chol</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">		<span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>logreg_multi (generic function with 2 methods)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">train</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">train_label</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">println</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="n">size</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>(212, 3)(91, 3)
</code></pre>
<p>Now we build the model and create the chain:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">model_multi</span> <span class="o">=</span> <span class="n">logreg_multi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">chain_multi</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model_multi</span><span class="p">,</span> <span class="n">NUTS</span><span class="p">(),</span> <span class="n">MCMCThreads</span><span class="p">(),</span> <span class="mi">2_000</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="c"># select 2000 samples directly</span>
</span></span></code></pre></div><pre><code>[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 1.6
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.8
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.8
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.8
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.8
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 1.6
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 0.8
[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 1.6





Chains MCMC chain (2000×16×8 Array{Float64, 3}):

Iterations        = 1001:1:3000
Number of chains  = 8
Samples per chain = 2000
Wall duration     = 11.32 seconds
Compute duration  = 87.27 seconds
parameters        = intercept, age, cp, chol
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m   ess_bulk [0m [1m   ess_tail [0m [1m    rhat[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m    Float64 [0m [90m    Float64 [0m [90m Float64[0m ⋯

   intercept   -0.2821    0.1647    0.0012   20113.9419   13042.8456    1.0003 ⋯
         age    0.6003    0.1760    0.0013   18327.5449   12926.7418    1.0001 ⋯
          cp    1.0699    0.1922    0.0014   19583.1899   13534.2405    0.9999 ⋯
        chol   -0.0073    0.1641    0.0012   18280.4944   12242.8280    1.0004 ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

   intercept   -0.6118   -0.3923   -0.2817   -0.1711    0.0388
         age    0.2645    0.4792    0.5964    0.7178    0.9575
          cp    0.7106    0.9372    1.0636    1.1963    1.4603
        chol   -0.3283   -0.1177   -0.0080    0.1025    0.3151
</code></pre>
<h3 id="plot-the-mcmc-diagnostics-1">Plot the MCMC Diagnostics</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain_multi</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20240109_Bayesian_Logistic_Regression/output_34_0.svg" type="" alt="png"  /></p>
<h3 id="summary-statistics">Summary Statistics</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">summarystats</span><span class="p">(</span><span class="n">chain_multi</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m   ess_bulk [0m [1m   ess_tail [0m [1m    rhat[0m ⋯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m    Float64 [0m [90m    Float64 [0m [90m Float64[0m ⋯

   intercept   -0.2821    0.1647    0.0012   20113.9419   13042.8456    1.0003 ⋯
         age    0.6003    0.1760    0.0013   18327.5449   12926.7418    1.0001 ⋯
          cp    1.0699    0.1922    0.0014   19583.1899   13534.2405    0.9999 ⋯
        chol   -0.0073    0.1641    0.0012   18280.4944   12242.8280    1.0004 ⋯
[36m                                                                1 column omitted[0m
</code></pre>
<h2 id="thank-you">Thank you!</h2>
<p>And that concludes this little tutorial showcasing the power of a Bayesian model and the fun of using Julia. Thank you for stopping by!</p>
<p>Victor Flores</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Bayesian Linear Regression with Julia and Turing.jl</title>
      <link>http://localhost:1313/posts/20231110_bayesian_linear_regression_julia/20231110_bayesian_linear_regression_julia/</link>
      <pubDate>Fri, 10 Nov 2023 14:53:29 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/20231110_bayesian_linear_regression_julia/20231110_bayesian_linear_regression_julia/</guid>
      <description>Learn the basics of Bayesian linear regression using Julia and Turing.jl. This tutorial covers model formulation, implementation, and interpretation through a practical example.</description>
      <content:encoded><![CDATA[<hr>
<h2 id="finding-a-linear-relationship-between-height-and-weight-using-bayesian-methods">Finding a Linear Relationship Between Height and Weight Using Bayesian Methods</h2>
<h3 id="problem-statement">Problem Statement</h3>
<p>You have some data on the relationship between the height and weight of some people, and you want to fit a linear model of the form:</p>
<p>$$y = \alpha + \beta x + \varepsilon$$</p>
<p>where $y$ is the weight, $x$ is the height, $\alpha$ is the intercept, $\beta$ is the slope, and $\varepsilon$ is the error term. You want to use Bayesian inference to estimate the posterior distributions of $\alpha$ and $\beta$ given the data and some prior assumptions. You also want to use probabilistic programming to implement the Bayesian model and perform inference using a package like <code>Turing.jl</code>.</p>
<p>Your task is to write the code in Julia that can generate some synthetic data (or use an existing data set), define the Bayesian linear regression model, and sample from the posterior distributions using Hamiltonian Monte Carlo (HMC).</p>
<h6 id="credit">Credit</h6>
<p>This exercise is heavily inspired, and mostly taken from, the doggo&rsquo;s tutorial. Please visit his <a href="https://www.youtube.com/@doggodotjl">Youtube channel here</a>, it&rsquo;s an amazing starting point for Julia programming!</p>
<h3 id="import-the-necessary-packages">Import the Necessary Packages</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">Turing</span><span class="p">,</span> <span class="n">CSV</span><span class="p">,</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">Plots</span><span class="p">,</span> <span class="n">StatsPlots</span><span class="p">,</span> <span class="n">LaTeXStrings</span>
</span></span></code></pre></div><h3 id="bayesian-workflow">Bayesian Workflow</h3>
<p>For this exercise, I will implement the following workflow:</p>
<ul>
<li>Collect data: this will be implemented by downloading the relevant data</li>
<li>Build a Bayesian model: will use <code>Turing.jl</code> to build the model</li>
<li>Infer the posterior distributions of the parameters $\alpha$ and $\beta$</li>
<li>Evaluate the fit of the model</li>
</ul>
<h4 id="collecting-the-data">Collecting the data</h4>
<p>The data to be analyzed will be the height vs. weight data from:
<a href="https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset">https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset</a>.</p>
<p>Since the dataset is too large, we will select only the first 1000 entries.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># collect data</span>
</span></span><span class="line"><span class="cl"><span class="c"># this data set was downloaded from kaggle:</span>
</span></span><span class="line"><span class="cl"><span class="c"># https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">joinpath</span><span class="p">(</span><span class="s">&#34;data&#34;</span><span class="p">,</span> <span class="s">&#34;SOCR-HeightWeight.csv&#34;</span><span class="p">),</span> <span class="n">DataFrame</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c"># select only 100 entries</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">1000</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">first</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>5×3 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Index</th><th style = "text-align: left;">Height(Inches)</th><th style = "text-align: left;">Weight(Pounds)</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">1</td><td style = "text-align: right;">65.7833</td><td style = "text-align: right;">112.993</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">2</td><td style = "text-align: right;">71.5152</td><td style = "text-align: right;">136.487</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">3</td><td style = "text-align: right;">69.3987</td><td style = "text-align: right;">153.027</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: right;">4</td><td style = "text-align: right;">68.2166</td><td style = "text-align: right;">142.335</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: right;">5</td><td style = "text-align: right;">67.7878</td><td style = "text-align: right;">144.297</td></tr></tbody></table></div>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># change the column headers for easier access</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">colnames</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#34;index&#34;</span><span class="p">,</span><span class="s">&#34;height&#34;</span><span class="p">,</span><span class="s">&#34;weight&#34;</span><span class="p">];</span> <span class="n">rename!</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="kt">Symbol</span><span class="o">.</span><span class="p">(</span><span class="n">colnames</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">first</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span></code></pre></div><div><div style = "float: left;"><span>5×3 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">index</th><th style = "text-align: left;">height</th><th style = "text-align: left;">weight</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">1</td><td style = "text-align: right;">65.7833</td><td style = "text-align: right;">112.993</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">2</td><td style = "text-align: right;">71.5152</td><td style = "text-align: right;">136.487</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">3</td><td style = "text-align: right;">69.3987</td><td style = "text-align: right;">153.027</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: right;">4</td><td style = "text-align: right;">68.2166</td><td style = "text-align: right;">142.335</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: right;">5</td><td style = "text-align: right;">67.7878</td><td style = "text-align: right;">144.297</td></tr></tbody></table></div>
<h4 id="visualizing-the-data">Visualizing the Data</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot_data</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Height vs. Weight&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">xlabel</span> <span class="o">=</span> <span class="s">&#34;Height (in)&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="n">ylabel</span> <span class="o">=</span> <span class="s">&#34;Weight (lb)&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20231110_Bayesian_Linear_Regression_Julia/output_9_0.svg" type="" alt="svg"  /></p>
<h4 id="building-a-bayesian-model-with-turingjl">Building a Bayesian model with <code>Turing.jl</code>.</h4>
<p>First, we assume that the weight is a variable dependent on the height. Thus, we can express the Bayesian model as:</p>
<p>$$y\sim N(\alpha + \beta^{T}\mathbf{X}, \sigma^2)$$</p>
<p>The above means that we assume that the data follows a normal distribution (in this case, a multivariate normal distribution), whose standard deviation is σ and its mean is the linear relationship $\alpha + \beta^{T}\mathbf{X}$.</p>
<p>Next, we need to assign priors to the variables $\alpha$, $\beta$ and $\sigma^2$. The latter is a measure of the uncertainty in <em>the model</em>.</p>
<p>So, the priors will be assigned as follows:</p>
<p>$$\alpha \sim N(0,10)$$
$$\beta \sim U(0,50)$$
$$\sigma^{2} \sim TN(0,100;0,\infty)$$</p>
<p>The last distribution is a <em>truncated normal distribution</em> bounded from 0 to $\infty$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="nd">@model</span> <span class="k">function</span> <span class="n">blr</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># priors:</span>
</span></span><span class="line"><span class="cl">	<span class="n">α</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="c"># intercept</span>
</span></span><span class="line"><span class="cl">	<span class="n">β</span> <span class="o">~</span> <span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">σ</span> <span class="o">~</span> <span class="n">truncated</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">);</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c"># variance standard distribution</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># likelihood</span>
</span></span><span class="line"><span class="cl">	<span class="c"># the likelihood in this case means that I assume that the data follows a</span>
</span></span><span class="line"><span class="cl">	<span class="c"># multivariate normal distribution, whose uncertainty is σ, and its mean is the linear relationship:</span>
</span></span><span class="line"><span class="cl">	<span class="n">avg_weight</span> <span class="o">=</span> <span class="n">α</span> <span class="o">.+</span> <span class="p">(</span><span class="n">β</span><span class="o">.*</span><span class="n">height</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c"># build the model</span>
</span></span><span class="line"><span class="cl">	<span class="n">weight</span> <span class="o">~</span> <span class="n">MvNormal</span><span class="p">(</span><span class="n">avg_weight</span><span class="p">,</span> <span class="n">σ</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><pre><code>blr (generic function with 2 methods)
</code></pre>
<p>The next step is to perform Bayesian inference. <em>Crank up the Bayes!</em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># crank up the bayes!</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">blr</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">NUTS</span><span class="p">(),</span> <span class="n">samples</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>[36m[1m┌ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1m└ [22m[39m  ϵ = 9.765625e-5
[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:11[39m9m





Chains MCMC chain (1000×15×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 31.4 seconds
Compute duration  = 31.4 seconds
parameters        = α, β, σ
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m     mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m [0m ⋯
 [90m     Symbol [0m [90m  Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m [0m ⋯

           α   -34.8414    7.6414    0.4117   344.5155   365.1189    1.0038    ⋯
           β     2.3859    0.1124    0.0060   345.5269   345.0618    1.0039    ⋯
           σ    10.3030    0.2239    0.0100   509.4680   389.9078    1.0016    ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m     2.5% [0m [1m    25.0% [0m [1m    50.0% [0m [1m    75.0% [0m [1m    97.5% [0m
 [90m     Symbol [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m

           α   -49.8948   -39.7950   -34.9188   -29.8116   -19.8403
           β     2.1673     2.3108     2.3872     2.4580     2.6100
           σ     9.8649    10.1550    10.3018    10.4554    10.7449
</code></pre>
<h4 id="visualizing-the-mcmc-diagnostics-and-summarizing-the-results">Visualizing the MCMC Diagnostics and Summarizing the Results</h4>
<p>Now that we have performed Bayesian inference using the <code>NUTS()</code> algorithm, we can visualize the results. Addisionally, call for a summary of the statistics of the inferred posterior distributions of $\theta$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">summarize</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><pre><code> [1m parameters [0m [1m     mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m [0m ⋯
 [90m     Symbol [0m [90m  Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m [0m ⋯

           α   -34.8414    7.6414    0.4117   344.5155   365.1189    1.0038    ⋯
           β     2.3859    0.1124    0.0060   345.5269   345.0618    1.0039    ⋯
           σ    10.3030    0.2239    0.0100   509.4680   389.9078    1.0016    ⋯
[36m                                                                1 column omitted[0m
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20231110_Bayesian_Linear_Regression_Julia/output_16_0.svg" type="" alt="svg"  /></p>
<h5 id="visualizing-the-results">Visualizing the results</h5>
<p>It is worth noting that the results from a Bayesian Linear Regression is not one single regression line, but many. From PyMC&rsquo;s <a href="https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/GLM_linear.html">Generalized Linear Regression tutorial</a>:</p>
<blockquote>
<p>In GLMs, we do not only have one best fitting regression line, but many. A posterior predictive plot takes multiple samples from the posterior (intercepts and slopes) and plots a regression line for each of them. We can manually generate these regression lines using the posterior samples directly.</p>
</blockquote>
<p>What this means is that if we want to visualize all the lines that are generated by the parameter posterior distribution sample pool, we need to generate one line per sample set, and then we can plot them all. This procedure is executed next.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="c"># plot all the sample regressions</span>
</span></span><span class="line"><span class="cl"><span class="c"># this method was taken from: https://www.youtube.com/watch?v=EgrrtZEVOv0&amp;t=1113s</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">samples</span>
</span></span><span class="line"><span class="cl">	<span class="n">α</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>    <span class="c">#chain[row, column, chain_ID]</span>
</span></span><span class="line"><span class="cl">	<span class="n">β</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">σ²</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">plot!</span><span class="p">(</span><span class="n">plot_data</span><span class="p">,</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="n">legend</span> <span class="o">=</span> <span class="nb">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="c"># samples</span>
</span></span><span class="line"><span class="cl">		<span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="ss">:orange</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="c"># error</span>
</span></span><span class="line"><span class="cl">        <span class="n">ribbon</span> <span class="o">=</span> <span class="n">σ²</span><span class="p">,</span> <span class="n">fillalpha</span> <span class="o">=</span> <span class="mf">0.002</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>	
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot_data</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20231110_Bayesian_Linear_Regression_Julia/output_18_0.svg" type="" alt="svg"  /></p>
<h3 id="using-the-regression-model-to-make-predictions">Using the Regression Model to Make Predictions</h3>
<p>Select the heights for which we want to predict the weights and then run the prediction command from <code>Turing</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">pred_height</span> <span class="o">=</span> <span class="p">[</span><span class="mi">62</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span> <span class="mi">67</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">blr</span><span class="p">(</span><span class="n">pred_height</span><span class="p">,</span> <span class="nb">missing</span><span class="p">),</span> <span class="n">chain</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Chains MCMC chain (1000×6×1 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 1
Samples per chain = 1000
parameters        = weight[1], weight[2], weight[3], weight[4], weight[5], weight[6]
internals         = 

Summary Statistics
 [1m parameters [0m [1m     mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m[0m ⋯
 [90m     Symbol [0m [90m  Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m[0m ⋯

   weight[1]   113.6815   10.3344    0.3270    997.5393   947.2109    0.9993   ⋯
   weight[2]   165.3164   10.8352    0.3744    832.5405   818.6640    1.0008   ⋯
   weight[3]   143.8911   10.5355    0.3461    929.5467   874.2977    0.9993   ⋯
   weight[4]   132.3417   10.4836    0.3448    921.6347   943.0320    1.0007   ⋯
   weight[5]   134.7606   10.7046    0.3350   1023.8876   977.6814    1.0025   ⋯
   weight[6]   124.9423   10.2245    0.3247    993.9282   867.7391    0.9991   ⋯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m     2.5% [0m [1m    25.0% [0m [1m    50.0% [0m [1m    75.0% [0m [1m    97.5% [0m
 [90m     Symbol [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m

   weight[1]    93.9378   106.3972   113.6943   120.8093   134.9264
   weight[2]   142.4871   158.4933   165.5406   172.7313   184.7437
   weight[3]   122.8292   137.0108   144.0339   151.1920   164.2645
   weight[4]   111.8872   125.3733   132.1726   139.2690   153.7222
   weight[5]   113.9147   127.4356   135.0149   142.1375   154.5537
   weight[6]   105.3221   118.0098   125.1640   131.6011   145.2976
</code></pre>
<h4 id="visualize-the-distributions-of-the-predicted-weights">Visualize the Distributions of the Predicted Weights</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></span></code></pre></div><p><img loading="lazy" src="/images/20231110_Bayesian_Linear_Regression_Julia/output_22_0.svg" type="" alt="svg"  /></p>
<p>Finally, to obtain a point estimate, compute the mean weight prediction for each height.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-julia" data-lang="julia"><span class="line"><span class="cl"><span class="n">mean_predictions</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Mean
 [1m parameters [0m [1m     mean [0m
 [90m     Symbol [0m [90m  Float64 [0m

   weight[1]   113.6815
   weight[2]   165.3164
   weight[3]   143.8911
   weight[4]   132.3417
   weight[5]   134.7606
   weight[6]   124.9423
</code></pre>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
