[{"content":"\nProblem Statement In this notebook, we will explore the relationship between height and weight using Bayesian linear regression. Our goal is to fit a linear model of the form:\n$$ y = \\alpha + \\beta x + \\varepsilon $$\nwhere:\n$y$ represents the weight, $x$ represents the height, $\\alpha$ is the intercept, $\\beta$ is the slope, $\\varepsilon$ is the error term, modeled as Gaussian white noise, i.e., $\\varepsilon \\sim \\mathcal{N}(0, \\sigma)$, where $\\sigma$ is the standard deviation of the noise. We will use Bayesian inference to estimate the posterior distributions of $\\alpha$ and $\\beta$ given our data and prior assumptions. Bayesian methods provide a natural way to quantify uncertainty in our parameter estimates and predictions.\nApproach To achieve our goal, we will:\nLoad Real Data: We will use an actual dataset representing the heights and weights of individuals, sourced from Kaggle. Define the Bayesian Model: Using the probabilistic programming package PyMC, we will define our Bayesian linear regression model, specifying our priors for $\\alpha$, $\\beta$, and $\\sigma$. Perform Inference: We will use Markov Chain Monte Carlo (MCMC) algorithms, such as the No-U-Turn Sampler (NUTS), to sample from the posterior distributions of our model parameters. Visualization and Prediction: We will visualize the results, including the regression lines sampled from the posterior, the uncertainty intervals, and make predictions on new, unobserved data points. Reference This notebook is inspired by examples from the PyMC documentation, specifically the Generalized Linear Regression tutorial. It also builds upon a similar implementation in Julia using Turing.jl. This PyMC recreation aims at providing a more complete illustration of the use of probabilistic programming languages.\nInitial setup Import the necessary packages.\nAdditionally, this notebook is supposed to be used in Google Colab. The data set (CSV) file is hosted in a private github repo. Therefore, include the github cloning to the temporary session so that the data can be accessed and used in the Colab session.\nimport os import arviz as az import pymc as pm import pandas as pd import xarray as xr import numpy as np import matplotlib.pyplot as plt %matplotlib inline plt.rcParams[\u0026#39;text.usetex\u0026#39;] = True plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#39;STIXGeneral\u0026#39; Bayesian Workflow For this exercise, I will implement the following workflow:\nCollect data: this will be implemented by downloading the relevant data set Build a Bayesian model: this will be built using PyMC Infer the posterior distributions of the parameters $\\alpha$ and $\\beta$, as well as the model noise Evaluate the fit of the model Collecting the data The data to be analyzed will be the height vs. weight data from https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset\n# load the data and print the header csv_path = \u0026#39;data/SOCR-HeightWeight.csv\u0026#39; data = pd.read_csv(csv_path) data.head() Index\rHeight(Inches)\rWeight(Pounds)\r0\r1\r65.78331\r112.9925\r1\r2\r71.51521\r136.4873\r2\r3\r69.39874\r153.0269\r3\r4\r68.21660\r142.3354\r4\r5\r67.78781\r144.2971\rLet\u0026rsquo;s instead work with the International System.\nConvert the values to centimeters and kilograms.\n# Renaming columns 2 and 3 new_column_names = {data.columns[1]: \u0026#39;Height (cm)\u0026#39;, data.columns[2]: \u0026#39;Weight (kg)\u0026#39;} data.rename(columns = new_column_names, inplace = True) # convert the values to SI units data[data.columns[1]] = data[data.columns[1]]*2.54 data[data.columns[2]] = data[data.columns[2]]*0.454 # assign the relevant data to variables for easier manipulation height = data[\u0026#39;Height (cm)\u0026#39;][:1000] weight = data[\u0026#39;Weight (kg)\u0026#39;][:1000] data.head() Index\rHeight (cm)\rWeight (kg)\r0\r1\r167.089607\r51.298595\r1\r2\r181.648633\r61.965234\r2\r3\r176.272800\r69.474213\r3\r4\r173.270164\r64.620272\r4\r5\r172.181037\r65.510883\rVisualize the data # scatter plot of the data plt.scatter(height, weight, s = 20, edgecolor = \u0026#39;black\u0026#39;, alpha = 0.5) plt.title(\u0026#39;Height vs. Weight\u0026#39;) plt.xlabel(\u0026#39;Height (cm)\u0026#39;) plt.ylabel(\u0026#39;Weight (kg)\u0026#39;) plt.grid(True, linestyle=\u0026#39;--\u0026#39;, linewidth=0.5, color=\u0026#39;gray\u0026#39;, alpha=0.5) # plt.show() Building a Bayesian model with PyMC First, we assume that the weight is a variable dependent on the height. Thus, we can express the Bayesian model as:\n$$y \\sim \\mathcal{N}(\\alpha + \\beta \\mathbf{X}, \\sigma^2)$$\nSince we want to infer the posterior distribution of the parameters $\\theta = {\\alpha, \\beta, \\sigma }$, we need to assign priors to those variables. Remember that $\\sigma$ is a measure of the uncertainty in the model.\n$$ \\begin{align*} \\alpha \u0026amp;\\sim \\mathcal{N}(0,10) \\\\ \\beta \u0026amp;\\sim \\mathcal{N}(0,1) \\\\ \\sigma \u0026amp;\\sim \\mathcal{TN}(0,100; 0, \\infty) \\end{align*} $$ The last distribution is a truncated normal distribution bounded from 0 to $\\infty$.\nNote: Here, we define the input data height as a MutableData container. The reason for this is because, later, we will want to change this input data, to make predictions. This will become clear a bit later.\nwith pm.Model() as blr_model: x = pm.MutableData(\u0026#39;height\u0026#39;, height) # define the priors alpha = pm.Normal(\u0026#39;alpha\u0026#39;, 0, 10) beta = pm.Normal(\u0026#39;beta\u0026#39;, 0, 10) sigma = pm.TruncatedNormal(\u0026#39;sigma\u0026#39;, mu = 0, sigma = 100, lower = 0) # define the likelihood - assign the variable name \u0026#34;y\u0026#34; to the observations y = pm.Normal(\u0026#39;y\u0026#39;, mu = alpha + (beta * x), sigma = sigma, observed = weight, shape = x.shape) # inference - crank up the bayes! trace = pm.sample(1000, chains = 4) Auto-assigning NUTS sampler...\rInitializing NUTS using jitter+adapt_diag...\rMultiprocess sampling (4 chains in 4 jobs)\rNUTS: [alpha, beta, sigma]\r100.00% [8000/8000 00:37\u0026lt;00:00 Sampling 4 chains, 0 divergences]\rSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 53 seconds.\rWe can explore the trace object.\ntrace.to_dataframe().columns Index([ 'chain',\r'draw',\r('posterior', 'alpha'),\r('posterior', 'beta'),\r('posterior', 'sigma'),\r('sample_stats', 'perf_counter_diff'),\r('sample_stats', 'perf_counter_start'),\r('sample_stats', 'smallest_eigval'),\r('sample_stats', 'step_size_bar'),\r('sample_stats', 'index_in_trajectory'),\r('sample_stats', 'energy'),\r('sample_stats', 'max_energy_error'),\r('sample_stats', 'energy_error'),\r('sample_stats', 'acceptance_rate'),\r('sample_stats', 'tree_depth'),\r('sample_stats', 'process_time_diff'),\r('sample_stats', 'step_size'),\r('sample_stats', 'n_steps'),\r('sample_stats', 'largest_eigval'),\r('sample_stats', 'diverging'),\r('sample_stats', 'lp'),\r('sample_stats', 'reached_max_treedepth')],\rdtype='object')\rVisualize the inference diagnostics Now that we have performed Bayesian inference using the NUTS() algorithm, we can visualize the results. Additionally, call for a summary of the statistics of the inferred posterior distributions of $\\theta$.\n# visualize the results # az.style.use(\u0026#39;arviz-darkgrid\u0026#39;) labeller = az.labels.MapLabeller(var_name_map = {\u0026#39;alpha\u0026#39;: r\u0026#39;$\\alpha$\u0026#39;, \u0026#39;beta\u0026#39;: r\u0026#39;$\\beta$\u0026#39;, \u0026#39;sigma\u0026#39;: r\u0026#39;$\\sigma$\u0026#39;}) az.plot_trace(trace, var_names = [\u0026#39;alpha\u0026#39;, \u0026#39;beta\u0026#39;, \u0026#39;sigma\u0026#39;], labeller = labeller, compact = False) plt.tight_layout() # plt.show() Interpreting the MCMC Diagnostics Plots Trace plots are crucial for diagnosing the performance of Markov Chain Monte Carlo (MCMC) algorithms. These plots typically consist of two parts for each parameter: the trace plot and the posterior density plot.\nThe trace plot shows the sampled values of a parameter across iterations. A well-behaved trace plot should look like a \u0026ldquo;hairy caterpillar,\u0026rdquo; indicating good mixing. This means the trace should move around the parameter space without getting stuck and should not display any apparent patterns or trends. If the trace shows a clear trend or drift, it suggests that the chain has not yet converged. For the parameters $\\alpha$ (intercept), $\\beta$ (slope), and $\\sigma$ (standard deviation of noise), we want to see the traces for different chains mixing well and stabilizing around a constant mean.\nThe posterior density plot shows the distribution of the sampled values of a parameter. This plot helps visualize the posterior distribution of the parameter. A good density plot should be smooth and unimodal, indicating that the parameter has a well-defined posterior distribution. If multiple chains are used, their density plots should overlap significantly, suggesting that all chains are sampling from the same distribution. For $\\alpha$, $\\beta$, and $\\sigma$, overlapping density plots indicate that the chains have converged to the same posterior distribution.\nNext, we can visualize the posterior distributions of the inferred parameters.eters.\n# visualize the posterior distributions az.plot_posterior(trace, var_names = [\u0026#39;alpha\u0026#39;, \u0026#39;beta\u0026#39;, \u0026#39;sigma\u0026#39;], labeller = labeller) plt.show() After visualizing the inference diagnostics and the posterior distributions of the paramters, we can also obtain the summary statistics.\n# get the summary statistics of the posterior distributions pm.summary(trace, kind = \u0026#34;stats\u0026#34;) mean\rsd\rhdi_3%\rhdi_97%\ralpha\r-28.557\r4.558\r-36.650\r-19.619\rbeta\r0.500\r0.026\r0.449\r0.548\rsigma\r4.657\r0.100\r4.474\r4.850\rVisualize the results Now that we have posterior distributions for the parameters $\\theta$, we can plot the the resulting linear regression functions. The following is an excerpt from PyMC\u0026rsquo;s Generalized Linear Regression tutorial:\nIn GLMs, we do not only have one best fitting regression line, but many. A posterior predictive plot takes multiple samples from the posterior (intercepts and slopes) and plots a regression line for each of them. We can manually generate these regression lines using the posterior samples directly.\nBelow, what we will effectively be doing is:\n$$ y_i = \\alpha_i + \\beta_i \\mathbf{X} \\ \\ \\ , \\ \\ \\ {i = 1, \\ldots , N_{samples}}$$\nwhere $N_{samples}$ are the number of samples from the posterior. This number comes from the inference procedure, and in practical terms is the umber of samples we asked PyMC to produce.\nIn other words, plotting the samples from the posterior distribution involves plotting the regression lines sampled from the posterior. Each sample represents a possible realization of the regression line based on the sampled values of the parameters $\\alpha$ (intercept) and $\\beta$ (slope).\nThese sample regression lines ullustrate the uncertainty in the regression model\u0026rsquo;s parameters and how this uncertainty propagates into the predictions (of the regression line).\n# use the posterior to create regression line samples # equivalent to: y[i] = alpha[i] + beta[i]*X trace.posterior[\u0026#34;y_posterior\u0026#34;] = trace.posterior[\u0026#34;alpha\u0026#34;] + trace.posterior[\u0026#34;beta\u0026#34;]*xr.DataArray(height) # plot the regression lines _, ax = plt.subplots(figsize=(7,7)) az.plot_lm(idata = trace, y = weight, x = height, axes=ax, y_model=\u0026#34;y_posterior\u0026#34;, y_kwargs={\u0026#34;color\u0026#34;:\u0026#34;b\u0026#34;, \u0026#34;alpha\u0026#34;:0.2, \u0026#34;markeredgecolor\u0026#34;:\u0026#34;k\u0026#34;, \u0026#34;label\u0026#34;:\u0026#34;Observed Data\u0026#34;, \u0026#34;markersize\u0026#34;:10}, y_model_plot_kwargs={\u0026#34;alpha\u0026#34;: 0.2, \u0026#34;zorder\u0026#34;: 10, \u0026#34;color\u0026#34;:\u0026#34;#00cc99\u0026#34;}, y_model_mean_kwargs={\u0026#34;color\u0026#34;:\u0026#34;red\u0026#34;} ) plt.show() Using the Linear Regression Model to Make Predictions Now that we have a fitted Bayesian linear regression model, we can use it to make predictions. This involves sampling from the posterior predictive distribution, which allows us to generate predictions for new data points while incorporating the uncertainty from the posterior distribution of the parameters.\nSample from the Posterior Predictive Distribution: This step involves using the inferred trace from our Bayesian linear regression model blr_model to generate predictions. The pm.sample_posterior_predictive function in PyMC allows us to do this. It uses the posterior samples of the parameters to compute the predicted values of the outcome variable. # now predict the outcomes using the inferred trace with blr_model: # use the updated values and predict outcomes and probabilities: pm.sample_posterior_predictive( trace, var_names = [\u0026#39;y\u0026#39;], return_inferencedata=True, extend_inferencedata=True, ) Sampling: [y]\r100.00% [4000/4000 00:00\u0026lt;00:00]\rExploring the Trace Object The trace object stores the results of our inference. Initially, it contained the posterior samples of the model parameters (e.g., intercept and slope).\nAfter running pm.sample_posterior_predictive, the trace object is extended to include the posterior predictive samples. These are the predicted values for the outcome variable, given the posterior distribution of the model parameters.\n# explore the trace object again trace.to_dataframe().columns Index([ 'chain',\r'draw',\r('posterior', 'alpha'),\r('posterior', 'beta'),\r('posterior', 'sigma'),\r('posterior', 'y_posterior[0]', 0),\r('posterior', 'y_posterior[100]', 100),\r('posterior', 'y_posterior[101]', 101),\r('posterior', 'y_posterior[102]', 102),\r('posterior', 'y_posterior[103]', 103),\r...\r('sample_stats', 'energy_error'),\r('sample_stats', 'acceptance_rate'),\r('sample_stats', 'tree_depth'),\r('sample_stats', 'process_time_diff'),\r('sample_stats', 'step_size'),\r('sample_stats', 'n_steps'),\r('sample_stats', 'largest_eigval'),\r('sample_stats', 'diverging'),\r('sample_stats', 'lp'),\r('sample_stats', 'reached_max_treedepth')],\rdtype='object', length=2022)\rWe can observe how now we have another inference data container: posterior_predictive. This was generated by passing the extend_inferencedata argument to the pm.sample_posterior_predictive function above.\nThis data contains predictions by passing the observed heights through our linear model and making predictions. Note that these \u0026ldquo;predictions\u0026rdquo; are made on observed data. This is similar to using validating the predictions on training data in machine learning, i.e. comparing the model predictions to the actual data on an observed input.\nWe can use the linear regression model to make predictions. It should be noted that, again, the linear regression model is not a single regression line, but rather a set of regression lines generated from the posterior probability of $\\theta$.\nVisualize the Prediction Confidence Interval After we sampled from the posterior, we might want to visualize this to understand the posterior predictive distribution.\nIn the code below, there are two things going on, let\u0026rsquo;s go through them.\nPlotting the samples from the posterior distribution This part is exactly what we did before, which is plotting the sample posteriors of the regression line. These sample regression lines are a natural product of propagating the uncertainty from the parameters unto the prediction line.\nPlotting the uncertainty in the mean and the observations Now we can add a ribbon to show the uncertainty not only in the regression line, but in the prediction points themselves. That is, that ribbon will tell us where we might expect a prediction point $i+1$, i.e.\n$$ y_{i+1} = \\alpha_{i+1} + \\beta_{i+1} x^* $$\nwhere $x^*$ is a test input point. In other words, and more specific to this demonstration:\nwhat is the interval where we would expect a predicted weight $y_{i+1}$ of an individual with a height $x*$.\n# use the posterior to create regression line samples # trace.posterior[\u0026#34;y_posterior\u0026#34;] = trace.posterior[\u0026#34;alpha\u0026#34;] + trace.posterior[\u0026#34;beta\u0026#34;]*xr.DataArray(height) # y_posterior = alpha + beta*x _, ax = plt.subplots(figsize=(7,7)) az.plot_lm(idata = trace, y = weight, x = height, axes=ax, y_model=\u0026#34;y_posterior\u0026#34;, y_kwargs={\u0026#34;color\u0026#34;:\u0026#34;b\u0026#34;, \u0026#34;alpha\u0026#34;:0.2, \u0026#34;markeredgecolor\u0026#34;:\u0026#34;k\u0026#34;, \u0026#34;label\u0026#34;:\u0026#34;Observed Data\u0026#34;, \u0026#34;markersize\u0026#34;:10}, y_model_plot_kwargs={\u0026#34;alpha\u0026#34;: 0.2, \u0026#34;zorder\u0026#34;: 10, \u0026#34;color\u0026#34;:\u0026#34;#00cc99\u0026#34;}, y_model_mean_kwargs={\u0026#34;color\u0026#34;:\u0026#34;red\u0026#34;} ); # plot the prediction interval az.plot_hdi( height, trace.posterior_predictive[\u0026#34;y\u0026#34;], hdi_prob=0.6, fill_kwargs={\u0026#34;alpha\u0026#34;: 0.8}, ) plt.show() Making Predictions on Unobserved Data Inputs Now, how about the case when we want to make predictions on test data that we have not seen? That is, predict the weight of an individual whose height/weight we have not observed (measured)\nIn other words, we have some test input data, i.e. some heights for which we want to predict the weights.\nSome references of where I learned how to do this:\nIn this example and this other example it says that we can generate out-of-sample predictions by using pm.sample_posterior_predictive and it shows an example of how to use the syntax.\nMore recently, this demo blog post clarifies how to make predictions on out-of-model samples.\nLet\u0026rsquo;s do just that now. First, we will define the test inputs we want to predict for, pred_height. Then, inside the model, we replace the data (which was defined as MutableData, with the new data we want to make predictions on. This is done as follows:\n# set new data inputs: pred_height = np.array([ \u0026#39;new_data\u0026#39; ]) with blr_model: pm.set_data({\u0026#39;height\u0026#39;: pred_height}) What this is effectively doing is telling sample_posterior_predictive that we need to make predictions on height which now happens to be different.\n# define the out-of-sample predictors pred_height = [158.0, 185.5, 165.2, 178.0, 180.0, 170.2] print(pred_height) with blr_model: # set the new data we want to make predictions for pm.set_data({\u0026#39;height\u0026#39;: pred_height}) post_pred = pm.sample_posterior_predictive( trace, predictions = True ) Sampling: [y]\r[158.0, 185.5, 165.2, 178.0, 180.0, 170.2]\r100.00% [4000/4000 00:00\u0026lt;00:00]\rWhat we have done above is create an inference data object called post_pred. This object contains the samples of the predictions on the new data. Specifically, it includes two containers: predictions and predictions_constant_data.\nThe predictions container holds the predicted samples for our new heights. The predictions_constant_data holds the new heights we passed into the model.\npost_pred.to_dataframe() chain\rdraw\r(y[0], 0)\r(y[1], 1)\r(y[2], 2)\r(y[3], 3)\r(y[4], 4)\r(y[5], 5)\r0\r0\r0\r48.981930\r62.971186\r62.143385\r59.300742\r56.100237\r54.329348\r1\r0\r1\r55.481192\r65.132876\r54.761877\r61.312254\r59.220124\r51.817360\r2\r0\r2\r49.471550\r66.016910\r60.646273\r57.876344\r56.203720\r60.318281\r3\r0\r3\r53.373737\r66.593653\r53.085799\r63.437949\r64.336626\r45.372830\r4\r0\r4\r52.981309\r69.320059\r51.590686\r60.372046\r62.210738\r48.188656\r...\r...\r...\r...\r...\r...\r...\r...\r...\r3995\r3\r995\r52.303814\r61.931117\r47.544216\r60.824401\r61.469545\r62.353284\r3996\r3\r996\r56.032295\r56.979040\r54.584837\r55.894216\r65.943908\r50.929285\r3997\r3\r997\r56.062352\r50.889499\r51.441003\r57.841533\r62.898654\r52.749139\r3998\r3\r998\r48.228772\r65.983383\r52.381164\r55.283946\r65.468049\r70.367514\r3999\r3\r999\r58.434184\r54.739363\r56.773260\r53.128112\r61.695469\r54.874142\r4000 rows × 8 columns\nWe can visualize the posterior distributions of the predictions.\naz.plot_posterior(post_pred, group=\u0026#34;predictions\u0026#34;); We can obtain point estimates by taking the mean of each prediction distribution. This is done by taking the mean of the predictions over the chain and draw dimensions, as follows:\npred_weight = post_pred.predictions[\u0026#39;y\u0026#39;].mean(dim = [\u0026#39;chain\u0026#39;, \u0026#39;draw\u0026#39;]) print(\u0026#34;Predicted weights: \u0026#34;, pred_weight.values) Predicted weights: [50.37415152 64.29241929 54.02070975 60.60276731 61.36759368 56.53983895]\rFinally, we can visualize where the predictions fall by adding a scatter plot with the new ${x^, y^}$ data.\n# use the posterior to create regression line samples # trace.posterior[\u0026#34;y_posterior\u0026#34;] = trace.posterior[\u0026#34;alpha\u0026#34;] + trace.posterior[\u0026#34;beta\u0026#34;]*xr.DataArray(height) # y_posterior = alpha + beta*x _, ax = plt.subplots(figsize=(7,7)) az.plot_lm(idata = trace, y = weight, x = height, axes=ax, y_model=\u0026#34;y_posterior\u0026#34;, y_kwargs={\u0026#34;color\u0026#34;:\u0026#34;b\u0026#34;, \u0026#34;alpha\u0026#34;:0.2, \u0026#34;markeredgecolor\u0026#34;:\u0026#34;k\u0026#34;, \u0026#34;label\u0026#34;:\u0026#34;Observed Data\u0026#34;, \u0026#34;markersize\u0026#34;:10}, y_model_plot_kwargs={\u0026#34;alpha\u0026#34;: 0.2, \u0026#34;zorder\u0026#34;: 10, \u0026#34;color\u0026#34;:\u0026#34;#00cc99\u0026#34;}, y_model_mean_kwargs={\u0026#34;color\u0026#34;:\u0026#34;red\u0026#34;} ); # plot the prediction interval az.plot_hdi( height, trace.posterior_predictive[\u0026#34;y\u0026#34;], hdi_prob=0.6, fill_kwargs={\u0026#34;alpha\u0026#34;: 0.8}, ) # add predicted weights to the plot ax.scatter(pred_height, pred_weight.values, color = \u0026#39;blue\u0026#39;, label = \u0026#39;Predicted Weights\u0026#39;, zorder = 15 ) ax.legend() plt.show() Thank you! This demo focused on a relatively simple task. Here, however, we focused more on what a Bayesian approach means in the context of a linear regression. Additionally, we focused on using PyMC for developing the model, visualizing the results and, just as importantly, on making predictions using those results.\nVictor\n","permalink":"http://localhost:1313/posts/20240527_baylinreg_pymc/e01_baylinreg_pymc/","summary":"Learn the basics of Bayesian linear regression using Julia and Turing.jl. This tutorial covers model formulation, implementation, and interpretation through a practical example.","title":"Bayesian Linear Regression with PyMC"},{"content":" Introduction This guide demonstrates how to apply transfer learning using a pre-trained vision model to classify cat moods based on their facila expressions. We\u0026rsquo;ll learn how to handle custom data setups.\nIn this demonstration, we recreate the exercise done in PyTorch, available here. Since that demonstration is quite detailed, we keep it pretty straightforward here.\nMotivation \u0026amp; Credit When I thought about learning how to implement a computer vision classification model for transfer learning in Julia and Flux, I immediately came upon two roadblocks:\nSince I am not an expert in Julia, I found the documentation to be a bit difficult to access (again, this is just me!). There are not many tutorials or resources to illustrate this particular case. Therefore I took it upon myself to put things together and make a demonstration that would hopefully be useful for someone who might not be an expert in Flux (or Julia).\nThis particular demo was inspired by a combination of the following resources:\nTransfer Learning and Twin Network for Image Classification using Flux.jl Flux.jl\u0026rsquo;s Model Zoo Tutorial PyTorch Transfer Learning for Computer Vision Tutorial Getting Started We will use a pre-trained ResNet18 model, initially trained on a general dataset, and fine-tune it for our specific task of classifying cat moods.\nInitialization First, we activate the current directory as our project environment by calling the package manager Pkg:\nusing Pkg Pkg.activate(\u0026#34;.\u0026#34;) Then we will import the required packages. Of course, this is also assuming that one has already added the relevant packages into the environment.\nusing Pkg Pkg.activate(\u0026#34;.\u0026#34;) using Random: shuffle! import Base: length, getindex using Images using Flux using Flux: update! using DataAugmentation using Metalhead using MLUtils using DataFrames, CSV using Plots \u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m project at `H:\\My Drive\\Projects\\Coding\\Portfolio\\Machine Learning\\Julia\\Transfer Learning with Flux` Retrieve the Data and Initial Setup First, we specify the paths to the dataset and labels CSV files for training, validation, and test sets. Then, we load these CSV files into DataFrames. Finally, we create vectors of absolute file paths for each image in the dataset.\nThis setup is essential for organizing the data and ensuring that our model can access the correct images and labels during training and evaluation.\nLabel Structure The data set we are using consists of three folders: train, val, test. Each of them contain a set of images of cats. The labels in this case, are in the form of a CSV file that maps the filename with a one-hot encoding to label the classification of the image, i.e. the cat\u0026rsquo;s mood - alarmed, angry, calm, pleased.\nThe dataset was obtained here.\n# specify the paths to the dataset and labels CSV train_data_path = \u0026#34;data/cat_expression_data/train\u0026#34; train_data_csv = \u0026#34;data/cat_expression_data/train/_classes.csv\u0026#34; val_data_path = \u0026#34;data/cat_expression_data/val\u0026#34; val_data_csv = \u0026#34;data/cat_expression_data/val/_classes.csv\u0026#34; test_data_path = \u0026#34;data/cat_expression_data/test\u0026#34; test_data_csv = \u0026#34;data/cat_expression_data/test/_classes.csv\u0026#34; # load the CSV file containing the labels train_labels_df = CSV.read(train_data_csv, DataFrame) test_labels_df = CSV.read(test_data_csv, DataFrame) val_labels_df = CSV.read(val_data_csv, DataFrame) # setup filepaths to the files as vectors train_filepaths = [abspath(joinpath(train_data_path, filename)) for filename in train_labels_df[!, 1] ] test_filepaths = [abspath(joinpath(test_data_path, filename)) for filename in test_labels_df[!, 1] ] val_filepaths = [abspath(joinpath(val_data_path, filename)) for filename in val_labels_df[!, 1] ] 110-element Vector{String}: \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;18cd56a2ae74d2ffc8fdc89cbb.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;6625698d9d2166cdafe47e6d17.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 106 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;99a04518d4d80adea474bbe89a.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 104 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;97c687e09bf5981b9bb729304f.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;be307e32ffc3c27ee7f49305b6.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 106 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;fabcbee5c45195a0e34918a0a1.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 105 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;d2b7179bdf5554ea40998d9d93.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 105 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;bae261f0ca148e055d0935580e.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 102 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;a84e5fa1564b409f26ea9ed0c9.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 106 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;4664e5d811b55a69cac9823a87.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;7fccb36f778a5cae5eda1e6cfc.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 104 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;824395bcb65dc5b8ecd013ab0d.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 106 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;4e1297350b8f05b54f387e002a.jpg\u0026quot; ⋮ \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 105 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;59f6a427983efd9308ddddeea7.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;8768c7f0096dc16431b41c8367.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;aa5d35bce083f1505a7b1e727e.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 104 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;5c4e68b8fba7c493f0b8bfd7bc.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;05ac086aa8b99cb8b942b1af16.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 102 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;db819e63e4b80c5caed5a07c47.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;b96481186b7376b108e9546306.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 105 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;d5aaf15e5d105aa82e24a85eff.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;5e29bd734c42a6b7b2267fb31e.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 104 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;0628948e8f68a77c821746f0b3.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 103 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;4dee18ead713b297b872642c25.jpg\u0026quot; \u0026quot;H:\\\\My Drive\\\\Projects\\\\Coding\\\\Por\u0026quot;\u001b[93m\u001b[1m ⋯ 104 bytes ⋯ \u001b[22m\u001b[39m\u0026quot;eeffac7d65a76096d457bd5949.jpg\u0026quot; Data Exploration As usual, we take a look at the data to understand what we are working with.\nBelow we make a couple of functions to visualize the data.\nNote that the helper function label_from_row will come in handy later on.\n# -----------------------------------------------------------------------# # helper function to extract label from the DataFrame function label_from_row(filename, labels_df, label_dict) # retrieve the label for the image from the DataFrame label_row = filter(row -\u0026gt; row.filename == filename, labels_df) label_index = findfirst(x -\u0026gt; label_row[1, x] == 1, names(labels_df)[2:end]) return label_dict[label_index] end # -----------------------------------------------------------------------# # function to display a selection of images and their labels function show_sample_images_and_labels(labels_df, label_dict; num_samples = 4) # randomly pick indices for sampling images sample_indices = rand(1:nrow(labels_df), num_samples) sample_filenames = labels_df.filename[sample_indices] # calculate number of rows and columns for the grid layuot num_cols = ceil(Int, num_samples / 2) num_rows = 2 # prepare a plot with a grid layout for the images p = plot(layout = (num_rows, num_cols), size(800, 200), legend = false, axis = false, grid = false) # load and plot each sampled image for (index, filename) in enumerate(sample_filenames) img_path = joinpath(train_data_path, filename) img = load(img_path) # load the image from the file # retrieve the label for the image from the DataFrame label = label_from_row(filename, labels_df, label_dict) plot!(p[index], img, title = label, axis = false) end display(p) # display the plot end # define a dictionary for label descriptions: label_dict = Dict(1 =\u0026gt; \u0026#34;alarmed\u0026#34;, 2 =\u0026gt; \u0026#34;angry\u0026#34;, 3 =\u0026gt; \u0026#34;calm\u0026#34;, 4 =\u0026gt; \u0026#34;pleased\u0026#34;) # run the function to show images show_sample_images_and_labels(train_labels_df, label_dict) Working with Custom Datasets When working with custom datasets in Julia, the concepts are similar as in PyTorch, but obviously following Julia\u0026rsquo;s syntax.\nIn essence, we read the CSV files containing image file paths and their corresponding labels into DataFrames. We then create functions to handle data loading and transformations, such as resizing and normalizing images. This approach is similar to PyTorch\u0026rsquo;s Dataset.\nLet\u0026rsquo;s have a quick look.\nCreate a Custom Dataset We define a custom dataset using a struct, which is similar to using a class in Python. The ImageContainer struct stores the image file paths and their corresponding labels in a DataFrame. We then create instances of this struct for the training, validation, and test datasets.\nstruct ImageContainer{T\u0026lt;:Vector} img::T labels_df::DataFrame end # generate dataset train_dataset = ImageContainer(train_filepaths, train_labels_df); val_dataset = ImageContainer(val_filepaths, val_labels_df); test_dataset = ImageContainer(test_filepaths, test_labels_df); Create the Data Loaders In this section, we set up data loaders for our custom dataset in Julia, similar to how data loaders are used in PyTorch to manage batching and shuffling of data.\nCall helper Function: label_from_row() : This function extracts the label from the DataFrame for a given image file. It finds the index of the column with a value of 1, indicating the class.\nLength and Indexing:\nlength(data::ImageContainer): Defines the length method to return the number of images in the dataset. Similar to PyTorch\u0026rsquo;s __len__. getindex(data::ImageContainer, idx::Int): This method is similar to PyTorch’s __getitem__. It loads an image, applies transformations, and returns the processed image along with its label. Data Augmentation and Transformations: pipeline: Defines a transformation pipeline for scaling and cropping images. transforms(image, labels_df): Inside getindex, this function applies the transformations to the image and normalizes it using the predefined mean and standard deviation values. DataLoaders: train_loader and val_loader: These DataLoader objects manage batching, shuffling, and parallel processing of the training and validation datasets, similar to torch.utils.data.DataLoader in PyTorch Notes on Implementing Custom Data Containers According to the documentation for MLUtils.DataLoader (see here), custom data containers should implement Base.length instead of numobs, and Base.getindex instead of getobs, unless there\u0026rsquo;s a difference between these functions and the base methods for multi-dimensional arrays.\nBase.length: Should be implemented to return the number of observations. This is akin to PyTorch\u0026rsquo;s __len__. Base.getindex: Should be implemented to handle indexing of the dataset, similar to PyTorch\u0026rsquo;s __getitem__. These methods ensure that the data is returned in a form suitable for the learning algorithm, maintaining consistency whether the index is a scalar or vector.\nlength(data::ImageContainer) = length(data.img) const im_size = (224, 224) const DATA_MEAN = [0.485f0, 0.456f0, 0.406f0] const DATA_STD = [0.229f0, 0.224f0, 0.225f0] # define a transformation pipeline pipeline = DataAugmentation.compose(ScaleKeepAspect(im_size), CenterCrop(im_size)) function getindex(data::ImageContainer, idx::Int) image = data.img[idx] labels_df = data.labels_df function transforms(image, labels_df) pipeline = ScaleKeepAspect(im_size) |\u0026gt; CenterCrop(im_size) _img = Images.load(image) _img = apply(pipeline, Image(_img)) |\u0026gt; itemdata img = collect(channelview(float32.(RGB.(_img)))) img = permutedims((img .- DATA_MEAN) ./ DATA_STD, (3, 2, 1) ) label = label_from_row(labels_df[idx, 1] , labels_df) return img, label end return transforms(image, labels_df) end train_loader = DataLoader( train_dataset; batchsize = 16, collate = true, parallel = true, ) val_loader = DataLoader( val_dataset; batchsize = 16, collate = true, parallel = true, ); Model Definition Here we will load the model with Metalhead.jl and change the classifier \u0026ldquo;head\u0026rdquo; of the architecture to suit our classification need.\nWe will use this to select the classifier head of the model and change it.\nFor the fine-tuning portion of this exercise will follow the model zoo documentation:\nLet\u0026rsquo;s try it out with the ResNet18 model.\n# load the pre-trained model resnet_model = ResNet(18; pretrain = true).layers # let\u0026#39;s look at the model resnet_model Chain( Chain( Chain( Conv((7, 7), 3 =\u0026gt; 64, pad=3, stride=2, bias=false), \u001b[90m# 9_408 parameters\u001b[39m BatchNorm(64, relu), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m MaxPool((3, 3), pad=1, stride=2), ), Chain( Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m NNlib.relu, Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m NNlib.relu, Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 64 =\u0026gt; 128, stride=2, bias=false), \u001b[90m# 8_192 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), Chain( Conv((3, 3), 64 =\u0026gt; 128, pad=1, stride=2, bias=false), \u001b[90m# 73_728 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m NNlib.relu, Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m NNlib.relu, Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 128 =\u0026gt; 256, stride=2, bias=false), \u001b[90m# 32_768 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), Chain( Conv((3, 3), 128 =\u0026gt; 256, pad=1, stride=2, bias=false), \u001b[90m# 294_912 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m NNlib.relu, Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m NNlib.relu, Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 256 =\u0026gt; 512, stride=2, bias=false), \u001b[90m# 131_072 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), Chain( Conv((3, 3), 256 =\u0026gt; 512, pad=1, stride=2, bias=false), \u001b[90m# 1_179_648 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m NNlib.relu, Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m NNlib.relu, Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), ), ), ), Chain( AdaptiveMeanPool((1, 1)), MLUtils.flatten, Dense(512 =\u0026gt; 1000), \u001b[90m# 513_000 parameters\u001b[39m ), ) \u001b[90m # Total: 62 trainable arrays, \u001b[39m11_689_512 parameters, \u001b[90m # plus 40 non-trainable, 9_600 parameters, summarysize \u001b[39m44.654 MiB. Now we modify the head, by chaning the last Chain in the model. We change the last layer to output 4 classes (as opposed to the original 1000 classes).\n# modify the model resnet_infer = deepcopy(resnet_model[1]) resnet_tune = Chain(AdaptiveMeanPool((1, 1)), Flux.flatten, Dense(512 =\u0026gt; 4)) Chain( AdaptiveMeanPool((1, 1)), Flux.flatten, Dense(512 =\u0026gt; 4), \u001b[90m# 2_052 parameters\u001b[39m ) And that\u0026rsquo;s it! Now, let\u0026rsquo;s just explore both portions of the model.\nresnet_infer Chain( Chain( Conv((7, 7), 3 =\u0026gt; 64, pad=3, stride=2, bias=false), \u001b[90m# 9_408 parameters\u001b[39m BatchNorm(64, relu), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m MaxPool((3, 3), pad=1, stride=2), ), Chain( Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m NNlib.relu, Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m NNlib.relu, Conv((3, 3), 64 =\u0026gt; 64, pad=1, bias=false), \u001b[90m# 36_864 parameters\u001b[39m BatchNorm(64), \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 64 =\u0026gt; 128, stride=2, bias=false), \u001b[90m# 8_192 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), Chain( Conv((3, 3), 64 =\u0026gt; 128, pad=1, stride=2, bias=false), \u001b[90m# 73_728 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m NNlib.relu, Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m NNlib.relu, Conv((3, 3), 128 =\u0026gt; 128, pad=1, bias=false), \u001b[90m# 147_456 parameters\u001b[39m BatchNorm(128), \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 128 =\u0026gt; 256, stride=2, bias=false), \u001b[90m# 32_768 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), Chain( Conv((3, 3), 128 =\u0026gt; 256, pad=1, stride=2, bias=false), \u001b[90m# 294_912 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m NNlib.relu, Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m NNlib.relu, Conv((3, 3), 256 =\u0026gt; 256, pad=1, bias=false), \u001b[90m# 589_824 parameters\u001b[39m BatchNorm(256), \u001b[90m# 512 parameters\u001b[39m\u001b[90m, plus 512\u001b[39m ), ), ), Chain( Parallel( addact(NNlib.relu, ...), Chain( Conv((1, 1), 256 =\u0026gt; 512, stride=2, bias=false), \u001b[90m# 131_072 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), Chain( Conv((3, 3), 256 =\u0026gt; 512, pad=1, stride=2, bias=false), \u001b[90m# 1_179_648 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m NNlib.relu, Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), ), Parallel( addact(NNlib.relu, ...), identity, Chain( Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m NNlib.relu, Conv((3, 3), 512 =\u0026gt; 512, pad=1, bias=false), \u001b[90m# 2_359_296 parameters\u001b[39m BatchNorm(512), \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m ), ), ), ) \u001b[90m # Total: 60 trainable arrays, \u001b[39m11_176_512 parameters, \u001b[90m # plus 40 non-trainable, 9_600 parameters, summarysize \u001b[39m42.693 MiB. resnet_tune Chain( AdaptiveMeanPool((1, 1)), Flux.flatten, Dense(512 =\u0026gt; 4), \u001b[90m# 2_052 parameters\u001b[39m ) Define evaluation and training functions Again, will follow the model zoo documentation. Small adaptations will be needed. (These two functions were taken directly from the documentation).\nfunction eval_f(m_infer, m_tune, val_loader) good = 0 count = 0 for(x, y) in val_loader good += sum(Flux.onecold(m_tune(m_infer(x))) .== y) count += length(y) end acc = round(good / count, digits = 4) return acc end eval_f (generic function with 1 method) function train_epoch!(model_infer, model_tune, opt, loader) for (x, y) in loader infer = model_infer(x) grads = gradient(model_tune) do m Flux.Losses.logitcrossentropy(m(infer), Flux.onehotbatch(y, 1:4)) end update!(opt, model_tune, grads[1]) end end train_epoch! (generic function with 1 method) resnet_opt = Flux.setup(Flux.Optimisers.Adam(1e-3), resnet_tune); for iter = 1:5 @time train_epoch!(resnet_infer, resnet_tune, resnet_opt, train_loader) metric_train = eval_f(resnet_infer, resnet_tune, train_loader) metric_eval = eval_f(resnet_infer, resnet_tune, val_loader) @info \u0026#34;train\u0026#34; metric = metric_train @info \u0026#34;eval\u0026#34; metric = metric_eval end 176.283332 seconds (37.11 M allocations: 98.153 GiB, 6.06% gc time, 143.87% compilation time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.5744 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.5455 70.815518 seconds (2.42 M allocations: 95.936 GiB, 11.25% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6823 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6273 90.463025 seconds (2.42 M allocations: 95.936 GiB, 11.21% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.7032 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6455 94.362892 seconds (2.42 M allocations: 95.936 GiB, 10.91% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.7433 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6727 116.526515 seconds (2.42 M allocations: 95.936 GiB, 9.62% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.7885 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6909 Vision Transformers Similar to the PyTorch demonstration, we can do transfer learning by changing a different computer vision model (Vision Transformer).\nLet\u0026rsquo;s get into it.\nvit_model = ViT(:base; pretrain = true).layers # let\u0026#39;s have a look at the model head, to see how many inputs the head needs vit_model[2] Chain( LayerNorm(768), \u001b[90m# 1_536 parameters\u001b[39m Dense(768 =\u0026gt; 1000), \u001b[90m# 769_000 parameters\u001b[39m ) \u001b[90m # Total: 4 arrays, \u001b[39m770_536 parameters, 2.940 MiB. # modify the head vit_infer = deepcopy(vit_model[1]) # notice how we keep the input to the model head vit_tune = Chain( LayerNorm(768), Dense(768 =\u0026gt; 4), ) Chain( LayerNorm(768), \u001b[90m# 1_536 parameters\u001b[39m Dense(768 =\u0026gt; 4), \u001b[90m# 3_076 parameters\u001b[39m ) \u001b[90m # Total: 4 arrays, \u001b[39m4_612 parameters, 18.352 KiB. vit_opt = Flux.setup(Flux.Optimisers.Adam(1e-3), vit_tune); for iter = 1:5 @time train_epoch!(vit_infer, vit_tune, vit_opt, train_loader) metric_train = eval_f(vit_infer, vit_tune, train_loader) metric_eval = eval_f(vit_infer, vit_tune, val_loader) @info \u0026#34;train\u0026#34; metric = metric_train @info \u0026#34;eval\u0026#34; metric = metric_eval end 627.303072 seconds (17.32 M allocations: 291.924 GiB, 4.61% gc time, 3.66% compilation time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.7058 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6273 565.986959 seconds (2.54 M allocations: 291.028 GiB, 4.71% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.8042 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6273 516.041945 seconds (2.54 M allocations: 291.028 GiB, 4.92% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.866 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6818 515.415614 seconds (2.54 M allocations: 291.028 GiB, 4.80% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.8973 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6818 427.423410 seconds (2.54 M allocations: 291.028 GiB, 5.01% gc time) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mtrain \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.9199 \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39meval \u001b[36m\u001b[1m└ \u001b[22m\u001b[39m metric = 0.6727 Save the Models using JLD2 resnet_model_state = Flux.state(resnet_model) vit_model_state = Flux.state(vit_model) jldsave(\u0026#34;resnet_model.jld2\u0026#34;; resnet_model_state) jldsave(\u0026#34;vit_model.jld2\u0026#34;; vit_model_state) \u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mOpening file with JLD2.MmapIO failed, falling back to IOStream \u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ JLD2 C:\\Users\\ingvi\\.julia\\packages\\JLD2\\7uAqU\\src\\JLD2.jl:300\u001b[39m \u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mOpening file with JLD2.MmapIO failed, falling back to IOStream \u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ JLD2 C:\\Users\\ingvi\\.julia\\packages\\JLD2\\7uAqU\\src\\JLD2.jl:300\u001b[39m using BSON: @save @save \u0026#34;resnet_model_sate.bson\u0026#34; resnet_model @save \u0026#34;vit_model_state.bson\u0026#34; vit_model Thank you! I hope this demonstration on using Julia and Flux for transfer learning was helpful!\nVictor\n","permalink":"http://localhost:1313/posts/20240521_julia_transfer_learning_v5/20240521_julia_transfer_learning_v5/","summary":"Replicating the cat mood classifier, this time using Julia and Flux.jl.","title":"Transfer Learning Classifier Again... with Julia!"},{"content":"\nCat Expression Classifier Using Convolutional Neural Networks This project aims to build a cat expression classifier with convolutional neural networks (CNNs) using PyTorch. This project serves as an introduction to image classification and also dives into the nuances of handling a specific, custom dataset and adapting pre-trained models for our purposes.\nObjective The primary objective of this project is to develop a model capable of classifying images of cat faces into one of four moods: alarmed, angry, calm, and pleased. By the end of this tutorial, you will learn how to preprocess image data, leverage transfer learning for image classification, and evaluate a model\u0026rsquo;s performance.\nTools and Techniques We will employ PyTorch, a powerful and versatile deep learning library, to construct our CNN. The model of choice for this tutorial is ResNet18, a robust architecture that is commonly used in image recognition tasks. Given the straightforward nature of our classificaiton problem, ResNet18 provides an ecellent balance between complexity and performance.\nWhy Transfer Learning? In this tutorial, we utilize transfer learning to take advantage of a pre-trained ResNet18 model. This approach allows us to use a model that has already learned a significant amount of relevant features from a vast and diverse dataset (ImageNet). By fine-tuning this model to our specific task, we can achieve high accuracy with relatively little data and reduce the computational cost typycally associated with training a deep neural network from scratch.\nDataset The dataset comprises images of cat faces, labeled according to their expressed mood. These images are organized into training, validation, and testing sets, each with a corresponding CSV file which maps filenames to mood labels. This guide will walk you through the process of loading, preprocessing, and augmenting this data to suit the needs of our CNN.\nThe dataset was obtained here.\nLet\u0026rsquo;s get started!\nDataset Exploration Listing the Number of Images in Each Set and Visualizing The Set Below we will mount the drive to retrieve the data set files. Then, will use Python\u0026rsquo;s os module to list the number of images in the dataset. This will give us an idea of the size of the set.\nAdditionally, we will include a flag to tell the model whether we want to train it or to load a previously saved model\u0026hellip; this will become clear later.\nFinally, we will set up a function to visualize some sample images from each set.\nimport os # flag to control whether to train the model or load a saved model should_train_resnet = False should_train_vit = False def set_path(): # check if the notebook is running on google colab if \u0026#39;google.colab\u0026#39; in str(get_ipython()): print(\u0026#39;Running on Google Colab.\u0026#39;) from google.colab import drive drive.mount(\u0026#39;/content/drive\u0026#39;) path = \u0026#39;/content/drive/PATH-TO-YOUR-DATA\u0026#39; else: print(\u0026#39;Running locally.\u0026#39;) path = \u0026#39;./data/cat_expression_data\u0026#39; return path base_dir = set_path() Running on Google Colab. Mounted at /content/drive # base directories train_dir = os.path.join(base_dir, \u0026#39;train\u0026#39;) test_dir = os.path.join(base_dir, \u0026#39;test\u0026#39;) val_dir = os.path.join(base_dir, \u0026#39;val\u0026#39;) def list_images(directory): \u0026#34;\u0026#34;\u0026#34; list folders and count image files in each folder \u0026#34;\u0026#34;\u0026#34; dir_name = os.path.basename(directory) image_files = [f for f in os.listdir(directory) if f.lower().endswith((\u0026#39;.jpg\u0026#39;, \u0026#39;jpeg\u0026#39;, \u0026#39;.bmp\u0026#39;, \u0026#39;.gif\u0026#39;))] print(f\u0026#39;Total image files in {dir_name}: {len(image_files)}\u0026#39;) list_images(train_dir) list_images(val_dir) list_images(test_dir) Total image files in train: 1149 Total image files in val: 110 Total image files in test: 55 Finally, we will make a dictionary that maps the classes to index-based labels, from the CSV file. We will need this way later, but we will define the dictionary this early on.\nVisualizing Some of the Data Let\u0026rsquo;s visualize a few images from each folder to ensure to have a better feel of the data.\nWe will do this by making a dataframe out of the annotations file where the labels are stored. We will use the test annotations, since this is the smallest dataset, and the other two have the same labels anyway.\nimport pandas as pd # define the annotations file annotations_filename = \u0026#39;_classes.csv\u0026#39; # define the full path to the annotations file test_annotations = os.path.join(test_dir, annotations_filename) # load the annotations file df = pd.read_csv(test_annotations) class_names = {index: col for index, col in enumerate(df.columns[1:])} # Adjust slicing if there are other columns print(class_names) {0: ' alarmed', 1: ' angry', 2: ' calm', 3: ' pleased'} import matplotlib.pyplot as plt from PIL import Image import random def show_sample_images(main_directory, num_samples=5): \u0026#34;\u0026#34;\u0026#34;Display sample images from each subfolder within the main directory.\u0026#34;\u0026#34;\u0026#34; subfolders = [f.path for f in os.scandir(main_directory) if f.is_dir()] for directory in subfolders: image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith((\u0026#39;.jpg\u0026#39;, \u0026#39;.jpeg\u0026#39;))] if len(image_files) \u0026gt; 0: chosen_samples = random.sample(image_files, min(len(image_files), num_samples)) # Plot settings fig, axes = plt.subplots(1, min(len(image_files), num_samples), figsize=(15, 5)) fig.suptitle(f\u0026#39;Sample Images from {os.path.basename(directory)}\u0026#39;, fontsize=16) for ax, img_path in zip(axes.flatten(), chosen_samples): image = Image.open(img_path) ax.imshow(image) ax.axis(\u0026#39;off\u0026#39;) # ax.set_title(os.path.basename(img_path)) plt.show() else: print(f\u0026#34;No images to display in {os.path.basename(directory)}.\u0026#34;) # Example usage with the base directory containing train, validation, and test subfolders show_sample_images(base_dir, num_samples = 3) Data Preprocessing This steps involves preparing the dataset for training a PyTorch model by resizing, normalizing, and applying data augmentation.\nNOTE: At this point, it is important to know what is the model or CNN architecture we will be using. Important aspects to consider include the image size, any data transformations for training and validation, data augmentation techniques, and setting up data loaders later.\nIn this example, we will use ResNet18 . The inputs must follow a specific format, as per the PyTorch ResNet documentation found here:\nAll pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\nTools for Data Preprocessing in PyTorch torchvision.transforms: Provides common image transformations like resizing, normalization, and augmentation. torch.utils.data.Dataset: A base class for creating custom datasets. torch.utils.data.DataLoader: Loads and batches data for training. The Data The data set we are using consists of three folders: train, val, test. Each of them contain a set of images of cats. The labels in this case, are in the form of a CSV file that maps the filename with a one-hot encoding to label the classification of the image, i.e. the cat\u0026rsquo;s mood - alarmed, angry, calm, pleased.\nBecause this dataset structure is not exactly suitable for the ImageFolder module in PyTorch, whereby labelling is made easier and based on the folder structure, we need to create a custom dataset and loader. Let\u0026rsquo;s get started!\nDefine Image Transformations Specify resizing dimensions, normalization parameters, and augmentation techniques (like random rotation, flips, etc.). Create separate transformations for training and validation datasets. # import transforms import torch import torchvision.transforms as transforms # define the image size image_size = (224, 224) # adjusted for ResNet18 # define transformations for the training dataset train_transforms = transforms.Compose([ transforms.Resize(256), # resize to ensure minimum size transforms.CenterCrop(224), # center crop to 224x224 transforms.RandomHorizontalFlip(), # data augmentation transforms.RandomRotation(15), # data augmentation transforms.ConvertImageDtype(torch.float), # important, because the read_image reads as uint8, needs to be float # given that below we apply normalization transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) ]) val_transforms = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ConvertImageDtype(torch.float), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) ]) With these transformations, the data pipeline will align with common practices for pre-trained models like ResNet18.\nCreate Custom Datasets and Data Loaders Given the structure of our dataset, where labels are provided in a CSV file rather than through directory structure, we need to use a custom dataset class. This will allow us to link echc image with its respective label based on our CSV file\u0026rsquo;s structure.\nCreating Custom Dataset We will extend the torch.utils.data.Dataset class to create our custom dataset. this class will override the necessary methods to handle our specific dataset setup:\nInitialization: Load the CSV file and set up the path to the images Length: Return the total number of images Get item: Load each image by index, apply the specified transformations, and parse the label from the CSV data import pandas as pd import torch from torch.utils.data import Dataset from torchvision.io import read_image class CustomImageDataset(Dataset): \u0026#34;\u0026#34;\u0026#34; a custom dataset class that loads images and their labels from a CSV \u0026#34;\u0026#34;\u0026#34; def __init__(self, annotations_file, img_dir, transform = None): \u0026#34;\u0026#34;\u0026#34; args: annotations_file (string): path to the CSV file with annotations img_dir (str): directory with all the images transform (callable, optional): transform to be applied on a sample \u0026#34;\u0026#34;\u0026#34; self.img_labels = pd.read_csv(annotations_file) # load annotations self.img_dir = img_dir self.transform = transform def __len__(self): \u0026#34;\u0026#34;\u0026#34; returns the number of items in the dataset \u0026#34;\u0026#34;\u0026#34; return len(self.img_labels) def __getitem__(self, idx): \u0026#34;\u0026#34;\u0026#34; fetches the image and label at the index idx from the dataset \u0026#34;\u0026#34;\u0026#34; img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) image = read_image(img_path) # convert one-hot encoded labels to a categorical label one_hot_label = self.img_labels.iloc[idx, 1:].values.astype(\u0026#39;float32\u0026#39;) # next find the index of the element in the slice which contains the \u0026#39;1\u0026#39; # since all other numbers will be 0; this will correspond to the label # 0, 1, 2, 3 label = torch.argmax(torch.tensor(one_hot_label)).item() if self.transform: image = self.transform(image) # apply transformations return image, label Now that we have defined the data classes, we can create objects for each of our datasets, as a CustomImageDataset class.\n# annotations_filename = \u0026#39;_classes.csv\u0026#39; # previously defined # paths to annotation files train_annotations = os.path.join(train_dir, annotations_filename) val_annotations = os.path.join(val_dir, annotations_filename) test_annotations = os.path.join(test_dir, annotations_filename) # previously defined # create dataset objects train_dataset = CustomImageDataset(train_annotations, train_dir, transform = train_transforms) val_dataset = CustomImageDataset(val_annotations, val_dir, transform = val_transforms) test_dataset = CustomImageDataset(test_annotations, test_dir, transform = val_transforms) Creating Data Loaders Data loaders in PyTorch provide the necessary functionality to batch, shuffle, and feed the data to your model during training in an efficient manner. They also handle parallel processing using multiple worker threads, which can significantly speed up data loading.\nIn short, data loaders take the dataset objects and handle the process of creating batches, shuffling the data, and parallelizing the data loading process.\nBelow we will create a data loaders for our datasets.\nfrom torch.utils.data import DataLoader train_loader = DataLoader( train_dataset, batch_size = 64, # defines how many samples per batch to load shuffle = True # shuffles the dataset at every epoch ) val_loader = DataLoader( val_dataset, batch_size = 64, shuffle = False # no need to shuffle validation data ) test_loader = DataLoader( test_dataset, batch_size = 64, shuffle = False ) In the loader above, we have the following main parts:\nBatch size: typycally set based on the system\u0026rsquo;s memory capacity and how large the model is. A larger batch size can speed up training but requires more memory. Shuffle: shuffling helps ensure that each batch sees a varierty of data across epochs, which can improve model generalization. Number of workers: this controls how many subproceses to use for data loading. More workers can lead to faster data preprocessing and reduced time to train each epoch but also increases memory usage. Integration with the Training Loop With the data loaders set up, we are now ready to integrate them into the model\u0026rsquo;s training and validation loops.\nThe code snippet below shows how this would be done. We will implement the actual integration when we get to the training section.\nfor epoch in range(num_epochs): for images, labels in train_loader: # Forward pass, backward pass, and optimize outputs = model(images) loss = criterion(outputs, labels) optimizer.zero_grad() loss.backward() optimizer.step() # Validation step at the end of each epoch model.eval() with torch.no_grad(): for images, labels in val_loader: predictions = model(images) # Calculate validation accuracy, loss, etc. Model Training Now that the data is ready and properly formatted for input into a neural network, the next step involves setting up and training the ResNet18 model. We will configure the model, define the loss function and optimizer, and implement the training and validation loops.\nNext Steps Model setup: Load the pre-trained ResNet18 model and modify it for our specific classification task (number of classes based on cat facial expressions) Loss function and optimizer: Define a loss function suitable for classification, e.g. CrossEntropyLoss Set up an optimizer (like Adam or SGD) to adjust the model weights during training based on the computed gradients Training loop: Implement the loop that processes the data through the model, computes the loss, updates the model parameters, and evaluates the model performance on the validation dataset periodically Monitoring and saving the model: Track performance metrics such as loss and accuracy Implement functionality to save the trained model for later use or further evaluation Model Setup In this section, we\u0026rsquo;ll configure a ResNet18 model to suit our specific classification task. Since the model is originally designed for ImageNet with 1000 classes, we\u0026rsquo;ll adapt it for our use case, which involves classifying images into four mood categories (alarmed, angry, calm, pleased).\nImport the Necessary Libraries # import torch # this has already been imported before import torch.nn as nn import torch.optim as optim from torchvision import models Load and Modify the Pre-trained ResNet18 We will load a pre-trained ResNet18 model and modify its final layer to suit our classification needs. This is known as transfer learning, and it is a technique that uses a pre-trained model and leverages its learned parameters to focus on a similar, more specific task. This is a powerful technique, since it uses the existing knowledge (such as edges and features) so that the new classification task is more robust, and faster to tune to the specific task.\nUnderstanding Transfer Learning Transfer Learning is a powerful technique in machine learning where a model developed for a particular task is reused as the starting point for a model on a second task. It\u0026rsquo;s especially popular in deep learning given the vast compute and time resources required to develop neural network models on large datasets and from scratch.\nWhy Use Transfer Learning? Efficiency: transfer learning allows us to leverage pre-trained networks that have already learned a good amount of features on large datasets. This is beneficial as it can drastically reduce the time and computational cost to achieve high performance. Performance: models trained on large-scalr datasets like ImageNet havve proven to generalize well to other datasets. Starting with these can provide a significand head-start in terms of performance. Applying Transfer Learning Model adaptation: for our specific task fo classifying cat moods, we take a pre-trained ResNet18 model and tailor it to our needs. The pre-trained model brings the advantage of learned features from ImageNet, a vast and diverse dataset. Feature extraction: by freezing (i.e. keeping the weight values as they are) the pre-trained layers, we utilize them as a feature extractor. Only the final layers are trained to adapt those features to our specific classification task. Model Setup with a Custom Classifier We have mentioned replacing the funal layer(s) as a transfer learning techniques. In this case, we replace the final fully connected (fc) layer of ResNet18 with a different layer which will suit our need to have 4 classes. Additionally, we will replace this fc layer with a more complex classifier portion, which involves adding additional layers such as ReLU for non-linearity, and dropout for regularization to prevent overfitting.\nReLU Activation: introduces non-linearity into the model, allowing it to learn more complex patterns. Dropout: Randomly zeros some of the elements of the input (to the layer, not input to the model) tensor with probability $p$ during training, which helps prevent overfitting. Let\u0026rsquo;s implement this classifier in our transfer learning setup.\n# assign the model weights weights = models.ResNet18_Weights.DEFAULT # create the model object with pre-trained weights model = models.resnet18(weights = weights) # freeze all the layers in the network for param in model.parameters(): param.requires_grad = False # replace the fc layer with a more complex classifier num_features = model.fc.in_features model.fc = nn.Sequential( nn.Linear(num_features, 256), # first linear layer nn.ReLU(), # non-linearity nn.Dropout(0.5), # dropout for regularization nn.Linear(256, len(class_names)) # output layer, 4 classes for cat moods ) # move model to GPU if available device = torch.device(\u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) model = model.to(device) Downloading: \u0026quot;https://download.pytorch.org/models/resnet18-f37072fd.pth\u0026quot; to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth 100%|██████████| 44.7M/44.7M [00:00\u0026lt;00:00, 117MB/s] Loss Function and Optimizer For our classification task, we need a loss function that effectively measures the discrepancy between the predicted labels and the actual labels. Since we\u0026rsquo;ve configured out model outputs to be class indices (from our dataset\u0026rsquo;s one-hot encoded labels), we\u0026rsquo;ll use CrossEntropyLoss, which is ideal for such clasification tasks.\nWe\u0026rsquo;ll par this with the Adam optimizer, which is known for its efficiency in handling sparse gradients and adaptive learning rate capabilities, making it well-suited for this task.\nLet\u0026rsquo;s set up our loss function and optimizer.\n# loss function criterion = nn.CrossEntropyLoss() # optimizer # optimize only the final classifier layers optimizer = optim.Adam(model.fc.parameters(), lr = 0.001) Training and Validation Loops Now, let\u0026rsquo;s write the code to train and validate our model. This involves running the model over several epochs, making predictions, calculating loss, updating the model parameters, and evaluating the model\u0026rsquo;s perfomance on the validation dataset.\nTraining loop: here, the model learns by adjusting its weights based on the calculated loss from the training data Validation loop: validation occurs post the training phase in each epoch and helps in evaluating the model\u0026rsquo;s performance on unseen data, ensuring it generalizes well and doesn\u0026rsquo;t overfit Saving/Loading the Model Save the Trained Model If we have performed training, we can save the model to use next time, so that we can avoid re-training everytime we run the notebook.\nWe will implement this part as an if statement, that would run the training loop and save the model if we choose to, otherwise, we would just load the model weights.\nimport pickle # define a function to set the save model path def model_save_path(): # check if the notebook is running on google colab if \u0026#39;google.colab\u0026#39; in str(get_ipython()): print(\u0026#39;Running on Google Colab.\u0026#39;) path = \u0026#39;/content/drive/PATH-TO-YOUR-SAVE-FOLDER\u0026#39; else: print(\u0026#39;Running locally.\u0026#39;) path = \u0026#39;./saved_models\u0026#39; return path def training_loop(flag, model, criterion, optimizer, model_filename, model_data_filename, num_epochs = None): if flag: # num_epochs = 25 # define the number of epochs for training train_losses = [] val_losses = [] for epoch in range(num_epochs): model.train() # set the model to training mode total_train_loss = 0 for images, labels in train_loader: images, labels = images.to(device), labels.to(device) # forward pass to get outputs outputs = model(images) loss = criterion(outputs, labels) # backpropagation and optimization optimizer.zero_grad() loss.backward() optimizer.step() total_train_loss += loss.item() * images.size(0) # calculate average training loss for the epoch avg_train_loss = total_train_loss / len(train_loader.dataset) train_losses.append(avg_train_loss) # print average training loss per epoch\u0026#34; print(f\u0026#39;Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\u0026#39;) #------------------# # validation phase # #------------------# model.eval() # set the model to evaluation mode total_val_loss = 0 total_val_accuracy = 0 with torch.no_grad(): for images, labels in val_loader: images, labels = images.to(device), labels.to(device) outputs = model(images) loss = criterion(outputs, labels) total_val_loss += loss.item() * images.size(0) _, predicted = torch.max(outputs, 1) total_val_accuracy += (predicted == labels).sum().item() # calculate average validation loss for the epoch avg_val_loss = total_val_loss / len(val_loader.dataset) val_losses.append(avg_val_loss) # calculate validation accuracy val_accuracy = 100 * total_val_accuracy / len(val_loader.dataset) # print validation accuracy print(f\u0026#39; Validation loss: {avg_val_loss:.4f}, Validation accuracy: {val_accuracy:.2f}%\u0026#39;) # save model and training data save_model_path = model_save_path() # model_filename = \u0026#39;vit_cat_mood.pth\u0026#39; model_path = os.path.join(save_model_path, model_filename) torch.save(model.state_dict(), model_path) print(\u0026#39;Model saved to\u0026#39;, model_path) # save the training and validation losses def save_training_data(train_losses, val_losses, filename): with open(filename, \u0026#39;wb\u0026#39;) as f: pickle.dump({\u0026#39;train_losses\u0026#39;: train_losses, \u0026#39;val_losses\u0026#39;: val_losses}, f) print(f\u0026#34;Training data saved to {filename}\u0026#34;) # Specify the filename for saving training data training_data_filename = os.path.join(save_model_path, model_data_filename) save_training_data(train_losses, val_losses, training_data_filename) return train_losses, val_losses else: # load the trained model save_model_path = model_save_path() # model_filename = \u0026#39;vit_cat_mood.pth\u0026#39; model_path = os.path.join(save_model_path, model_filename) model.load_state_dict(torch.load(model_path, map_location = device)) model.eval() print(\u0026#39;Model loaded and set to evaluation mode.\u0026#39;) # load training data # Load the training and validation losses def load_training_data(filename): with open(filename, \u0026#39;rb\u0026#39;) as f: data = pickle.load(f) return data training_data_filename = os.path.join(save_model_path, model_data_filename) training_data = load_training_data(training_data_filename) train_losses = training_data[\u0026#39;train_losses\u0026#39;] val_losses = training_data[\u0026#39;val_losses\u0026#39;] print(\u0026#39;Training data loaded successfully.\u0026#39;) return train_losses, val_losses model_filename = \u0026#39;resnet18_cat_mood.pth\u0026#39; model_data_filename = \u0026#39;resnet18_training_data.pkl\u0026#39; train_losses, val_losses = training_loop(should_train_resnet, model, criterion, optimizer, model_filename, model_data_filename, num_epochs = 25) Running on Google Colab. Model loaded and set to evaluation mode. Training data loaded successfully. Model Evaluation Now that the model is trained, the next step is to evaluate its performance more thoroughly, and possibly improve it based on the insights gained.\nEvaluating the model involves checking the accuracy and also looking at other metrics like precision, recall, and F1-score, especially if the dataset is imbalanced or if specific classes are more important than others.\nModel Evaluation on Validation Set After training a machine learning model, it\u0026rsquo;s crucial to evaluate its performance comprehensively. Here, we will detail three key diagnostic tools\u0026quot;\nConfusion matrix Plotting training and validation losses Visualization of the predictions Confusion Matrix A confusion matrix provides a detailed breakdown of the model\u0026rsquo;s predictions, showing exactly how many samples from each class were correctly or incorrectly predicted as each other class. This is crucial for understanding the model\u0026rsquo;s performance across different categories.\nfrom sklearn.metrics import confusion_matrix, classification_report import seaborn as sns import matplotlib.pyplot as plt def evaluate_model(model, data_loader, device): model.eval() true_labels = [] predictions = [] with torch.no_grad(): for images, labels in data_loader: images, labels = images.to(device), labels.to(device) outputs = model(images) _, preds = torch.max(outputs, 1) predictions.extend(preds.cpu().numpy()) true_labels.extend(labels.cpu().numpy()) # compute the confusion matrix cm = confusion_matrix(true_labels, predictions) clf_report = classification_report(true_labels, predictions, output_dict = True) # Convert classification report dictionary to DataFrame clf_report_df = pd.DataFrame(clf_report).transpose() return cm, clf_report_df cm, clf_report_df = evaluate_model(model, val_loader, device) # Plot the confusion matrix plt.figure(figsize=(10, 8)) sns.heatmap(cm, annot=True, fmt=\u0026#39;d\u0026#39;, cmap=\u0026#39;Blues\u0026#39;) plt.title(\u0026#39;Confusion Matrix\u0026#39;) plt.ylabel(\u0026#39;True Label\u0026#39;) plt.xlabel(\u0026#39;Predicted Label\u0026#39;) plt.show() # Print classification report print(\u0026#39;Classification Report:\u0026#39;) print(clf_report_df) Classification Report: precision recall f1-score support 0 0.333333 0.285714 0.307692 14.000000 1 0.862069 0.714286 0.781250 35.000000 2 0.487179 0.678571 0.567164 28.000000 3 0.866667 0.787879 0.825397 33.000000 accuracy 0.672727 0.672727 0.672727 0.672727 macro avg 0.637312 0.616613 0.620376 110.000000 weighted avg 0.700728 0.672727 0.679728 110.000000 Plotting Training and Validation Losses Plotting the training and validation losses over epochs allows us to monitor the learning process, identifying issues such as overfitting or underfitting.\ndef plot_losses(train_losses, val_losses): \u0026#34;\u0026#34;\u0026#34; Plot the training and validation losses. Parameters: - train_losses: list of training loss values per epoch - val_losses: list of validation loss values per epoch \u0026#34;\u0026#34;\u0026#34; plt.figure(figsize = (10, 6)) plt.plot(train_losses, label = \u0026#39;Training Loss\u0026#39;, color = \u0026#39;blue\u0026#39;, marker = \u0026#39;o\u0026#39;) plt.plot(val_losses, label = \u0026#39;Validation Loss\u0026#39;, color = \u0026#39;red\u0026#39;, marker = \u0026#39;o\u0026#39;) plt.title(\u0026#39;Training and Validation Losses Over Epochs\u0026#39;) plt.xlabel(\u0026#39;Epoch\u0026#39;) plt.ylabel(\u0026#39;Loss\u0026#39;) plt.legend() plt.grid(True) plt.show() # take the tracked losses from thet training loop plot_losses(train_losses, val_losses) Visualization of the Predictions Visualizing model predictions on actual data points provides immediate qualitative feedback about model behavior. It helps identify paterns in which the model performs well or poorly, revealing potential biases, underfitting, or overfitting.\nimport numpy as np def visualize_predictions(model, data_loader, device, class_names, num_images = 10): model.eval() images_so_far = 0 rows = num_images // 2 if num_images % 2 == 0 else num_images // 2 + 1 fig, axes = plt.subplots(nrows = rows, ncols = 2, figsize = (12, num_images * 3)) # define the mean and std deviation used for normalization mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) with torch.no_grad(): for i, (images, labels) in enumerate(data_loader): images, labels = images.to(device), labels.to(device) outputs = model(images) _, preds = torch.max(outputs, 1) for j in range(images.size(0)): if images_so_far \u0026lt; num_images: ax = axes[images_so_far // 2, images_so_far % 2] if num_images \u0026gt; 1 else axes # arrange in grid ax.axis(\u0026#39;off\u0026#39;) # convert tensors to integers predicted_label = preds[j].item() actual_label = labels[j].item() # reverse normalization transform img = images.cpu().data[j].numpy().transpose((1, 2, 0)) # change CxHxW to HxWxC img = std * img + mean # reverse normalization img = np.clip(img, 0, 1) # clip values to ensure they fall between 0 and 1 # use converted integers to access class names ax.set_title(f\u0026#39;predicted: {class_names[predicted_label]} | actual: {class_names[actual_label]}\u0026#39;, fontsize = 12) ax.imshow(img) images_so_far += 1 else: plt.tight_layout() # adjust layout plt.show() return # make new loader for random samples vis_loader = DataLoader( val_dataset, batch_size = 10, shuffle = True, ) visualize_predictions(model, vis_loader, device, class_names, num_images = 4) Evaluation of Model Performance Our Cat Expression Classifier, built on a modified ResNet18 architecture, demonstrates a promising ability to classify cat expressions into four categories: alarmed, angry, calm, and pleased. Here, we provide a detailed analysis of the model\u0026rsquo;s performance based on our the training and validation efforts.\nOverall Performance Metrics The model achieves an overall accuracy of 68.18% on the validation set. This is a decent foundation but indicates room for further refinement, especially in distinguishing between expressions that share subtle features. Here is a breakdown of the key performance metrics:\nPrecision: Measures the accuracy of positive predictions. for example, the pleased category shows high precision, indicating that the model reliably identifies this expression. Recall: Reflects the model\u0026rsquo;s ability to identify all relevant instances of a class. The angry category has a high recall, suggesting that the model effectively captures most of the angry expressions. F1-Score: Balances precision and recall and is particularly useful in scenarios where class distribution is uneven. Confusion Matrix Insights the confusion matrix provides a granular view of the model\u0026rsquo;s performance across the different classes. It highlights specific areas where the model performs well and others where it struggles, such as:\nMisclassifications between alarmed and angry suggest that the model may be conflating these expressions due to their similar features. The high accuracy in identifying pleased expressions shows that distinct features of this mood are well captured by the model. Training and Validation Losses The training and validation loss plots reveal the learning dynamics over the epochs:\nA steady decrease in training loss indicates that the model is effectively learning from the training data. The pattern of validation loss provides insights into the model\u0026rsquo;s generalization ability. Increases in validation loss suggest moments where the model might be overfitting to the training data. Trying out VisionTransformers Data Transformations for Vision Transformer When transitioning from a CNN like ResNet18 to a Vision Transformer (ViT), it\u0026rsquo;s essential to evaluate whether the existing preprocessing steps - particulary the data transformations - are suitable for the new model architecture. For ViT , wed must consider their unique handling of image data, which relies on dividing the image into fixed-size patches and understanding global dependencies through self-attention mechanisms.\nFor this exercise, we will maintain the same transformations we have previously defined.\nThe decision to retain the initial transformations is based on the principle of consistency and the minimal impact expected by changing model architectures regarding how images are scaled and augmented. The chosen transformations ensure that the images are adequately prepared for the neural network without introducing complexities or distortions that could hinder the learning of global patterns, which are vital for Vision Transformers due to their reliance on self-attention mechanisms.\nAdditionally, maintaining these transformations allows for a more straightforward comparison between the ResNet18 model and the Vision Transformer model, as any changes in model performance can more confidently be attributed to the architectural differences rather than changes in data preprocessing.\nLoad Pre-Trained Vision Transformer Model First, we need to load the ViT model that has been pre-trained on a large dataset. We\u0026rsquo;ll then adapt the classifier head to our needs, which is classifying cat moods into four categories.\n# load the ViT pre-trained model weights_vit = models.ViT_B_16_Weights.DEFAULT model_vit = models.vit_b_16(weights = weights_vit) # print the model structure to understand what needs to be replaced print(model_vit) Downloading: \u0026quot;https://download.pytorch.org/models/vit_b_16-c867db91.pth\u0026quot; to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth 100%|██████████| 330M/330M [00:02\u0026lt;00:00, 124MB/s] VisionTransformer( (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16)) (encoder): Encoder( (dropout): Dropout(p=0.0, inplace=False) (layers): Sequential( (encoder_layer_0): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_1): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_2): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_3): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_4): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_5): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_6): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_7): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_8): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_9): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_10): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_11): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) ) (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True) ) (heads): Sequential( (head): Linear(in_features=768, out_features=1000, bias=True) ) ) Freezing the Encoder Layers Freezing the encoder layers prevents their weights from being updated during training, which means they retain the knowledge they have already gained from ImageNet. We only want to train the classifier that we will modify to our specific task.\n# freeze all layers in the model by disabling gradient computation for param in model_vit.parameters(): param.requires_grad = False Modify the Classifier The standard ViT model includes a classifier at the end (usually named heads in torchvision models), which is a linear layer designed for the original classification task, e.g. 1000 classes for ImageNet. We will replace this with a new classifier suited for our task (4 cat moods).\n# replace the classifier head # as we saw in the architecture above, the classifier is called `heads` num_features = model_vit.heads.head.in_features # ge tthe number of input features # replace with a new head for len(class_names) = 4 model_vit.heads = nn.Sequential( nn.Linear(num_features, len(class_names)) ) # move model to appropriate device model_vit.to(device) VisionTransformer( (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16)) (encoder): Encoder( (dropout): Dropout(p=0.0, inplace=False) (layers): Sequential( (encoder_layer_0): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_1): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_2): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_3): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_4): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_5): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_6): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_7): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_8): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_9): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_10): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) (encoder_layer_11): EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate='none') (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) ) ) (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True) ) (heads): Sequential( (0): Linear(in_features=768, out_features=4, bias=True) ) ) Define Loss Function and Optimizer Now, define the loss function and an optimizer. Since we are only training the classifier layer, ensure the optimizer is set to only update the parameters of the classifier.\n# optimizer will not change, but still show it here: criterion = nn.CrossEntropyLoss() # optimizer - only optimize the classifier parameters optimizer = optim.Adam(model_vit.heads.parameters(), lr = 0.001) Training Loop Here, we revisit the training process, adapting our previously established procedures to the Vision Transformer (ViT) model. Much like our approach with Resnet18, we utilize a similar training loop structure to ensure consistency and comparability. the core steps of training - forward pass, loss computation, backward pass, and parameters update - are maintained, but they are now applied to a differently structured model that leverages self-attention mechanisms rather than convolutional layers. This section briefly outlines these steps, focusing on any adjustments specific to the ViT to optimize it for our cat mood classification task.\nmodel_filename = \u0026#39;vit_cat_mood.pth\u0026#39; model_data_filename = \u0026#39;vit_training_data.pkl\u0026#39; train_losses, val_losses = training_loop(should_train_vit, model_vit, criterion, optimizer, model_filename, model_data_filename, num_epochs = 25) Running on Google Colab. Model loaded and set to evaluation mode. Training data loaded successfully. Model Evaluation Confusion Matrix The confusion matrix below shows the following results:\nClass alarmed: moderate confusion with other classes, indicating difficulty in distinguishing alarmed from other moods. Class angry: high accuracy, showing that `angry is well-recognized, with few misclassifications Class calm: some confusion, particularly with pleased, suggesting similar features or expressions between these moods that the model confuses Class pleased: best performance, indicating clear distinguishing features that the model learnes effectively Considerations on Data Quality Throughout the development and evaluation of our models, it has become evident that the quality of the dataset significantly impacts the classification accuracy. Certain misclassifications observed, such as the confusion between \u0026lsquo;pleased\u0026rsquo; and \u0026lsquo;calm\u0026rsquo; or \u0026lsquo;alarmed\u0026rsquo; and \u0026lsquo;angry,\u0026rsquo; suggest that the labels may not always align perfectly with the visual cues present in the images. This discrepancy can stem from subjective interpretations of cat expressions during labeling. Improving the dataset by refining the labeling process, possibly with the assistance of animal behavior experts, or by curating a more consistently labeled dataset could enhance model performance. Enhancing data quality would help in training more accurate and reliable models, thereby increasing the robustness of the classification outcomes.\nClassification Report From the classification report, we can draw the following conclusions:\nClass pleased shows the highest precision, indicating a high rate of true positive predictions Class angry has the highes recall, suggesting effective identification of this mood Classes angry and pleased show high F1-scores, indicating robust performance. Overall Accuracy The model achieves and accuracy of 74.55%, which is a solid performance but suggests room for improvement, particularly in reducing misclassifications among less distinct moods.\ncm, clf_report_df = evaluate_model(model_vit, val_loader, device) # Plot the confusion matrix plt.figure(figsize=(10, 8)) sns.heatmap(cm, annot=True, fmt=\u0026#39;d\u0026#39;, cmap=\u0026#39;Blues\u0026#39;) plt.title(\u0026#39;Confusion Matrix\u0026#39;) plt.ylabel(\u0026#39;True Label\u0026#39;) plt.xlabel(\u0026#39;Predicted Label\u0026#39;) plt.show() # Print classification report print(\u0026#39;Classification Report:\u0026#39;) print(clf_report_df) Classification Report: precision recall f1-score support 0 0.461538 0.428571 0.444444 14.000000 1 0.815789 0.885714 0.849315 35.000000 2 0.625000 0.535714 0.576923 28.000000 3 0.857143 0.909091 0.882353 33.000000 accuracy 0.745455 0.745455 0.745455 0.745455 macro avg 0.689868 0.689773 0.688259 110.000000 weighted avg 0.734544 0.745455 0.738361 110.000000 Training and Validation Losses The plot of training loss shows a consistent decrease, indicating that the model is effectively learning from the data. The vlaidation loss decreases alongside the training loss but begins to plateau, suggesting that the model might be nearing its learning capacity with the current configuration and dataset.\n# take the tracked losses from thet training loop plot_losses(train_losses, val_losses) visualize_predictions(model_vit, vis_loader, device, class_names, num_images = 4) Using the Model for Inference on New Data Let\u0026rsquo;s try out the model on new, unseen data. This photo did not come from a dataset, but rather from a friend of mine who wants to know her cat\u0026rsquo;s mood.\nFor inference, we first need to apply some simple transformation (not augmentation). In this case, we can use our previously defined val_transforms:\nval_transforms = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.ConvertImageDtype(torch.float), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) ]) Then, we can define a simple function to open, transform and add a batch dimension to the file we want to pass.\nThen, the function will pass the image to the model to make inference. This latter step is done in a way so that the gradients are not computed, and the image data is passed as a forward pass only.\nFinally, we will include a de-normalization to the transformed image, so that we can display it along with the predicted label.\n# Function to classify a single image and display it with the predicted label def classify_and_display_image(image_path): image = Image.open(image_path) transformed_image = val_transforms(image) image_tensor = transformed_image.unsqueeze(0) # Add batch dimension with torch.no_grad(): # Disable gradient calculation output = model(image_tensor) _, predicted = torch.max(output, 1) label = class_names[predicted.item()] # Convert the transformed image tensor back to a PIL image for display transformed_image = transformed_image.permute(1, 2, 0) # Change from (C, H, W) to (H, W, C) transformed_image = transformed_image.numpy() # Denormalize the image mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) transformed_image = std * transformed_image + mean transformed_image = np.clip(transformed_image, 0, 1) # Display the image with the predicted label plt.imshow(transformed_image) plt.title(f\u0026#39;Predicted Label: {label}\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() # Example usage classify_and_display_image(\u0026#39;gato.jpg\u0026#39;) Conclusion This tutorial guides you through creating a cat expression classifier using convolutional neural networks with ResNet18 and later with a Vision Transformer (ViT). It demonstrates how to apply transfer learning to improve efficiency and accuracy with limited data.\nThe guide is structured to provide clear steps and practical examples for each phase of the project, from data preprocessing and model training to evaluation. By breaking down complex concepts and processes into manageable parts, it ensures that readers can easily follow along and apply these techniques to their projects.\n","permalink":"http://localhost:1313/posts/20240515_cat_mood_classification/20240515_cat_mood_classification/","summary":"Things we learn here include image data exploration, transfer learning, custom datasets, comparing ML models, saving/loading models and model data, conditional setup for different work environments.","title":"Transfer Learning Classifier Using PyTorch"},{"content":" Part 1: Collecting and Cleaning the Data import pandas as pd import numpy as np import matplotlib.pyplot as plt import plotly.graph_objects as go import plotly.express as px import json Importing the excel files. These files come from the INE (Electoral Institute in Mexico). Then, we can do some data wrangling to filter the relevant data.\nThe data comes from these two sources:\nThe voter registration data: The Open Data page The elections results data: Election Results Let\u0026rsquo;s explore the data as it comes.\n(Note that, unfortunately, the dataframe output did not export correctly to the file displayed here).\ndf_sx = pd.read_excel(\u0026#39;data/padron_y_ln_sexo.xlsx\u0026#39;) print(len(df_sx.columns)) df_sx.head() 15 CLAVE\\nENTIDAD NOMBRE\\nENTIDAD CLAVE\\nDISTRITO NOMBRE\\nDISTRITO CLAVE\\nMUNICIPIO NOMBRE\\nMUNICIPIO SECCION PADRON\\nHOMBRES PADRON\\nMUJERES PADRON\\nNO BINARIO PADRON\\nELECTORAL LISTA\\nHOMBRES LISTA\\nMUJERES LISTA\\nNO BINARIO LISTA\\nNOMINAL 0 1 RESIDENTES EXTRANJERO 0.0 0 0.0 0 0.0 8444 5756 0 14200 3452 2577 0 6029 1 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 338.0 973 1013 0 1986 970 1011 0 1981 2 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 339.0 895 954 0 1849 893 953 0 1846 3 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 340.0 951 1001 0 1952 949 998 0 1947 4 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 341.0 1174 1184 0 2358 1172 1184 0 2356 We start by changing the names of the columns for readability.\n# change column names col_names_sx = [\u0026#39;Clave Entidad\u0026#39;, \u0026#39;Nombre Entidad\u0026#39;, \u0026#39;Clave Distrito\u0026#39;, \u0026#39;Nombre Distrito\u0026#39;, \u0026#39;Clave Municipio\u0026#39;, \u0026#39;Nombre Municipio\u0026#39;, \u0026#39;Seccion\u0026#39;, \u0026#39;Padron Hombre\u0026#39;, \u0026#39;Padron Mujeres\u0026#39;, \u0026#39;Padron No Binario\u0026#39;, \u0026#39;Padron Electoral\u0026#39;, \u0026#39;Lista Hombres\u0026#39;, \u0026#39;Lista Mujeres\u0026#39;, \u0026#39;Lista No Binario\u0026#39;, \u0026#39;Lista Nominal\u0026#39;] df_sx.columns = col_names_sx df_sx.head() Clave Entidad Nombre Entidad Clave Distrito Nombre Distrito Clave Municipio Nombre Municipio Seccion Padron Hombre Padron Mujeres Padron No Binario Padron Electoral Lista Hombres Lista Mujeres Lista No Binario Lista Nominal 0 1 RESIDENTES EXTRANJERO 0.0 0 0.0 0 0.0 8444 5756 0 14200 3452 2577 0 6029 1 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 338.0 973 1013 0 1986 970 1011 0 1981 2 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 339.0 895 954 0 1849 893 953 0 1846 3 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 340.0 951 1001 0 1952 949 998 0 1947 4 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 341.0 1174 1184 0 2358 1172 1184 0 2356 Verify the data types in the dataframe and whether there are null values\nprint(df_sx.dtypes) print(df_sx.isnull().sum()) Clave Entidad object Nombre Entidad object Clave Distrito float64 Nombre Distrito object Clave Municipio float64 Nombre Municipio object Seccion float64 Padron Hombre int64 Padron Mujeres int64 Padron No Binario int64 Padron Electoral int64 Lista Hombres int64 Lista Mujeres int64 Lista No Binario int64 Lista Nominal int64 dtype: object Clave Entidad 0 Nombre Entidad 1 Clave Distrito 1 Nombre Distrito 1 Clave Municipio 1 Nombre Municipio 1 Seccion 1 Padron Hombre 0 Padron Mujeres 0 Padron No Binario 0 Padron Electoral 0 Lista Hombres 0 Lista Mujeres 0 Lista No Binario 0 Lista Nominal 0 dtype: int64 There are indeed some null values in some of the columns. Since the null values live in rows that we will not need, i.e. we will filter the rows to include only the values for the State of \u0026ldquo;Quintana Roo\u0026rdquo;, we don\u0026rsquo;t need to bother in removing or doing any data gymnastics to those null values.\nLet\u0026rsquo;s filter the data we need now.\n# filter rows by state quintana roo df_sx_qroo = df_sx[df_sx[\u0026#39;Nombre Entidad\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] # select columns for padron electoral df_pe_sx_qroo = df_sx_qroo.iloc[:,:11] # select columns for lista nominal cols_to_drop = df_sx_qroo.columns[7:11] df_ln_sx_qroo = df_sx_qroo.drop(columns = cols_to_drop) df_ln_sx_qroo.head() Clave Entidad Nombre Entidad Clave Distrito Nombre Distrito Clave Municipio Nombre Municipio Seccion Lista Hombres Lista Mujeres Lista No Binario Lista Nominal 50685 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 182.0 1046 1015 0 2061 50686 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 183.0 1056 1085 0 2141 50687 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 184.0 982 981 0 1963 50688 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 185.0 1228 1198 0 2426 50689 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 186.0 525 465 0 990 Election Results. First, we will work with the data related to the election results.\nLet\u0026rsquo;s load all the files separately (as they were available from the source).\n# load the files df_re_2009 = pd.read_csv(\u0026#39;data/DIPUTACIONES_FED_MR_2009/2009_SEE_DIP_FED_MR_NAL_SEC.csv\u0026#39;) df_re_2012 = pd.read_csv(\u0026#39;data/DIPUTACIONES_FED_MR_2012/2012_SEE_DIP_FED_MR_NAL_SEC.csv\u0026#39;) df_re_2015 = pd.read_csv(\u0026#39;data/DIPUTACIONES_FED_MR_2015/2015_SEE_DIP_FED_MR_NAL_SEC.csv\u0026#39;) df_re_2018 = pd.read_csv(\u0026#39;data/DIPUTACIONES_FED_MR_2018/2018_SEE_DIP_FED_MR_NAL_SEC.csv\u0026#39;) df_re_2021 = pd.read_csv(\u0026#39;data/DIPUTACIONES_FED_MR_2021/2021_SEE_DIP_FED_MR_NAL_SEC.csv\u0026#39;) # filter rows by state quintana roo df_re_2009_qroo = df_re_2009[df_re_2009[\u0026#39;NOMBRE_ESTADO\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] df_re_2012_qroo = df_re_2012[df_re_2012[\u0026#39;NOMBRE_ESTADO\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] df_re_2015_qroo = df_re_2015[df_re_2015[\u0026#39;NOMBRE_ESTADO\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] df_re_2018_qroo = df_re_2018[df_re_2018[\u0026#39;NOMBRE_ESTADO\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] df_re_2021_qroo = df_re_2021[df_re_2021[\u0026#39;NOMBRE_ESTADO\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] df_re_2021_qroo.head() CIRCUNSCRIPCION ID_ESTADO NOMBRE_ESTADO ID_DISTRITO_FEDERAL CABECERA_DISTRITAL_FEDERAL ID_MUNICIPIO MUNICIPIO SECCION CASILLAS PAN ... PVEM_PT PVEM_MORENA PT_MORENA CAND_IND1 CAND_IND2 CAND_IND3 NUM_VOTOS_CAN_NREG NUM_VOTOS_NULOS TOTAL_VOTOS LISTA_NOMINAL 49016 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 0 NaN 0 NaN 0.0 ... 0.0 0.0 0.0 NaN NaN NaN 0.0 0.0 2.0 2 49017 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 182 3.0 180.0 ... 0.0 3.0 2.0 NaN NaN NaN 0.0 29.0 1097.0 2160 49018 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 183 3.0 103.0 ... 0.0 5.0 3.0 NaN NaN NaN 3.0 30.0 1083.0 2159 49019 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 184 3.0 91.0 ... 0.0 10.0 6.0 NaN NaN NaN 1.0 46.0 1169.0 1981 49020 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 185 4.0 113.0 ... 0.0 3.0 6.0 NaN NaN NaN 1.0 38.0 1377.0 2371 5 rows × 34 columns\nWe can already see that there are some columns that are not needed. These columns, in particular, are the independent candidate columns, and they are effectively empty. These columns\u0026rsquo; names all begin with CAND. We can use that to quickly drop all of them.\nWe can also drop the null value included in the municipality (MUNICIPIO) columns, which leaked after filtering by the State before. We need to drop this one too.\n# define a list of all the dataframes to loop over them below df_re_all_years = [df_re_2009_qroo, df_re_2012_qroo, df_re_2015_qroo, df_re_2018_qroo, df_re_2021_qroo] # drop independent candidates and any rows with NaN in the MUNICIPIO columns for df in df_re_all_years: # drop rows where \u0026#39;MUNICIPIO\u0026#39; is NaN df.dropna(subset=[\u0026#39;MUNICIPIO\u0026#39;], inplace = True) # select columns that begin with \u0026#34;CAND\u0026#34; cols_cand_ind = df.columns[df.columns.str.startswith(\u0026#39;CAND\u0026#39;)] # drop the identified columns df.drop(columns=cols_cand_ind, inplace = True) df_re_all_years[-1].head() CIRCUNSCRIPCION ID_ESTADO NOMBRE_ESTADO ID_DISTRITO_FEDERAL CABECERA_DISTRITAL_FEDERAL ID_MUNICIPIO MUNICIPIO SECCION CASILLAS PAN ... PAN_PRD PRI_PRD PVEM_PT_MORENA PVEM_PT PVEM_MORENA PT_MORENA NUM_VOTOS_CAN_NREG NUM_VOTOS_NULOS TOTAL_VOTOS LISTA_NOMINAL 49017 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 182 3.0 180.0 ... 0.0 2.0 5.0 0.0 3.0 2.0 0.0 29.0 1097.0 2160 49018 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 183 3.0 103.0 ... 0.0 2.0 5.0 0.0 5.0 3.0 3.0 30.0 1083.0 2159 49019 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 184 3.0 91.0 ... 0.0 2.0 12.0 0.0 10.0 6.0 1.0 46.0 1169.0 1981 49020 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 185 4.0 113.0 ... 0.0 1.0 15.0 0.0 3.0 6.0 1.0 38.0 1377.0 2371 49021 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 186 2.0 37.0 ... 0.0 0.0 3.0 0.0 11.0 7.0 0.0 23.0 650.0 972 5 rows × 31 columns\nNow we can extract the political party names from each of the dataframes. At each election year, the parties may be different, and also there are alliances which make this somewhat more complicated.\n# List to store party names lists for each DataFrame party_names_per_df = [] for df in df_re_all_years: party_names = [] # Empty list to store party names for current DataFrame # Get a list of column names column_names = list(df.columns) try: # Find the indices of \u0026#34;CASILLAS\u0026#34; and \u0026#34;NUM_VOTOS_CAN_NREG\u0026#34; (handle potential errors) casillas_index = column_names.index(\u0026#39;CASILLAS\u0026#39;) num_votos_index = column_names.index(\u0026#39;NUM_VOTOS_CAN_NREG\u0026#39;) # Extract party names between the indices (avoid out-of-bounds) party_names = column_names[casillas_index + 1:min(num_votos_index, len(column_names))] except ValueError: # Handle cases where \u0026#34;CASILLAS\u0026#34; or \u0026#34;NUM_VOTOS_CAN_NREG\u0026#34; might not exist print(f\u0026#34;\\nWARNING: \u0026#39;CASILLAS\u0026#39; or \u0026#39;NUM_VOTOS_CAN_NREG\u0026#39; not found in DataFrame\u0026#34;) # Append the party names list for this DataFrame party_names_per_df.append(party_names) party_names_per_df [['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'CONV', 'NVA_ALIANZA', 'PSD', 'PRIMERO_MEXICO', 'SALVEMOS_MEXICO'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NVA_ALIANZA', 'PRI_PVEM', 'PRD_PT_MC', 'PRD_PT', 'PRD_MC', 'PT_MC'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NVA_ALIANZA', 'MORENA', 'PH', 'ES', 'PAN_NVA_ALIANZA', 'PRI_PVEM', 'PRD_PT'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NA', 'MORENA', 'ES', 'PAN_PRD_MC', 'PAN_PRD', 'PAN_MC', 'PRD_MC', 'PRI_PVEM_NA', 'PRI_PVEM', 'PRI_NA', 'PVEM_NA', 'PT_MORENA_ES', 'PT_MORENA', 'PT_ES', 'MORENA_ES'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'MORENA', 'PES', 'RSP', 'FXM', 'PAN_PRI_PRD', 'PAN_PRI', 'PAN_PRD', 'PRI_PRD', 'PVEM_PT_MORENA', 'PVEM_PT', 'PVEM_MORENA', 'PT_MORENA']] Just to get a feel of the data, we can see how many rows there are in each of the dataframes.\nprint(\u0026#39;Number of lines in the 2009 election dataframe: \u0026#39;, len(df_re_2009_qroo) ) print(\u0026#39;Number of lines in the 2012 election dataframe: \u0026#39;, len(df_re_2012_qroo) ) print(\u0026#39;Number of lines in the 2015 election dataframe: \u0026#39;, len(df_re_2015_qroo) ) print(\u0026#39;Number of lines in the 2018 election dataframe: \u0026#39;, len(df_re_2018_qroo) ) print(\u0026#39;Number of lines in the 2021 election dataframe: \u0026#39;, len(df_re_2021_qroo) ) Number of lines in the 2009 election dataframe: 729 Number of lines in the 2012 election dataframe: 831 Number of lines in the 2015 election dataframe: 938 Number of lines in the 2018 election dataframe: 939 Number of lines in the 2021 election dataframe: 1033 Preliminary Visualization Visualizaremos la informacion agregando los datos por año. De esta manera, tendremos un historial de tiempo por cada municipio, en el cual podemos ver el historial de los resultados de cada partido politico en cada municipio.\nHere we visualize the information by aggregating the data per year. In this way, we will have a time history per municipality (municipio), where we can see the history of the results for each political party in each municipality.\nGroup by Political Party Para un analisis mas compacto, podemos agrupar los partidos politicos incluyendo sus alianzas. De este modo, por ejemplo, tendriamos que:\nFor a more compact analysis, we can group the political parties including the alliances. In this we, we would have, for example:\n\u0026#39;PAN\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PAN_NVA_ALIANZA\u0026#39;, \u0026#39;PAN_PRD_MC\u0026#39;, \u0026#39;PAN_PRD\u0026#39;, \u0026#39;PAN_MC\u0026#39;, \u0026#39;PAN_PRI_PRD\u0026#39;, \u0026#39;PAN_PRI\u0026#39;] Which means that the party PAN would also include the alliances with the other parties named Nueva Alianza, an alliance with PRD named PAN_PRD, etc.\nNOTE # write a dictionary with the alliances per party alliance_mapping = { \u0026#39;PAN\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PAN_NVA_ALIANZA\u0026#39;, \u0026#39;PAN_PRD\u0026#39;], \u0026#39;PRI\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PRI_PVEM\u0026#39;, \u0026#39;PRI_NA\u0026#39;, \u0026#39;PRI_PVEM_NA\u0026#39;, \u0026#39;PAN_PRI_PRD\u0026#39;, \u0026#39;PAN_PRI\u0026#39;, \u0026#39;PRI_PRD\u0026#39;], \u0026#39;PRD\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;PRD_PT\u0026#39;, \u0026#39;PAN_PRI_PRD\u0026#39;], \u0026#39;PVEM\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;PVEM_NA\u0026#39;, \u0026#39;PVEM_PT\u0026#39;], \u0026#39;PT\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;PT_ES\u0026#39;], \u0026#39;MC\u0026#39;: [\u0026#39;MC\u0026#39;, \u0026#39;PRD_PT_MC\u0026#39;, \u0026#39;PRD_MC\u0026#39;, \u0026#39;PT_MC\u0026#39;, \u0026#39;PAN_PRD_MC\u0026#39;, \u0026#39;PAN_MC\u0026#39;], \u0026#39;MORENA\u0026#39;: [\u0026#39;MORENA\u0026#39;, \u0026#39;PT_MORENA_ES\u0026#39;, \u0026#39;PT_MORENA\u0026#39;, \u0026#39;MORENA_ES\u0026#39;, \u0026#39;PVEM_PT_MORENA\u0026#39;, \u0026#39;PVEM_MORENA\u0026#39;], \u0026#39;NVA_ALIANZA\u0026#39;: [\u0026#39;NVA_ALIANZA\u0026#39;], \u0026#39;PSD\u0026#39;: [\u0026#39;PSD\u0026#39;], \u0026#39;PRIMERO_MEXICO\u0026#39;: [\u0026#39;PRIMERO_MEXICO\u0026#39;], \u0026#39;SALVEMOS_MEXICO\u0026#39;: [\u0026#39;SALVEMOS_MEXICO\u0026#39;], \u0026#39;PH\u0026#39;: [\u0026#39;PH\u0026#39;], \u0026#39;ES\u0026#39;: [\u0026#39;ES\u0026#39;], \u0026#39;NA\u0026#39;: [\u0026#39;NA\u0026#39;], \u0026#39;PES\u0026#39;: [\u0026#39;PES\u0026#39;], \u0026#39;RSP\u0026#39;: [\u0026#39;RSP\u0026#39;], \u0026#39;FXM\u0026#39;: [\u0026#39;FXM\u0026#39;], } main_parties = { \u0026#39;PAN\u0026#39;: \u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;: \u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;: \u0026#39;PRD\u0026#39;, \u0026#39;PVEM\u0026#39;: \u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;: \u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;: \u0026#39;MC\u0026#39;, \u0026#39;MORENA\u0026#39;: \u0026#39;MORENA\u0026#39;, \u0026#39;NVA_ALIANZA\u0026#39;: \u0026#39;NVA_ALIANZA\u0026#39;, \u0026#39;PSD\u0026#39;: [\u0026#39;PSD\u0026#39;], \u0026#39;PRIMERO_MEXICO\u0026#39;: [\u0026#39;PRIMERO_MEXICO\u0026#39;], \u0026#39;SALVEMOS_MEXICO\u0026#39;: [\u0026#39;SALVEMOS_MEXICO\u0026#39;], \u0026#39;PH\u0026#39;: [\u0026#39;PH\u0026#39;], \u0026#39;ES\u0026#39;: [\u0026#39;ES\u0026#39;], \u0026#39;NA\u0026#39;: [\u0026#39;NA\u0026#39;], \u0026#39;PES\u0026#39;: [\u0026#39;PES\u0026#39;], \u0026#39;RSP\u0026#39;: [\u0026#39;RSP\u0026#39;], \u0026#39;FXM\u0026#39;: [\u0026#39;FXM\u0026#39;], # Add more as needed for each unique party or alliance... } Vote Distribution Among Alliances The way this works is that the votes for any alliance are equally divided amongs the parties that conform the alliance.\ndf_re_2018_qroo.head() CIRCUNSCRIPCION ID_ESTADO NOMBRE_ESTADO ID_DISTRITO CABECERA_DISTRITAL ID_MUNICIPIO MUNICIPIO SECCION CASILLAS PAN ... PRI_NA PVEM_NA PT_MORENA_ES PT_MORENA PT_ES MORENA_ES NUM_VOTOS_CAN_NREG NUM_VOTOS_NULOS TOTAL_VOTOS LISTA_NOMINAL 48293 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 1 BENITO JUAREZ 962 3 79.0 ... 3.0 0.0 18.0 10.0 0.0 7.0 9.0 25.0 879.0 1574 48294 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 182 3 279.0 ... 0.0 0.0 4.0 5.0 3.0 5.0 4.0 50.0 1275.0 2116 48295 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 183 3 190.0 ... 1.0 0.0 4.0 1.0 0.0 0.0 1.0 30.0 1171.0 2117 48296 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 184 3 237.0 ... 6.0 3.0 4.0 5.0 0.0 0.0 0.0 64.0 1227.0 1919 48297 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 185 4 229.0 ... 2.0 1.0 7.0 5.0 1.0 3.0 0.0 52.0 1446.0 2308 5 rows × 34 columns\nalliance_votes_mapping = { \u0026#39;PAN_NVA_ALIANZA\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;NVA_ALIANZA\u0026#39;], \u0026#39;PAN_PRD\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PRI_PVEM\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PVEM\u0026#39;], \u0026#39;PRI_NA\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PRI_PVEM_NA\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PVEM\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PAN_PRI_PRD\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PAN_PRI\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;], \u0026#39;PRI_PRD\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PRD_PT\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;PT\u0026#39;], \u0026#39;PVEM_NA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PVEM_PT\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;], \u0026#39;PT_ES\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PRD_PT_MC\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PRD_MC\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PT_MC\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PAN_PRD_MC\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRD\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PAN_MC\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;MORENA_ES\u0026#39;: [\u0026#39;MORENA\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PT_MORENA_ES\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PT_MORENA\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;], \u0026#39;PVEM_PT_MORENA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;], \u0026#39;PVEM_MORENA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;MORENA\u0026#39;], } def distribute_alliance_votes(df, alliances): # ensure that party columns exist in the dataframe, add them if the do not all_parties = set(party for parties in alliances.values() for party in parties) for party in all_parties: if party not in df.columns: df[party] = 0 # distribute the votes from each alliance to the respective parties for alliance, parties in alliances.items(): if alliance in df.columns: split_votes = df[alliance] / len(parties) for party in parties: df[party] += split_votes # optionally remove the alliance columns df.drop(columns = list(alliances.keys()), inplace = True, errors = \u0026#39;ignore\u0026#39;) return df # apply the vote split function to all the dataframes: df_re_2009_qroo = distribute_alliance_votes(df_re_2009_qroo, alliance_votes_mapping) df_re_2012_qroo = distribute_alliance_votes(df_re_2012_qroo, alliance_votes_mapping) df_re_2015_qroo = distribute_alliance_votes(df_re_2015_qroo, alliance_votes_mapping) df_re_2018_qroo = distribute_alliance_votes(df_re_2018_qroo, alliance_votes_mapping) df_re_2021_qroo = distribute_alliance_votes(df_re_2021_qroo, alliance_votes_mapping) df_re_2018_qroo.head() CIRCUNSCRIPCION ID_ESTADO NOMBRE_ESTADO ID_DISTRITO CABECERA_DISTRITAL ID_MUNICIPIO MUNICIPIO SECCION CASILLAS PAN ... PT MC NA MORENA ES NUM_VOTOS_CAN_NREG NUM_VOTOS_NULOS TOTAL_VOTOS LISTA_NOMINAL NVA_ALIANZA 48293 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 1 BENITO JUAREZ 962 3 80.166667 ... 64.000000 26.166667 14.166667 525.500000 39.500000 9.0 25.0 879.0 1574 0 48294 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 182 3 281.000000 ... 42.333333 48.500000 14.666667 405.333333 26.333333 4.0 50.0 1275.0 2116 0 48295 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 183 3 192.000000 ... 44.833333 61.000000 14.166667 445.833333 24.333333 1.0 30.0 1171.0 2117 0 48296 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 184 3 240.000000 ... 45.833333 52.500000 24.166667 444.833333 19.333333 0.0 64.0 1227.0 1919 0 48297 3 23 QUINTANA ROO 1 PLAYA DEL CARMEN 2 COZUMEL 185 4 231.500000 ... 43.333333 62.000000 19.500000 502.333333 24.333333 0.0 52.0 1446.0 2308 0 5 rows × 23 columns\n# list to store party names lists for each DataFrame party_names_per_df = [] for df in df_re_all_years: party_names = [] # empty list to store party names for current DataFrame # get a list of column names column_names = list(df.columns) try: # find the indices of \u0026#34;CASILLAS\u0026#34; and \u0026#34;NUM_VOTOS_CAN_NREG\u0026#34; (handle potential errors) casillas_index = column_names.index(\u0026#39;CASILLAS\u0026#39;) num_votos_index = column_names.index(\u0026#39;NUM_VOTOS_CAN_NREG\u0026#39;) # extract party names between the indices (avoid out-of-bounds) party_names = column_names[casillas_index + 1:min(num_votos_index, len(column_names))] except ValueError: # handle cases where \u0026#34;CASILLAS\u0026#34; or \u0026#34;NUM_VOTOS_CAN_NREG\u0026#34; might not exist print(f\u0026#34;\\nWARNING: \u0026#39;CASILLAS\u0026#39; or \u0026#39;NUM_VOTOS_CAN_NREG\u0026#39; not found in DataFrame\u0026#34;) # append the party names list for this DataFrame party_names_per_df.append(party_names) party_names_per_df [['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'CONV', 'NVA_ALIANZA', 'PSD', 'PRIMERO_MEXICO', 'SALVEMOS_MEXICO'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NVA_ALIANZA'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NVA_ALIANZA', 'MORENA', 'PH', 'ES'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'NA', 'MORENA', 'ES'], ['PAN', 'PRI', 'PRD', 'PVEM', 'PT', 'MC', 'MORENA', 'PES', 'RSP', 'FXM']] Visualizations Time History Here we develop a function to plot the historical number of votes per party. Each plot will show the data for a selected municipality. The idea is to have an interactive dashboard where one could easily select these parameters and access the plot.\n# function for plotting the time history, given a eyar, and a municipality def plot_aggregated_votes_by_main_party_px(df_list, main_parties, selected_municipality, election_years): \u0026#34;\u0026#34;\u0026#34; Plots an interactive line plot with filled areas to zero for each main party and its alliances, in a selected municipality across elections using Plotly Express. This approximates the non-stacked area plot behavior of the original function. \u0026#34;\u0026#34;\u0026#34; # initialize dictionary to hold vote totals for main parties votes_by_main_party = {main_party: [0] * len(election_years) for main_party in main_parties} # loop through each DataFrame and year for i, (df, year) in enumerate(zip(df_list, election_years)): # filter the DataFrame for the selected municipality if selected_municipality in df[\u0026#39;MUNICIPIO\u0026#39;].values: filtered_df = df[df[\u0026#39;MUNICIPIO\u0026#39;] == selected_municipality] # loop through each main party and its alliances for party in main_parties: # aggregate votes for each party in the alliance, adding to the main party\u0026#39;s total if party in filtered_df.columns: votes_by_main_party[party][i] += filtered_df[party].sum() # prepare the data for plotting data_for_plotting = [] for main_party, votes in votes_by_main_party.items(): for year, vote in zip(election_years, votes): data_for_plotting.append({\u0026#39;Election Year\u0026#39;: year, \u0026#39;Total Votes\u0026#39;: vote, \u0026#39;Party\u0026#39;: main_party}) df_plot = pd.DataFrame(data_for_plotting) # create the plot fig = px.line(df_plot, x=\u0026#39;Election Year\u0026#39;, y=\u0026#39;Total Votes\u0026#39;, color=\u0026#39;Party\u0026#39;, line_shape=\u0026#39;linear\u0026#39;, title=f\u0026#39;Total Votes per Party (Including Alliances), in {selected_municipality}\u0026#39;) # customize the layout fig.update_traces(mode=\u0026#39;lines\u0026#39;, line=dict(width=2.5), fill=\u0026#39;tozeroy\u0026#39;) fig.update_layout(xaxis_title=\u0026#39;Election Year\u0026#39;, yaxis_title=\u0026#39;Total Votes\u0026#39;, legend_title=\u0026#39;Party\u0026#39;, font=dict(family=\u0026#34;Arial, sans-serif\u0026#34;, size=12, color=\u0026#34;#333\u0026#34;), hovermode=\u0026#39;x unified\u0026#39;, legend = dict( orientation = \u0026#39;h\u0026#39;, yanchor = \u0026#39;bottom\u0026#39;, y = -0.6, # adjuist to fit layout xanchor = \u0026#39;center\u0026#39;, x = 0.5 )) return fig Let\u0026rsquo;s look at an example, by calling the municipality called Benito Juarez.\nmunicipality = \u0026#39;BENITO JUAREZ\u0026#39; # as an example election_years = [year for year in range(2009, 2022, 3)] plot_aggregated_votes_by_main_party_px(df_re_all_years, main_parties, municipality, election_years) Pie Chart def plot_election_pie_chart(selected_year, selected_municipality, df_re_all_years, main_parties): # mapping years to their indices in the list of dataframes year_to_index = {2009: 0, 2012: 1, 2015:2, 2018: 3, 2021: 4} selected_year_index = year_to_index.get(selected_year) if selected_year_index is None: print(f\u0026#34;No data available for the year {selected_year}.\u0026#34;) return # extract the dataframe for the selected year df_selected_year = df_re_all_years[selected_year_index] # filtering the df for the selected municipality df_municipality = df_selected_year[df_selected_year[\u0026#39;MUNICIPIO\u0026#39;] == selected_municipality] if df_municipality.empty: print(f\u0026#39;No data available for {selected_municipality}.\u0026#39;) return # aggregating votes for each main party votes_by_party = {main_party: 0 for main_party in main_parties} for party in main_parties: if party in df_municipality.columns: votes_by_party[party] += df_municipality[party].sum() # create the pie chart df_votes = pd.DataFrame(list(votes_by_party.items()), columns = [\u0026#39;Party\u0026#39;, \u0026#39;Votes\u0026#39;]) fig = px.pie(df_votes, values = \u0026#39;Votes\u0026#39;, names = \u0026#39;Party\u0026#39;, title = f\u0026#39;Vote Distribution in {selected_municipality}, {selected_year}\u0026#39;) # Update the traces to remove the text labels fig.update_traces(textinfo=\u0026#39;none\u0026#39;, hoverinfo=\u0026#39;label+percent\u0026#39;) return fig plot_election_pie_chart(2012, municipality, df_re_all_years, main_parties) Choropleth Now we can build some choropleths. To do this, we collected a geojson file for the municipalities in the State of Quintana Roo, Mexico.\nThe file can be found in this GitHub repository.\n# define some colors for each party party_colors = { \u0026#39;PAN\u0026#39;: \u0026#39;#0052CC\u0026#39;, # Blue \u0026#39;PRI\u0026#39;: \u0026#39;#013369\u0026#39;, # Dark Blue \u0026#39;PRD\u0026#39;: \u0026#39;#FFD700\u0026#39;, # Gold \u0026#39;PVEM\u0026#39;: \u0026#39;#00A550\u0026#39;, # Green \u0026#39;PT\u0026#39;: \u0026#39;#E00000\u0026#39;, # Red \u0026#39;MC\u0026#39;: \u0026#39;#FF7F00\u0026#39;, # Orange \u0026#39;MORENA\u0026#39;: \u0026#39;#6813D5\u0026#39;, # Purple \u0026#39;NVA_ALIANZA\u0026#39;: \u0026#39;#00AAAA\u0026#39;, # Teal \u0026#39;PSD\u0026#39;: \u0026#39;#555555\u0026#39;, # Dark Gray \u0026#39;PRIMERO_MEXICO\u0026#39;: \u0026#39;#9C2AA0\u0026#39;, # Magenta \u0026#39;SALVEMOS_MEXICO\u0026#39;: \u0026#39;#6CACE4\u0026#39;, # Light Blue \u0026#39;PH\u0026#39;: \u0026#39;#F0A3A3\u0026#39;, # Pink \u0026#39;ES\u0026#39;: \u0026#39;#2AD2C9\u0026#39;, # Cyan \u0026#39;NA\u0026#39;: \u0026#39;#F68B1F\u0026#39;, # Amber \u0026#39;PES\u0026#39;: \u0026#39;#93C572\u0026#39;, # Lime \u0026#39;RSP\u0026#39;: \u0026#39;#CC317C\u0026#39;, # Rose \u0026#39;FXM\u0026#39;: \u0026#39;#8B4513\u0026#39;, # SaddleBrown # Add more entries for each party as needed... } Now, for this map to work, we need the data in the geojson file to coincide exactly with the names of the municipalities in the dataframes.\nFirst, we explore the names of the municipalities in the dataframe for the recent elections, since this is the dataframe that contains all of the municipalities, including the most recently incorporated (i.e. in earlier elections, some of these municipalities did not exist).\n# from aggregate df, we pull the latest one, and see the unique names for the column \u0026#39;MUNICIPIO\u0026#39; df_re_all_years[-1][\u0026#39;MUNICIPIO\u0026#39;].unique() array(['COZUMEL', 'SOLIDARIDAD', 'TULUM', 'ISLA MUJERES', 'LAZARO CARDENAS', 'BENITO JUAREZ', 'FELIPE CARRILLO PUERTO', 'JOSE MARIA MORELOS', 'OTHON P. BLANCO', 'BACALAR', 'PUERTO MORELOS'], dtype=object) Likewise, we explore the goejson to see how the municipalities are named. Let\u0026rsquo;s explore the geojson file.\n# Load the GeoJSON file geojson_file_path = \u0026#39;utils/mexico-geojson/2022/states/Quintana Roo.json\u0026#39; with open(geojson_file_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: geojson_data = json.load(file) # Extract \u0026#34;NOM_MUN\u0026#34; values nom_mun_list = [feature[\u0026#39;properties\u0026#39;][\u0026#39;NOMGEO\u0026#39;] for feature in geojson_data[\u0026#39;features\u0026#39;]] # Print the list to see what values are stored print(nom_mun_list) ['Felipe Carrillo Puerto', 'Cozumel', 'Isla Mujeres', 'Othón P. Blanco', 'Solidaridad', 'Puerto Morelos', 'Benito Juárez', 'José María Morelos', 'Lázaro Cárdenas', 'Tulum', 'Bacalar'] NOTE After trying a few things out, the geojson was not working as intended. This was due to a difference in the name encoding. To fix this, we adjusted the geojson file in the property properties.NOMGEO/\nWe will do this programmatically, and save a new file with the new names.\n# Define a mapping of GeoJSON names to desired names, based on your DataFrame # This is a manual step but only needs to be done once name_mapping = { \u0026#39;Felipe Carrillo Puerto\u0026#39;: \u0026#39;FELIPE CARRILLO PUERTO\u0026#39;, \u0026#39;Cozumel\u0026#39;: \u0026#39;COZUMEL\u0026#39;, \u0026#39;Isla Mujeres\u0026#39;: \u0026#39;ISLA MUJERES\u0026#39;, \u0026#39;Othón P. Blanco\u0026#39;: \u0026#39;OTHON P. BLANCO\u0026#39;, \u0026#39;Solidaridad\u0026#39;: \u0026#39;SOLIDARIDAD\u0026#39;, \u0026#39;Puerto Morelos\u0026#39;: \u0026#39;PUERTO MORELOS\u0026#39;, \u0026#39;Benito Juárez\u0026#39;: \u0026#39;BENITO JUAREZ\u0026#39;, \u0026#39;José María Morelos\u0026#39;: \u0026#39;JOSE MARIA MORELOS\u0026#39;, \u0026#39;Lázaro Cárdenas\u0026#39;: \u0026#39;LAZARO CARDENAS\u0026#39;, \u0026#39;Tulum\u0026#39;: \u0026#39;TULUM\u0026#39;, \u0026#39;Bacalar\u0026#39;: \u0026#39;BACALAR\u0026#39; } # Iterate over each feature and adjust the names for feature in geojson_data[\u0026#39;features\u0026#39;]: original_name = feature[\u0026#39;properties\u0026#39;][\u0026#39;NOMGEO\u0026#39;] if original_name in name_mapping: feature[\u0026#39;properties\u0026#39;][\u0026#39;NOMGEO\u0026#39;] = name_mapping[original_name] #------------------------------------------------------------------------------# #--------------------- Save the modified GeoJSON to a new file ----------------# #------------------------------------------------------------------------------# # modified_geojson_file_path = \u0026#39;qroo_geojson_2022.json\u0026#39; # with open(modified_geojson_file_path, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: # json.dump(geojson_data, file, ensure_ascii=False, indent=4) # create year mapping dictionary # Mapping each election year to its corresponding dataframe df_dict = { 2009: df_re_2009_qroo, 2012: df_re_2012_qroo, 2015: df_re_2015_qroo, 2018: df_re_2018_qroo, 2021: df_re_2021_qroo, } # load the new geojson file here election_years = [year for year in range(2009, 2022, 3)] geojson_file_path = \u0026#39;data/shapefiles/qroo_geojson_2022.json\u0026#39; with open(geojson_file_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: geojson_data = json.load(file) Choropleth for Winning Party per Municipality Now let\u0026rsquo;s create a function to generate the choropleth. We note that for each election year, there will be a different municipality map. Therefore, in some years, some municipalities will be missing altogether.\nThis choropleth will show the winning party per municipality, at a given year.\ndef create_winning_party_per_year_choropleth(selected_year, geojson, main_parties, df_dict): # This function now handles a single year\u0026#39;s DataFrame and generates a choropleth map for that year. df_year = df_dict[selected_year] winning_party_by_municipality = {} for municipality in df_year[\u0026#39;MUNICIPIO\u0026#39;].unique(): votes_by_party = {main_party: 0 for main_party in main_parties} # for main_party, parties in alliance_mapping.items(): # for party in parties: # if party in df_year.columns: # votes_by_party[main_party] += df_year.loc[df_year[\u0026#39;MUNICIPIO\u0026#39;] == municipality, party].sum() for party in main_parties: if party in df_year.columns: votes_by_party[party] += df_year.loc[df_year[\u0026#39;MUNICIPIO\u0026#39;] == municipality, party].sum() winning_party = max(votes_by_party, key=votes_by_party.get) winning_party_by_municipality[municipality] = winning_party df_map = pd.DataFrame(list(winning_party_by_municipality.items()), columns=[\u0026#39;MUNICIPIO\u0026#39;, \u0026#39;Partido Ganador\u0026#39;]) df_map[\u0026#39;Year\u0026#39;] = selected_year fig = px.choropleth( df_map, geojson=geojson, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Partido Ganador\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_discrete_map=party_colors, projection=\u0026#34;mercator\u0026#34;, ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) fig.update_layout(title=f\u0026#34;Winning Party per Municipality, {selected_year}\u0026#34;) return fig # Return the figure for this specific year # Example of how to call the function for a single year year = 2021 df_year = df_dict[year] # Assuming df_dict is defined with years as keys fig = create_winning_party_per_year_choropleth(year, geojson_data, main_parties, df_dict) fig.show() Maps Showing the Gender Proportion per Municipality For this choropleth, we will need the voter registration dataframe, so we call it again.\nprint(df_ln_sx_qroo.columns) df_ln_sx_qroo.head() Index(['Clave Entidad', 'Nombre Entidad', 'Clave Distrito', 'Nombre Distrito', 'Clave Municipio', 'Nombre Municipio', 'Seccion', 'Lista Hombres', 'Lista Mujeres', 'Lista No Binario', 'Lista Nominal'], dtype='object') Clave Entidad Nombre Entidad Clave Distrito Nombre Distrito Clave Municipio Nombre Municipio Seccion Lista Hombres Lista Mujeres Lista No Binario Lista Nominal 50685 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 182.0 1046 1015 0 2061 50686 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 183.0 1056 1085 0 2141 50687 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 184.0 982 981 0 1963 50688 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 185.0 1228 1198 0 2426 50689 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 186.0 525 465 0 990 def create_gender_proportion_choropleth(df, geojson_data): # Aggregate data by MUNICIPIO if not already aggregated df_grouped = df.groupby(\u0026#39;Nombre Municipio\u0026#39;).sum().reset_index() # Calculate the percentage of women registered voters df_grouped[\u0026#39;Porcentaje Mujeres\u0026#39;] = (df_grouped[\u0026#39;Lista Mujeres\u0026#39;] / df_grouped[\u0026#39;Lista Nominal\u0026#39;]) * 100 # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson_data, locations=\u0026#39;Nombre Municipio\u0026#39;, color=\u0026#39;Porcentaje Mujeres\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_continuous_scale=px.colors.sequential.Plasma, projection=\u0026#34;mercator\u0026#34;, title=\u0026#34;Percentage of Women in Voter Registration\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) # Update layout for colorbar position fig.update_layout( coloraxis_colorbar=dict( title=\u0026#39;Women Percentage\u0026#39;, orientation=\u0026#39;h\u0026#39;, x=0.5, xanchor=\u0026#39;center\u0026#39;, y=-0.2, thickness=10, # Adjust the thickness of the colorbar len=0.65 # Set the length as a fraction of the plot area width ) ) return fig create_gender_proportion_choropleth(df_ln_sx_qroo, geojson_data) Map Grouped by Age Range df_age = pd.read_excel(\u0026#39;data/padron_y_ln_rango_edad.xlsx\u0026#39;) print(len(df_age.columns)) df_age.head() 87 CLAVE\\nENTIDAD NOMBRE\\nENTIDAD CLAVE\\nDISTRITO NOMBRE\\nDISTRITO CLAVE\\nMUNICIPIO NOMBRE\\nMUNICIPIO SECCION PADRON\\nHOMBRES PADRON\\nMUJERES PADRON\\nNO BINARIO ... LISTA_50_54_NOBINARIO LISTA_55_59_HOMBRES LISTA_55_59_MUJERES LISTA_55_59_NOBINARIO LISTA_60_64_HOMBRES LISTA_60_64_MUJERES LISTA_60_64_NOBINARIO LISTA_65_Y_MAS_HOMBRES LISTA_65_Y_MAS_MUJERES LISTA_65_Y_MAS_NOBINARIO 0 1 RESIDENTES EXTRANJERO 0.0 0 0.0 0 0.0 8444 5756 0 ... 0.0 355.0 234.0 0.0 180.0 149.0 0.0 206.0 139.0 0.0 1 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 338.0 973 1013 0 ... 0.0 56.0 72.0 0.0 39.0 37.0 0.0 88.0 109.0 0.0 2 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 339.0 895 954 0 ... 0.0 55.0 60.0 0.0 38.0 43.0 0.0 88.0 97.0 0.0 3 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 340.0 951 1001 0 ... 0.0 56.0 66.0 0.0 46.0 48.0 0.0 103.0 83.0 0.0 4 1 AGUASCALIENTES 1.0 JESUS MARIA ... 2.0 ASIENTOS 341.0 1174 1184 0 ... 0.0 59.0 60.0 0.0 50.0 62.0 0.0 110.0 105.0 0.0 5 rows × 87 columns\ndf_age.columns Index(['CLAVE\\nENTIDAD', 'NOMBRE\\nENTIDAD', 'CLAVE\\nDISTRITO', 'NOMBRE\\nDISTRITO', 'CLAVE\\nMUNICIPIO', 'NOMBRE\\nMUNICIPIO', 'SECCION', 'PADRON\\nHOMBRES', 'PADRON\\nMUJERES', 'PADRON\\nNO BINARIO', 'PADRON\\nELECTORAL', 'LISTA\\nHOMBRES', 'LISTA\\nMUJERES', 'LISTA\\nNO BINARIO', 'LISTA\\nNOMINAL', 'PADRON_18_HOMBRES', 'PADRON_18_MUJERES', 'PADRON_18_NOBINARIO', 'PADRON_19_HOMBRES', 'PADRON_19_MUJERES', 'PADRON_19_NOBINARIO', 'PADRON_20_24_HOMBRES', 'PADRON_20_24_MUJERES', 'PADRON_20_24_NOBINARIO', 'PADRON_25_29_HOMBRES', 'PADRON_25_29_MUJERES', 'PADRON_25_29_NOBINARIO', 'PADRON_30_34_HOMBRES', 'PADRON_30_34_MUJERES', 'PADRON_30_34_NOBINARIO', 'PADRON_35_39_HOMBRES', 'PADRON_35_39_MUJERES', 'PADRON_35_39_NOBINARIO', 'PADRON_40_44_HOMBRES', 'PADRON_40_44_MUJERES', 'PADRON_40_44_NOBINARIO', 'PADRON_45_49_HOMBRES', 'PADRON_45_49_MUJERES', 'PADRON_45_49_NOBINARIO', 'PADRON_50_54_HOMBRES', 'PADRON_50_54_MUJERES', 'PADRON_50_54_NOBINARIO', 'PADRON_55_59_HOMBRES', 'PADRON_55_59_MUJERES', 'PADRON_55_59_NOBINARIO', 'PADRON_60_64_HOMBRES', 'PADRON_60_64_MUJERES', 'PADRON_60_64_NOBINARIO', 'PADRON_65_Y_MAS_HOMBRES', 'PADRON_65_Y_MAS_MUJERES', 'PADRON_65_Y_MAS_NOBINARIO', 'LISTA_18_HOMBRES', 'LISTA_18_MUJERES', 'LISTA_18_NOBINARIO', 'LISTA_19_HOMBRES', 'LISTA_19_MUJERES', 'LISTA_19_NOBINARIO', 'LISTA_20_24_HOMBRES', 'LISTA_20_24_MUJERES', 'LISTA_20_24_NOBINARIO', 'LISTA_25_29_HOMBRES', 'LISTA_25_29_MUJERES', 'LISTA_25_29_NOBINARIO', 'LISTA_30_34_HOMBRES', 'LISTA_30_34_MUJERES', 'LISTA_30_34_NOBINARIO', 'LISTA_35_39_HOMBRES', 'LISTA_35_39_MUJERES', 'LISTA_35_39_NOBINARIO', 'LISTA_40_44_HOMBRES', 'LISTA_40_44_MUJERES', 'LISTA_40_44_NOBINARIO', 'LISTA_45_49_HOMBRES', 'LISTA_45_49_MUJERES', 'LISTA_45_49_NOBINARIO', 'LISTA_50_54_HOMBRES', 'LISTA_50_54_MUJERES', 'LISTA_50_54_NOBINARIO', 'LISTA_55_59_HOMBRES', 'LISTA_55_59_MUJERES', 'LISTA_55_59_NOBINARIO', 'LISTA_60_64_HOMBRES', 'LISTA_60_64_MUJERES', 'LISTA_60_64_NOBINARIO', 'LISTA_65_Y_MAS_HOMBRES', 'LISTA_65_Y_MAS_MUJERES', 'LISTA_65_Y_MAS_NOBINARIO'], dtype='object') # Select columns by their positions: 1-7, 12-15, and the last 36 cols_to_keep = list(range(0, 7)) + list(range(11, 15)) + list(range(-36, 0)) # Now, select these columns from the DataFrame df_ln_age = df_age.iloc[:, cols_to_keep] # filter rows by state quintana roo df_ln_age_qroo = df_ln_age[df_ln_age[\u0026#39;NOMBRE\\nENTIDAD\u0026#39;] == \u0026#39;QUINTANA ROO\u0026#39;] # select columns for padron electoral # df_ln_age_qroo = df_age_qroo.iloc[:,:11] print(df_ln_age_qroo.columns) df_ln_age_qroo.head() Index(['CLAVE\\nENTIDAD', 'NOMBRE\\nENTIDAD', 'CLAVE\\nDISTRITO', 'NOMBRE\\nDISTRITO', 'CLAVE\\nMUNICIPIO', 'NOMBRE\\nMUNICIPIO', 'SECCION', 'LISTA\\nHOMBRES', 'LISTA\\nMUJERES', 'LISTA\\nNO BINARIO', 'LISTA\\nNOMINAL', 'LISTA_18_HOMBRES', 'LISTA_18_MUJERES', 'LISTA_18_NOBINARIO', 'LISTA_19_HOMBRES', 'LISTA_19_MUJERES', 'LISTA_19_NOBINARIO', 'LISTA_20_24_HOMBRES', 'LISTA_20_24_MUJERES', 'LISTA_20_24_NOBINARIO', 'LISTA_25_29_HOMBRES', 'LISTA_25_29_MUJERES', 'LISTA_25_29_NOBINARIO', 'LISTA_30_34_HOMBRES', 'LISTA_30_34_MUJERES', 'LISTA_30_34_NOBINARIO', 'LISTA_35_39_HOMBRES', 'LISTA_35_39_MUJERES', 'LISTA_35_39_NOBINARIO', 'LISTA_40_44_HOMBRES', 'LISTA_40_44_MUJERES', 'LISTA_40_44_NOBINARIO', 'LISTA_45_49_HOMBRES', 'LISTA_45_49_MUJERES', 'LISTA_45_49_NOBINARIO', 'LISTA_50_54_HOMBRES', 'LISTA_50_54_MUJERES', 'LISTA_50_54_NOBINARIO', 'LISTA_55_59_HOMBRES', 'LISTA_55_59_MUJERES', 'LISTA_55_59_NOBINARIO', 'LISTA_60_64_HOMBRES', 'LISTA_60_64_MUJERES', 'LISTA_60_64_NOBINARIO', 'LISTA_65_Y_MAS_HOMBRES', 'LISTA_65_Y_MAS_MUJERES', 'LISTA_65_Y_MAS_NOBINARIO'], dtype='object') CLAVE\\nENTIDAD NOMBRE\\nENTIDAD CLAVE\\nDISTRITO NOMBRE\\nDISTRITO CLAVE\\nMUNICIPIO NOMBRE\\nMUNICIPIO SECCION LISTA\\nHOMBRES LISTA\\nMUJERES LISTA\\nNO BINARIO ... LISTA_50_54_NOBINARIO LISTA_55_59_HOMBRES LISTA_55_59_MUJERES LISTA_55_59_NOBINARIO LISTA_60_64_HOMBRES LISTA_60_64_MUJERES LISTA_60_64_NOBINARIO LISTA_65_Y_MAS_HOMBRES LISTA_65_Y_MAS_MUJERES LISTA_65_Y_MAS_NOBINARIO 50685 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 182.0 1046 1015 0 ... 0.0 77.0 77.0 0.0 69.0 57.0 0.0 99.0 111.0 0.0 50686 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 183.0 1056 1085 0 ... 0.0 65.0 68.0 0.0 50.0 62.0 0.0 100.0 97.0 0.0 50687 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 184.0 982 981 0 ... 0.0 75.0 65.0 0.0 43.0 36.0 0.0 105.0 112.0 0.0 50688 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 185.0 1228 1198 0 ... 0.0 76.0 83.0 0.0 50.0 56.0 0.0 119.0 113.0 0.0 50689 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 186.0 525 465 0 ... 0.0 21.0 30.0 0.0 29.0 34.0 0.0 56.0 40.0 0.0 5 rows × 47 columns\ndf_ln_age_qroo.dtypes CLAVE\\nENTIDAD object NOMBRE\\nENTIDAD object CLAVE\\nDISTRITO float64 NOMBRE\\nDISTRITO object CLAVE\\nMUNICIPIO float64 NOMBRE\\nMUNICIPIO object SECCION float64 LISTA\\nHOMBRES int64 LISTA\\nMUJERES int64 LISTA\\nNO BINARIO int64 LISTA\\nNOMINAL int64 LISTA_18_HOMBRES float64 LISTA_18_MUJERES float64 LISTA_18_NOBINARIO float64 LISTA_19_HOMBRES float64 LISTA_19_MUJERES float64 LISTA_19_NOBINARIO float64 LISTA_20_24_HOMBRES float64 LISTA_20_24_MUJERES float64 LISTA_20_24_NOBINARIO float64 LISTA_25_29_HOMBRES float64 LISTA_25_29_MUJERES float64 LISTA_25_29_NOBINARIO float64 LISTA_30_34_HOMBRES float64 LISTA_30_34_MUJERES float64 LISTA_30_34_NOBINARIO float64 LISTA_35_39_HOMBRES float64 LISTA_35_39_MUJERES float64 LISTA_35_39_NOBINARIO float64 LISTA_40_44_HOMBRES float64 LISTA_40_44_MUJERES float64 LISTA_40_44_NOBINARIO float64 LISTA_45_49_HOMBRES float64 LISTA_45_49_MUJERES float64 LISTA_45_49_NOBINARIO float64 LISTA_50_54_HOMBRES float64 LISTA_50_54_MUJERES float64 LISTA_50_54_NOBINARIO float64 LISTA_55_59_HOMBRES float64 LISTA_55_59_MUJERES float64 LISTA_55_59_NOBINARIO float64 LISTA_60_64_HOMBRES float64 LISTA_60_64_MUJERES float64 LISTA_60_64_NOBINARIO float64 LISTA_65_Y_MAS_HOMBRES float64 LISTA_65_Y_MAS_MUJERES float64 LISTA_65_Y_MAS_NOBINARIO float64 dtype: object Change the Column Names to Avoid Special Characters ln_age_col_names = [\u0026#39;CLAVE ENTIDAD\u0026#39;, \u0026#39;NOMBRE ENTIDAD\u0026#39;, \u0026#39;CLAVE DISTRITO\u0026#39;, \u0026#39;NOMBRE DISTRITO\u0026#39;, \u0026#39;CLAVE MUNICIPIO\u0026#39;, \u0026#39;MUNICIPIO\u0026#39;, \u0026#39;SECCION\u0026#39;, \u0026#39;LISTA HOMBRES\u0026#39;, \u0026#39;LISTA MUJERES\u0026#39;, \u0026#39;LISTA NO BINARIO\u0026#39;, \u0026#39;LISTA NOMINAL\u0026#39;, \u0026#39;LISTA_18_HOMBRES\u0026#39;, \u0026#39;LISTA_18_MUJERES\u0026#39;, \u0026#39;LISTA_18_NOBINARIO\u0026#39;, \u0026#39;LISTA_19_HOMBRES\u0026#39;, \u0026#39;LISTA_19_MUJERES\u0026#39;, \u0026#39;LISTA_19_NOBINARIO\u0026#39;, \u0026#39;LISTA_20_24_HOMBRES\u0026#39;, \u0026#39;LISTA_20_24_MUJERES\u0026#39;, \u0026#39;LISTA_20_24_NOBINARIO\u0026#39;, \u0026#39;LISTA_25_29_HOMBRES\u0026#39;, \u0026#39;LISTA_25_29_MUJERES\u0026#39;, \u0026#39;LISTA_25_29_NOBINARIO\u0026#39;, \u0026#39;LISTA_30_34_HOMBRES\u0026#39;, \u0026#39;LISTA_30_34_MUJERES\u0026#39;, \u0026#39;LISTA_30_34_NOBINARIO\u0026#39;, \u0026#39;LISTA_35_39_HOMBRES\u0026#39;, \u0026#39;LISTA_35_39_MUJERES\u0026#39;, \u0026#39;LISTA_35_39_NOBINARIO\u0026#39;, \u0026#39;LISTA_40_44_HOMBRES\u0026#39;, \u0026#39;LISTA_40_44_MUJERES\u0026#39;, \u0026#39;LISTA_40_44_NOBINARIO\u0026#39;, \u0026#39;LISTA_45_49_HOMBRES\u0026#39;, \u0026#39;LISTA_45_49_MUJERES\u0026#39;, \u0026#39;LISTA_45_49_NOBINARIO\u0026#39;, \u0026#39;LISTA_50_54_HOMBRES\u0026#39;, \u0026#39;LISTA_50_54_MUJERES\u0026#39;, \u0026#39;LISTA_50_54_NOBINARIO\u0026#39;, \u0026#39;LISTA_55_59_HOMBRES\u0026#39;, \u0026#39;LISTA_55_59_MUJERES\u0026#39;, \u0026#39;LISTA_55_59_NOBINARIO\u0026#39;, \u0026#39;LISTA_60_64_HOMBRES\u0026#39;, \u0026#39;LISTA_60_64_MUJERES\u0026#39;, \u0026#39;LISTA_60_64_NOBINARIO\u0026#39;, \u0026#39;LISTA_65_Y_MAS_HOMBRES\u0026#39;, \u0026#39;LISTA_65_Y_MAS_MUJERES\u0026#39;, \u0026#39;LISTA_65_Y_MAS_NOBINARIO\u0026#39;] df_ln_age_qroo.columns = ln_age_col_names df_ln_age_qroo[[\u0026#39;CLAVE ENTIDAD\u0026#39;, \u0026#39;NOMBRE ENTIDAD\u0026#39;, \u0026#39;NOMBRE DISTRITO\u0026#39;]].astype(str) df_ln_age_qroo.head() CLAVE ENTIDAD NOMBRE ENTIDAD CLAVE DISTRITO NOMBRE DISTRITO CLAVE MUNICIPIO MUNICIPIO SECCION LISTA HOMBRES LISTA MUJERES LISTA NO BINARIO ... LISTA_50_54_NOBINARIO LISTA_55_59_HOMBRES LISTA_55_59_MUJERES LISTA_55_59_NOBINARIO LISTA_60_64_HOMBRES LISTA_60_64_MUJERES LISTA_60_64_NOBINARIO LISTA_65_Y_MAS_HOMBRES LISTA_65_Y_MAS_MUJERES LISTA_65_Y_MAS_NOBINARIO 50685 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 182.0 1046 1015 0 ... 0.0 77.0 77.0 0.0 69.0 57.0 0.0 99.0 111.0 0.0 50686 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 183.0 1056 1085 0 ... 0.0 65.0 68.0 0.0 50.0 62.0 0.0 100.0 97.0 0.0 50687 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 184.0 982 981 0 ... 0.0 75.0 65.0 0.0 43.0 36.0 0.0 105.0 112.0 0.0 50688 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 185.0 1228 1198 0 ... 0.0 76.0 83.0 0.0 50.0 56.0 0.0 119.0 113.0 0.0 50689 23 QUINTANA ROO 1.0 SOLIDARIDAD ... 2.0 COZUMEL 186.0 525 465 0 ... 0.0 21.0 30.0 0.0 29.0 34.0 0.0 56.0 40.0 0.0 5 rows × 47 columns\n# refactor into a function for later use on the dashboard def create_age_choropleth(df, geojson): # Aggregate data by MUNICIPIO df_grouped = df.groupby(\u0026#39;MUNICIPIO\u0026#39;).sum().reset_index() # Determine the predominant age range for each municipality age_groups = df_grouped.columns[11:] df_grouped[\u0026#39;Rango de Edad Predominante\u0026#39;] = df_grouped[age_groups].idxmax(axis=1) # when summing, pandas also concatenates the strings in \u0026#34;NOMBRE ENTIDAD\u0026#34; # so do some housekeeping df_grouped.drop(columns=[\u0026#39;NOMBRE ENTIDAD\u0026#39;]) # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Rango de Edad Predominante\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_continuous_scale=px.colors.sequential.Plasma, projection=\u0026#34;mercator\u0026#34;, title=\u0026#34;Predominant Gender and Age Range in Voter Registration\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) return fig create_age_choropleth(df_ln_age_qroo, geojson_data) Total Voter Registration per Municipality We will use the data in the column LISTA NOMINAL (i.e. the number of registered voters) from the dataframe df_ln_sx_qroo. Based on this, we\u0026rsquo;ll obtain the totals per municipality so we can visualize them.\nLet\u0026rsquo;s get a refresher on the column names.\ndf_ln_sx_qroo.columns Index(['Clave Entidad', 'Nombre Entidad', 'Clave Distrito', 'Nombre Distrito', 'Clave Municipio', 'Nombre Municipio', 'Seccion', 'Lista Hombres', 'Lista Mujeres', 'Lista No Binario', 'Lista Nominal'], dtype='object') # refactor into a function for later use on dashboard def create_total_bar_plot(df): # group data df_ln_qroo_totals = df.groupby([\u0026#39;Nombre Municipio\u0026#39;])[[\u0026#39;Lista Hombres\u0026#39;, \u0026#39;Lista Mujeres\u0026#39;, \u0026#39;Lista Nominal\u0026#39;]].sum().reset_index() fig_bar_totals = px.bar( df_ln_qroo_totals, x=\u0026#39;Nombre Municipio\u0026#39;, y=[\u0026#39;Lista Hombres\u0026#39;,\u0026#39;Lista Mujeres\u0026#39;], labels = {\u0026#39;value\u0026#39;: \u0026#39;Lista Nominal\u0026#39;, \u0026#39;variable\u0026#39;: \u0026#39;\u0026#39;}, title=\u0026#34;Registered Voters per Municipality\u0026#34;, color_discrete_sequence=px.colors.qualitative.Dark24 ) # make a dictionary for abbreviated municipality names abb_mun_dict = { \u0026#39;BACALAR\u0026#39;: \u0026#39;BCL\u0026#39;, \u0026#39;BENITO JUAREZ\u0026#39;: \u0026#39;BJ\u0026#39;, \u0026#39;COZUMEL\u0026#39;: \u0026#39;CZ\u0026#39;, \u0026#39;FELIPE CARRILLO PUERTO\u0026#39;: \u0026#39;FCP\u0026#39;, \u0026#39;ISLA MUJERES\u0026#39;: \u0026#39;IM\u0026#39;, \u0026#39;JOSE MARIA MORELOS\u0026#39;: \u0026#39;JMM\u0026#39;, \u0026#39;LAZARO CARDENAS\u0026#39;: \u0026#39;LC\u0026#39;, \u0026#39;OTHON P. BLANCO\u0026#39;: \u0026#39;OPB\u0026#39;, \u0026#39;PUERTO MORELOS\u0026#39;: \u0026#39;PM\u0026#39;, \u0026#39;SOLIDARIDAD\u0026#39;: \u0026#39;SLD\u0026#39;, \u0026#39;TULUM\u0026#39;: \u0026#39;TLM\u0026#39; } fig_bar_totals.update_layout( xaxis = dict( tickvals = df_ln_qroo_totals[\u0026#39;Nombre Municipio\u0026#39;], # Original names ticktext = [abb_mun_dict.get(name, name) for name in df_ln_qroo_totals[\u0026#39;Nombre Municipio\u0026#39;]] # Abbreviated names ), yaxis = dict(title = \u0026#39;Registered Voters\u0026#39;), plot_bgcolor = \u0026#39;rgba(0,0,0,0)\u0026#39;, # transparent background uniformtext_minsize = 8, # ensure text size is legible uniformtext_mode = \u0026#39;hide\u0026#39;, # hide text if it doesn\u0026#39;t fit ) fig_bar_totals.update_traces( hoverinfo=\u0026#39;x+y\u0026#39;, # Show the municipio name and the count on hover hovertemplate=\u0026#34;\u0026lt;b\u0026gt;%{x}\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;Total: %{y}\u0026lt;extra\u0026gt;\u0026lt;/extra\u0026gt;\u0026#34; # Custom hover template ) return fig_bar_totals create_total_bar_plot(df_ln_sx_qroo) # refactor into a function for later use on dashboard def create_total_choropleth(df, geojson): df_ln_qroo_totals = df.groupby([\u0026#39;Nombre Municipio\u0026#39;])[[\u0026#39;Lista Hombres\u0026#39;, \u0026#39;Lista Mujeres\u0026#39;, \u0026#39;Lista Nominal\u0026#39;]].sum().reset_index() fig_choropleth_totals = px.choropleth(df_ln_qroo_totals, geojson=geojson, locations=\u0026#39;Nombre Municipio\u0026#39;, color=\u0026#39;Lista Nominal\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, # Adjust based on your GeoJSON properties projection=\u0026#34;mercator\u0026#34;, color_continuous_scale=\u0026#34;Portland\u0026#34;, title=\u0026#34;Registered Voters per Municipality\u0026#34;) fig_choropleth_totals.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) fig_choropleth_totals.update_layout( coloraxis_colorbar = dict( title = \u0026#39;Total Registered Voters\u0026#39;, orientation= \u0026#39;h\u0026#39;, x = 0.5, xanchor = \u0026#39;center\u0026#39;, y = -0.2, thickness = 10, len = 0.65 ) ) return fig_choropleth_totals create_total_choropleth(df_ln_sx_qroo, geojson_data) Map with Voter Proportion vs Total Registered Voters per Municipality To create a map with the proportion of voters vs the total registered voters, we need the dataframe with the election results. In these dataframes, there are columns with the total of people that went out to vote.\ndf_grouped = df_re_2021_qroo.groupby(\u0026#39;MUNICIPIO\u0026#39;).agg({ \u0026#39;TOTAL_VOTOS\u0026#39;: \u0026#39;sum\u0026#39;, \u0026#39;LISTA_NOMINAL\u0026#39;: \u0026#39;sum\u0026#39; }).reset_index() df_grouped[\u0026#39;Porcentaje\u0026#39;] = df_grouped[\u0026#39;TOTAL_VOTOS\u0026#39;] / df_grouped[\u0026#39;LISTA_NOMINAL\u0026#39;] df_grouped MUNICIPIO TOTAL_VOTOS LISTA_NOMINAL Porcentaje 0 BACALAR 19204.0 31916 0.601704 1 BENITO JUAREZ 245654.0 630987 0.389317 2 COZUMEL 38876.0 70987 0.547650 3 FELIPE CARRILLO PUERTO 36950.0 55894 0.661073 4 ISLA MUJERES 13456.0 21729 0.619265 5 JOSE MARIA MORELOS 21985.0 27940 0.786865 6 LAZARO CARDENAS 16346.0 21981 0.743642 7 OTHON P. BLANCO 79889.0 174372 0.458153 8 PUERTO MORELOS 11189.0 21716 0.515242 9 SOLIDARIDAD 80806.0 229306 0.352394 10 TULUM 21607.0 35739 0.604578 selected_year = 2015 def create_voter_turnout_proportion_choropleth(df_resultados, selected_year, geojson_data): # Aggregate data by MUNICIPIO if not already aggregated df_grouped = df_resultados.groupby(\u0026#39;MUNICIPIO\u0026#39;).agg({ \u0026#39;TOTAL_VOTOS\u0026#39;: \u0026#39;sum\u0026#39;, \u0026#39;LISTA_NOMINAL\u0026#39;: \u0026#39;sum\u0026#39; }).reset_index() df_grouped[\u0026#39;Porcentaje Votantes\u0026#39;] = df_grouped[\u0026#39;TOTAL_VOTOS\u0026#39;] / df_grouped[\u0026#39;LISTA_NOMINAL\u0026#39;] * 100 # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson_data, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Porcentaje Votantes\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_continuous_scale=px.colors.sequential.YlOrRd, projection=\u0026#34;mercator\u0026#34;, title=f\u0026#34;Total Voter Turnout in {selected_year}\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) # Update layout for colorbar position fig.update_layout( coloraxis_colorbar=dict( title=(f\u0026#39;Voter Turnout Percentage in {selected_year}\u0026#39;), orientation=\u0026#39;h\u0026#39;, x=0.5, xanchor=\u0026#39;center\u0026#39;, y=-0.2, thickness=10, # Adjust the thickness of the colorbar len=0.65 # Set the length as a fraction of the plot area width ) ) return fig create_voter_turnout_proportion_choropleth(df_re_2018_qroo, selected_year, geojson_data) ","permalink":"http://localhost:1313/posts/20240509_election_dash_part_1-data_cleaning/election_dash_part_1-data_cleaning/","summary":"In this project, election data is collected, explored and cleaned. Visualization functions are refactored to be used on a dashboard later on.","title":"Election Data Dashboard Pt. 1: Collection and Cleaning"},{"content":" Creating the Dashboard using dash The cleaned data is loadsed and the plot generating functions are refactored here. Then a dashboard is created using dash.\nThis dashboard is deployed (at the time of writing this post) here:\nhttps://elections-dash.onrender.com/\nHere is the full code:\nimport requests import pandas as pd import dash from dash import Dash, dcc, html, Input, Output import plotly.express as px import dash_bootstrap_components as dbc # generate variables and constants election_years = [year for year in range(2009, 2022, 3)] # Mapping each election year to its corresponding dataframe def distribute_alliance_votes(df, alliances): # ensure that party columns exist in the dataframe, add them if the do not all_parties = set(party for parties in alliances.values() for party in parties) for party in all_parties: if party not in df.columns: df[party] = 0 # distribute the votes from each alliance to the respective parties for alliance, parties in alliances.items(): if alliance in df.columns: split_votes = df[alliance] / len(parties) for party in parties: df[party] += split_votes # optionally remove the alliance columns df.drop(columns = list(alliances.keys()), inplace = True, errors = \u0026#39;ignore\u0026#39;) return df main_parties = { \u0026#39;PAN\u0026#39;: \u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;: \u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;: \u0026#39;PRD\u0026#39;, \u0026#39;PVEM\u0026#39;: \u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;: \u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;: \u0026#39;MC\u0026#39;, \u0026#39;MORENA\u0026#39;: \u0026#39;MORENA\u0026#39;, \u0026#39;NVA_ALIANZA\u0026#39;: \u0026#39;NVA_ALIANZA\u0026#39;, \u0026#39;PSD\u0026#39;: [\u0026#39;PSD\u0026#39;], \u0026#39;PRIMERO_MEXICO\u0026#39;: [\u0026#39;PRIMERO_MEXICO\u0026#39;], \u0026#39;SALVEMOS_MEXICO\u0026#39;: [\u0026#39;SALVEMOS_MEXICO\u0026#39;], \u0026#39;PH\u0026#39;: [\u0026#39;PH\u0026#39;], \u0026#39;ES\u0026#39;: [\u0026#39;ES\u0026#39;], \u0026#39;NA\u0026#39;: [\u0026#39;NA\u0026#39;], \u0026#39;PES\u0026#39;: [\u0026#39;PES\u0026#39;], \u0026#39;RSP\u0026#39;: [\u0026#39;RSP\u0026#39;], \u0026#39;FXM\u0026#39;: [\u0026#39;FXM\u0026#39;], # Add more as needed for each unique party or alliance... } alliance_votes_mapping = { \u0026#39;PAN_NVA_ALIANZA\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;NVA_ALIANZA\u0026#39;], \u0026#39;PAN_PRD\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PRI_PVEM\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PVEM\u0026#39;], \u0026#39;PRI_NA\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PRI_PVEM_NA\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PVEM\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PAN_PRI_PRD\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PAN_PRI\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRI\u0026#39;], \u0026#39;PRI_PRD\u0026#39;: [\u0026#39;PRI\u0026#39;, \u0026#39;PRD\u0026#39;], \u0026#39;PRD_PT\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;PT\u0026#39;], \u0026#39;PVEM_NA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;NA\u0026#39;], \u0026#39;PVEM_PT\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;], \u0026#39;PT_ES\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PRD_PT_MC\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PRD_MC\u0026#39;: [\u0026#39;PRD\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PT_MC\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PAN_PRD_MC\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;PRD\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;PAN_MC\u0026#39;: [\u0026#39;PAN\u0026#39;, \u0026#39;MC\u0026#39;], \u0026#39;MORENA_ES\u0026#39;: [\u0026#39;MORENA\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PT_MORENA_ES\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;, \u0026#39;ES\u0026#39;], \u0026#39;PT_MORENA\u0026#39;: [\u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;], \u0026#39;PVEM_PT_MORENA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;PT\u0026#39;, \u0026#39;MORENA\u0026#39;], \u0026#39;PVEM_MORENA\u0026#39;: [\u0026#39;PVEM\u0026#39;, \u0026#39;MORENA\u0026#39;], # Add any other specific alliances as needed } # load data # URL of the GeoJSON file on GitHub geojson_url = \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/qroo_geojson_2022.json\u0026#39; # Fetch the GeoJSON data response = requests.get(geojson_url) geojson_data = response.json() if response.status_code == 200 else None df_ln_sx_qroo = pd.read_csv(\u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_lista_nominal_sexo.csv\u0026#39;) df_ln_age_qroo = pd.read_csv(\u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_lista_nominal_edad.csv\u0026#39;) csv_urls = [ \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_results_2009.csv\u0026#39;, \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_results_2012.csv\u0026#39;, \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_results_2015.csv\u0026#39;, \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_results_2018.csv\u0026#39;, \u0026#39;https://raw.githubusercontent.com/vflores-io/elections_dash/main/data/cleaned_results_2021.csv\u0026#39; # Add more URLs as needed ] # Load each CSV file into a DataFrame df_re_2009_qroo = pd.read_csv(csv_urls[0]) df_re_2012_qroo = pd.read_csv(csv_urls[1]) df_re_2015_qroo = pd.read_csv(csv_urls[2]) df_re_2018_qroo = pd.read_csv(csv_urls[3]) df_re_2021_qroo = pd.read_csv(csv_urls[4]) df_re_2009_qroo = distribute_alliance_votes(df_re_2009_qroo, alliance_votes_mapping) df_re_2012_qroo = distribute_alliance_votes(df_re_2012_qroo, alliance_votes_mapping) df_re_2015_qroo = distribute_alliance_votes(df_re_2015_qroo, alliance_votes_mapping) df_re_2018_qroo = distribute_alliance_votes(df_re_2018_qroo, alliance_votes_mapping) df_re_2021_qroo = distribute_alliance_votes(df_re_2021_qroo, alliance_votes_mapping) df_re_all_years = [df_re_2009_qroo, df_re_2012_qroo, df_re_2015_qroo, df_re_2018_qroo, df_re_2021_qroo] df_dict = { 2009: df_re_2009_qroo, 2012: df_re_2012_qroo, 2015: df_re_2015_qroo, 2018: df_re_2018_qroo, 2021: df_re_2021_qroo, } def create_total_bar_plot(df): df.rename(columns={\u0026#39;Lista Hombres\u0026#39;: \u0026#39;Registered Men\u0026#39;, \u0026#39;Lista Mujeres\u0026#39;: \u0026#39;Registered Women\u0026#39;, \u0026#39;Lista Nominal\u0026#39;: \u0026#39;Total Registered\u0026#39;}, inplace = True) # group data df_ln_qroo_totals = df.groupby([\u0026#39;Nombre Municipio\u0026#39;])[[\u0026#39;Registered Men\u0026#39;, \u0026#39;Registered Women\u0026#39;, \u0026#39;Total Registered\u0026#39;]].sum().reset_index() fig_bar_totals = px.bar( df_ln_qroo_totals, x=\u0026#39;Nombre Municipio\u0026#39;, y=[\u0026#39;Registered Men\u0026#39;, \u0026#39;Registered Women\u0026#39;], labels = {\u0026#39;value\u0026#39;: \u0026#39;Lista Nominal\u0026#39;, \u0026#39;variable\u0026#39;: \u0026#39;\u0026#39;}, title=\u0026#34;Registered Voters per Municipality\u0026#34;, color_discrete_sequence=px.colors.qualitative.T10 ) # make a dictionary for abbreviated municipality names abb_mun_dict = { \u0026#39;BACALAR\u0026#39;: \u0026#39;BCL\u0026#39;, \u0026#39;BENITO JUAREZ\u0026#39;: \u0026#39;BJ\u0026#39;, \u0026#39;COZUMEL\u0026#39;: \u0026#39;CZ\u0026#39;, \u0026#39;FELIPE CARRILLO PUERTO\u0026#39;: \u0026#39;FCP\u0026#39;, \u0026#39;ISLA MUJERES\u0026#39;: \u0026#39;IM\u0026#39;, \u0026#39;JOSE MARIA MORELOS\u0026#39;: \u0026#39;JMM\u0026#39;, \u0026#39;LAZARO CARDENAS\u0026#39;: \u0026#39;LC\u0026#39;, \u0026#39;OTHON P. BLANCO\u0026#39;: \u0026#39;OPB\u0026#39;, \u0026#39;PUERTO MORELOS\u0026#39;: \u0026#39;PM\u0026#39;, \u0026#39;SOLIDARIDAD\u0026#39;: \u0026#39;SLD\u0026#39;, \u0026#39;TULUM\u0026#39;: \u0026#39;TLM\u0026#39; } fig_bar_totals.update_layout( xaxis = dict( tickvals = df_ln_qroo_totals[\u0026#39;Nombre Municipio\u0026#39;], # Original names ticktext = [abb_mun_dict.get(name, name) for name in df_ln_qroo_totals[\u0026#39;Nombre Municipio\u0026#39;]] # Abbreviated names ), yaxis = dict(title = \u0026#39;Registered Voters\u0026#39;), plot_bgcolor = \u0026#39;rgba(0,0,0,0)\u0026#39;, # transparent background uniformtext_minsize = 8, # ensure text size is legible uniformtext_mode = \u0026#39;hide\u0026#39;, # hide text if it doesn\u0026#39;t fit ) fig_bar_totals.update_traces( hoverinfo=\u0026#39;x+y\u0026#39;, # Show the municipio name and the count on hover hovertemplate=\u0026#34;\u0026lt;b\u0026gt;%{x}\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;Total: %{y}\u0026lt;extra\u0026gt;\u0026lt;/extra\u0026gt;\u0026#34; # Custom hover template ) return fig_bar_totals def create_total_choropleth(df, geojson): df_ln_qroo_totals = df.groupby([\u0026#39;Nombre Municipio\u0026#39;])[[\u0026#39;Lista Nominal\u0026#39;]].sum().reset_index() ochre_scale = [ [0.0, \u0026#39;#4c78c8\u0026#39;], # Blue [1.0, \u0026#39;#f58518\u0026#39;], # Light ochre (yellow) ] fig_choropleth_totals = px.choropleth(df_ln_qroo_totals, geojson=geojson, locations=\u0026#39;Nombre Municipio\u0026#39;, color=\u0026#39;Lista Nominal\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, # Adjust based on your GeoJSON properties projection=\u0026#34;mercator\u0026#34;, color_continuous_scale=ochre_scale, title=\u0026#34;Registered Voters per Municipality\u0026#34;) fig_choropleth_totals.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) fig_choropleth_totals.update_layout( coloraxis_colorbar = dict( title = \u0026#39;Total Registered Voters\u0026#39;, orientation= \u0026#39;h\u0026#39;, x = 0.5, xanchor = \u0026#39;center\u0026#39;, y = -0.2, thickness = 10, len = 0.65 ) ) return fig_choropleth_totals #-------------------------------------------------------------------------- def create_age_choropleth(df, geojson): # Aggregate data by MUNICIPIO df_grouped = df.groupby(\u0026#39;MUNICIPIO\u0026#39;).sum().reset_index() # Determine the predominant age range for each municipality # age_groups = df_grouped.columns[11:] age_groups = [\u0026#39;Men 18\u0026#39;, \u0026#39;Women 18\u0026#39;, \u0026#39;Non-Binary 18\u0026#39;, \u0026#39;Men 19\u0026#39;, \u0026#39;Women 19\u0026#39;, \u0026#39;Non-Binary 19\u0026#39;, \u0026#39;Men 20-24\u0026#39;, \u0026#39;Women 20-24\u0026#39;, \u0026#39;Non-Binary 20-24\u0026#39;, \u0026#39;Men 25-29\u0026#39;, \u0026#39;Women 25-29\u0026#39;, \u0026#39;Non-Binary 25-29\u0026#39;, \u0026#39;Men 30-34\u0026#39;, \u0026#39;Women 30-34\u0026#39;, \u0026#39;Non-Binary 30-34\u0026#39;, \u0026#39;Men 35-39\u0026#39;, \u0026#39;Women 35-39\u0026#39;, \u0026#39;Non-Binary 35-39\u0026#39;, \u0026#39;Men 40-44\u0026#39;, \u0026#39;Women 40-44\u0026#39;, \u0026#39;Non-Binary 40-44\u0026#39;, \u0026#39;Men 45-49\u0026#39;, \u0026#39;Women 45-49\u0026#39;, \u0026#39;Non-Binary 45-49\u0026#39;, \u0026#39;Men 50-54\u0026#39;, \u0026#39;Women 50-54\u0026#39;, \u0026#39;Non-Binary 50-54\u0026#39;, \u0026#39;Men 55-59\u0026#39;, \u0026#39;Women 55-59\u0026#39;, \u0026#39;Non-Binary 55-59\u0026#39;, \u0026#39;Men 60-64\u0026#39;, \u0026#39;Women 60-64\u0026#39;, \u0026#39;Non-Binary 60-64\u0026#39;, \u0026#39;Men 65+\u0026#39;, \u0026#39;Women 65+\u0026#39;, \u0026#39;Non-Binary 65+\u0026#39;] # Rename the columns from the 12th column onwards df_grouped.columns = list(df_grouped.columns[:11]) + age_groups[:len(df_grouped.columns) - 11] df_grouped[\u0026#39;Predominant Age and Gender Group\u0026#39;] = df_grouped[age_groups].idxmax(axis=1) # when summing, pandas also concatenates the strings in \u0026#34;NOMBRE ENTIDAD\u0026#34; # so do some housekeeping df_grouped.drop(columns=[\u0026#39;NOMBRE ENTIDAD\u0026#39;]) # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Predominant Age and Gender Group\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_discrete_sequence=px.colors.qualitative.T10, projection=\u0026#34;mercator\u0026#34;, title=\u0026#34;Predominant Gender and Age Range in Voter Registration\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) return fig #------------------------------------------------------------------------------------- def create_gender_proportion_choropleth(df, geojson_data): # Aggregate data by MUNICIPIO if not already aggregated df_grouped = df.groupby(\u0026#39;Nombre Municipio\u0026#39;).sum().reset_index() # Calculate the percentage of women registered voters df_grouped[\u0026#39;Women Percentage\u0026#39;] = (df_grouped[\u0026#39;Lista Mujeres\u0026#39;] / df_grouped[\u0026#39;Lista Nominal\u0026#39;]) * 100 ochre_scale = [ [0.0, \u0026#39;#4c78c8\u0026#39;], # Blue [1.0, \u0026#39;#f58518\u0026#39;], # Light ochre (yellow) ] # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson_data, locations=\u0026#39;Nombre Municipio\u0026#39;, color=\u0026#39;Women Percentage\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_continuous_scale=ochre_scale, projection=\u0026#34;mercator\u0026#34;, title=\u0026#34;Percentage of Women in Voter Registration\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) # Update layout for colorbar position fig.update_layout( coloraxis_colorbar=dict( title=\u0026#39;Women Percentage\u0026#39;, orientation=\u0026#39;h\u0026#39;, x=0.5, xanchor=\u0026#39;center\u0026#39;, y=-0.2, thickness=10, # Adjust the thickness of the colorbar len=0.65 # Set the length as a fraction of the plot area width ) ) return fig #----------------------------------------------------------------------------- def create_winning_party_per_year_choropleth(selected_year, geojson, main_parties, df_dict): # This function now handles a single year\u0026#39;s DataFrame and generates a choropleth map for that year. df_year = df_dict[selected_year] winning_party_by_municipality = {} for municipality in df_year[\u0026#39;MUNICIPIO\u0026#39;].unique(): votes_by_party = {main_party: 0 for main_party in main_parties} # for main_party, parties in alliance_mapping.items(): # for party in parties: # if party in df_year.columns: # votes_by_party[main_party] += df_year.loc[df_year[\u0026#39;MUNICIPIO\u0026#39;] == municipality, party].sum() for party in main_parties: if party in df_year.columns: votes_by_party[party] += df_year.loc[df_year[\u0026#39;MUNICIPIO\u0026#39;] == municipality, party].sum() winning_party = max(votes_by_party, key=votes_by_party.get) winning_party_by_municipality[municipality] = winning_party df_map = pd.DataFrame(list(winning_party_by_municipality.items()), columns=[\u0026#39;MUNICIPIO\u0026#39;, \u0026#39;Winning Party\u0026#39;]) df_map[\u0026#39;Year\u0026#39;] = selected_year fig = px.choropleth( df_map, geojson=geojson, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Winning Party\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, projection=\u0026#34;mercator\u0026#34;, color_discrete_sequence=px.colors.qualitative.T10, ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) fig.update_layout(title=f\u0026#34;Winning Party per Municipality, {selected_year}\u0026#34;) return fig #-------------------------------------------------------------------------------------- def plot_election_pie_chart(selected_year, selected_municipality, df_re_all_years, main_parties): # mapping years to their indices in the list of dataframes year_to_index = {2009: 0, 2012: 1, 2015:2, 2018: 3, 2021: 4} selected_year_index = year_to_index.get(selected_year) if selected_year_index is None: print(f\u0026#34;No data available for the year {selected_year}.\u0026#34;) return # extract the dataframe for the selected year df_selected_year = df_re_all_years[selected_year_index] # filtering the df for the selected municipality df_municipality = df_selected_year[df_selected_year[\u0026#39;MUNICIPIO\u0026#39;] == selected_municipality] if df_municipality.empty: print(f\u0026#39;No data available for {selected_municipality}.\u0026#39;) return # aggregating votes for each main party votes_by_party = {main_party: 0 for main_party in main_parties} for party in main_parties: if party in df_municipality.columns: votes_by_party[party] += df_municipality[party].sum() # create the pie chart df_votes = pd.DataFrame(list(votes_by_party.items()), columns = [\u0026#39;Party\u0026#39;, \u0026#39;Votes\u0026#39;]) fig = px.pie(df_votes, values = \u0026#39;Votes\u0026#39;, names = \u0026#39;Party\u0026#39;, title = f\u0026#39;Vote Distribution in {selected_municipality}, {selected_year}\u0026#39;, color_discrete_sequence=px.colors.qualitative.T10) # Update the traces to remove the text labels fig.update_traces(textinfo=\u0026#39;none\u0026#39;, hoverinfo=\u0026#39;label+percent\u0026#39;) return fig #------------------------------------------------------------------------------------ def plot_aggregated_votes_by_main_party_px(df_list, main_parties, selected_municipality, election_years): \u0026#34;\u0026#34;\u0026#34; Plots an interactive line plot with filled areas to zero for each main party and its alliances, in a selected municipality across elections using Plotly Express. This approximates the non-stacked area plot behavior of the original function. \u0026#34;\u0026#34;\u0026#34; # initialize dictionary to hold vote totals for main parties votes_by_main_party = {main_party: [0] * len(election_years) for main_party in main_parties} # loop through each DataFrame and year for i, (df, year) in enumerate(zip(df_list, election_years)): # filter the DataFrame for the selected municipality if selected_municipality in df[\u0026#39;MUNICIPIO\u0026#39;].values: filtered_df = df[df[\u0026#39;MUNICIPIO\u0026#39;] == selected_municipality] # loop through each main party and its alliances for party in main_parties: # aggregate votes for each party in the alliance, adding to the main party\u0026#39;s total if party in filtered_df.columns: votes_by_main_party[party][i] += filtered_df[party].sum() # prepare the data for plotting data_for_plotting = [] for main_party, votes in votes_by_main_party.items(): for year, vote in zip(election_years, votes): data_for_plotting.append({\u0026#39;Election Year\u0026#39;: year, \u0026#39;Total Votes\u0026#39;: vote, \u0026#39;Party\u0026#39;: main_party}) df_plot = pd.DataFrame(data_for_plotting) # create the plot fig = px.line(df_plot, x=\u0026#39;Election Year\u0026#39;, y=\u0026#39;Total Votes\u0026#39;, color=\u0026#39;Party\u0026#39;, line_shape=\u0026#39;linear\u0026#39;, title=f\u0026#39;Total Votes per Party (Including Alliances), in {selected_municipality}\u0026#39;, color_discrete_sequence=px.colors.qualitative.T10) # customize the layout fig.update_traces(mode=\u0026#39;lines\u0026#39;, line=dict(width=2.5), fill=\u0026#39;tozeroy\u0026#39;) fig.update_layout(xaxis_title=\u0026#39;Election Year\u0026#39;, yaxis_title=\u0026#39;Total Votes\u0026#39;, legend_title=\u0026#39;Party\u0026#39;, font=dict(family=\u0026#34;Arial, sans-serif\u0026#34;, size=12, color=\u0026#34;#333\u0026#34;), hovermode=\u0026#39;x unified\u0026#39;, legend = dict( orientation = \u0026#39;h\u0026#39;, yanchor = \u0026#39;bottom\u0026#39;, y = -0.6, # adjuist to fit layout xanchor = \u0026#39;center\u0026#39;, x = 0.5 )) return fig #---------------------------------------------------------------------------------------------- # HELPER function to get the municipalities per selected year def get_municipalities_per_year(df_dict, selected_year): df_selected = df_dict.get(selected_year) if df_selected is None: print(f\u0026#34;No data available for the year {selected_year}.\u0026#34;) return [] # Retrieve and return a sorted list of unique municipalities return sorted(df_selected[\u0026#39;MUNICIPIO\u0026#39;].unique()) #------------------------------------------------------------------------------------------------- def create_voter_turnout_proportion_choropleth(df_resultados, selected_year, geojson_data): # Aggregate data by MUNICIPIO if not already aggregated df_grouped = df_resultados.groupby(\u0026#39;MUNICIPIO\u0026#39;).agg({ \u0026#39;TOTAL_VOTOS\u0026#39;: \u0026#39;sum\u0026#39;, \u0026#39;LISTA_NOMINAL\u0026#39;: \u0026#39;sum\u0026#39; }).reset_index() df_grouped[\u0026#39;Porcentaje Votantes\u0026#39;] = df_grouped[\u0026#39;TOTAL_VOTOS\u0026#39;] / df_grouped[\u0026#39;LISTA_NOMINAL\u0026#39;] * 100 ochre_scale = [ [0.0, \u0026#39;#4c78c8\u0026#39;], # Blue [1.0, \u0026#39;#f58518\u0026#39;], # Light ochre (yellow) ] # Assuming `geojson` is your GeoJSON object for the municipalities fig = px.choropleth( df_grouped, geojson=geojson_data, locations=\u0026#39;MUNICIPIO\u0026#39;, color=\u0026#39;Porcentaje Votantes\u0026#39;, featureidkey=\u0026#34;properties.NOMGEO\u0026#34;, color_continuous_scale=ochre_scale, projection=\u0026#34;mercator\u0026#34;, title=f\u0026#34;Voter Turnout Percentage in {selected_year}\u0026#34; ) fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=False) # Update layout for colorbar position fig.update_layout( coloraxis_colorbar=dict( title=(f\u0026#39;Voter Turnout Percentage in {selected_year}\u0026#39;), orientation=\u0026#39;h\u0026#39;, x=0.5, xanchor=\u0026#39;center\u0026#39;, y=-0.2, thickness=10, # Adjust the thickness of the colorbar len=0.65 # Set the length as a fraction of the plot area width ) ) return fig # static figures: static_choropleth_percentage_women = create_gender_proportion_choropleth(df_ln_sx_qroo, geojson_data) static_choropleth_age = create_age_choropleth(df_ln_age_qroo, geojson_data) static_choropleth_totals = create_total_choropleth(df_ln_sx_qroo, geojson_data) static_bar_totals = create_total_bar_plot(df_ln_sx_qroo) # Create a Dash application # app = Dash(__name__) # Assuming you\u0026#39;re fine with adding Bootstrap to your project app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP]) app.css.append_css({\u0026#39;external_url\u0026#39;: \u0026#39;/assets/styles.css\u0026#39;}) colors = { \u0026#39;background\u0026#39;: \u0026#39;#111111\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;#7FDBFF\u0026#39; } server = app.server # Layout app.layout = dbc.Container([ html.H1(\u0026#34;Elections Dashboard\u0026#34;), dbc.Row([ dbc.Col(dcc.Dropdown( id=\u0026#39;year-dropdown\u0026#39;, options=[{\u0026#39;label\u0026#39;: year, \u0026#39;value\u0026#39;: year} for year in sorted(set(election_years))], value=sorted(set(election_years))[0], # Default to the earliest year className=\u0026#39;dropdown\u0026#39; ), width = 12, lg = 6, className = \u0026#39;mb-2\u0026#39;), dbc.Col(dcc.Dropdown( id=\u0026#39;municipio-dropdown\u0026#39;, className=\u0026#39;dropdown\u0026#39; ), width = 12, lg = 6, className = \u0026#39;mb-2\u0026#39;) ]), dbc.Row([ dbc.Col(dcc.Graph(id=\u0026#39;time-series-plot\u0026#39;, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6), dbc.Col(dcc.Graph(id=\u0026#39;pie-chart\u0026#39;, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6) ]), dbc.Row([ dbc.Col(dcc.Graph(id=\u0026#39;choropleth-total-voters\u0026#39;, figure = static_choropleth_totals, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6), dbc.Col(dcc.Graph(id=\u0026#39;choropleth-turnout\u0026#39;, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6) ]), dbc.Row([ dbc.Col(dcc.Graph(id=\u0026#39;choropleth-age\u0026#39;, figure=static_choropleth_age, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6), dbc.Col(dcc.Graph(id=\u0026#39;choropleth-women\u0026#39;, figure=static_choropleth_percentage_women, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6) ]), dbc.Row([ dbc.Col(dcc.Graph(id=\u0026#39;choropleth-winning\u0026#39;, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6), dbc.Col(dcc.Graph(id=\u0026#39;bar-total-voters\u0026#39;, figure=static_bar_totals, className=\u0026#39;graph-container\u0026#39;), width = 12, lg = 6) ]) ], fluid=True) # Callback to update municipio dropdown based on year selection @app.callback( Output(\u0026#39;municipio-dropdown\u0026#39;, \u0026#39;options\u0026#39;), Output(\u0026#39;municipio-dropdown\u0026#39;, \u0026#39;value\u0026#39;), [Input(\u0026#39;year-dropdown\u0026#39;, \u0026#39;value\u0026#39;)] ) def set_municipio_options(selected_year): # Assuming a function that returns municipios for a given year municipalities = get_municipalities_per_year(df_dict, selected_year) options = [{\u0026#39;label\u0026#39;: m, \u0026#39;value\u0026#39;: m} for m in municipalities] new_value = municipalities[0] if municipalities else None # Default to first municipality or None return options, new_value # Callback to update interactive visualizations @app.callback( [Output(\u0026#39;time-series-plot\u0026#39;, \u0026#39;figure\u0026#39;), Output(\u0026#39;pie-chart\u0026#39;, \u0026#39;figure\u0026#39;), Output(\u0026#39;choropleth-winning\u0026#39;, \u0026#39;figure\u0026#39;), Output(\u0026#39;choropleth-turnout\u0026#39;, \u0026#39;figure\u0026#39;)], [Input(\u0026#39;year-dropdown\u0026#39;, \u0026#39;value\u0026#39;), Input(\u0026#39;municipio-dropdown\u0026#39;, \u0026#39;value\u0026#39;)] ) def update_visualizations(selected_year, selected_municipality): time_series_chart = plot_aggregated_votes_by_main_party_px( df_re_all_years, main_parties, selected_municipality, election_years ) pie_chart_per_municipality_per_year = plot_election_pie_chart( selected_year, selected_municipality, df_re_all_years, main_parties ) choropleth_winning_party_per_year = create_winning_party_per_year_choropleth( selected_year, geojson_data, main_parties, df_dict ) df_resultados = df_dict[selected_year] voter_proportion_choropleth = create_voter_turnout_proportion_choropleth(df_resultados, selected_year, geojson_data) return (time_series_chart, pie_chart_per_municipality_per_year, choropleth_winning_party_per_year, voter_proportion_choropleth) if __name__ == \u0026#39;__main__\u0026#39;: app.run_server() ","permalink":"http://localhost:1313/posts/20240509_election_dash_part_2-dashboard/20240509_election_dash_part_2-dashboard/","summary":"The cleaned data is loadsed and the plot generating functions are refactored here. Then a dashboard is created using dash.","title":"Election Data Dashboard Pt. 2: Dashboard with Dash"},{"content":" Introduction In this tutorial, an AR(p) (Autoregressive model of order p) is employed to analyze the trneds of a time series and forecast the behavior of the signal.\nAuto-regressive models are based on the assumption the behavior of a time series or signal depends on past values. The order of the AR model tells \u0026ldquo;how far back\u0026rdquo; the past values will affect the current value.\nCredits This exercise is mostly following this tutorial.\nDefinition The AR(p) model is defined as:\n$$ X_t = \\sum_{i=1}^{p} \\phi_i X_{t-i} + \\varepsilon_t $$\nwhere $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ is the model uncertainty represented as white Gaussian noise, i.e. it follows a normal distribution of mean $\\mu=0$ and standard deviation $\\sigma$.\nIt follows that an AR(2) model is defined as:\n$$ X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\varepsilon_t $$\nNaturally, we want to find the parameters $\\theta={\\phi_1, \\phi_2,\\sigma}$. Since these are unobserved quantities of interest, we need to use an inference method to reveal these parameters. We will use Bayesian inference to achieve this goal.\nData Exploration For this example, I will generate artificial data. This will be done by first defining some values for the parameters $\\theta$ and then we will generate random data using those parameters by initializing the $X_1, X_2$ values, and then applying the AR(2) equation to generate the subsequent values.\nFirst, we import the relevant packages.\nusing StatsPlots, Turing, LaTeXStrings, Random, DataFrames Random.seed!(42) TaskLocalRNG()\rNow we create some artificial data. The steps involved in this are as follows:\nDefine some values for the parameters $\\theta$ Set the number of timesteps t Initialize an empty vector of size $\\mathbb{R}^{t+p}$ Initialize the first two $X$ values with randomly generated numbers using rand Populate the vector by using the equation for $X_t$ # define true values for θ true_phi_1 = -0.4 true_phi_2 = 0.3 true_sigma = 0.12 # define the time steps time = 100 # create an empty X vector X = Vector{Float64}(undef, time+2) # initialize the X vector with two random values at time steps 1 and 2 # to do this, use a random normally distributed number with mean zero and standard deviation σ, i.e., ε~N(0, σ) X[1] = rand(Normal(0, true_sigma)) X[2] = rand(Normal(0, true_sigma)) # populate vector X for t in 3:(time+2) X[t] = true_phi_1*X[t-1] + true_phi_2*X[t-2] + rand(Normal(0, true_sigma)) end\tVisualize the (Artificial) Data p_data = plot(X[3:end], legend = false, linewidth = 2, # xlims = (0, 60), # ylims = (-0.6, 0.6), title = \u0026#34;Bayesian Autoregressive AR(2) Model\u0026#34;, xlabel = L\u0026#34;t\u0026#34;, ylabel = L\u0026#34;X_t\u0026#34;, widen = true ) Modeling The next step is to construct our probabilistic model. Again, the goal here is to infer the values of the model parameters $\\theta$. Once we have inferred these parameters, we can make probabilistic predictions on the future behavior of the signal $X$.\nBayesian model Since we are using a Bayesian approach, our goal, in Bayesian terms, is to find the posterior distribution of the parameters $\\theta$, given a prior distribution, or prior knowledge, of the parameters before making any observations, i.e., seeing any data, and also a likelihood function, which reflects what kind of distribution (we assume) that the data is sourced from. Another way of understanding the likelihood function is the probability of making a set of observations $X$ given the parameters $\\theta$.\nThis relationship is established by Bayes\u0026rsquo; Theorem:\n$$ P(\\theta | X) \\propto P(X | \\theta)P(\\theta) $$\nIn summary, constructing the Bayesian model in this case comprises a selection of prior distributions for our unknown parameters $\\theta$ and a likelihood function. We will do this using the Turing.jl package.\nThe model therefore will consist of the prior distributions:\n$$ \\begin{align*} \\phi_1 \u0026amp; \\sim \\mathcal{N}(0, 1) \\ \\phi_2 \u0026amp; \\sim \\mathcal{N}(0, 1) \\ \\sigma \u0026amp; \\sim \\text{Exp}(1) \\end{align*} $$\nAnd the likelihood:\n$$ X_t \\sim \\mathcal{N}(\\mu_t, \\sigma) $$\nwhere $\\mu_t = \\sum_{i=1}^{p} \\phi_i X_{t-i}$ is the mean function of the distribution that governs X_t.\nA comment on the choice of priors For autoregressive parameters, using a normal distribution is a common choice. This is because the normal distribution is convenient and allows for a range of plausible values.\nFor the prior on the model uncertainty, the exponential distribution is sometimes used for non-negative parameters and has a similar role to the inverse gamma.\nFurthermore, the inverse gamma distribution is often chosen as a prior for the standard deviation because it is conjugate to the normal likelihood. This means that the posterior distribution will have a known form, making computations more tractable.\nBayesian model using Turing.jl Now we proceed to set up the model using the Turing.jl package.\n@model function ar(X, time) # pass the data X and the time vector # priors phi_1 ~ Normal(0, 1) phi_2 ~ Normal(0, 1) sigma ~ Exponential(1) # likelihood # initialize with random initial values X[1] ~ Normal(0, sigma) X[2] ~ Normal(0, sigma) # populate with samples for i in 3:(time+2) mu = phi_1*X[i-1] + phi_2*X[i-2] X[i] ~ Normal(mu, sigma) end end ar (generic function with 2 methods)\rmodel = ar(X, time) sampler = NUTS() samples = 1_000 chain = sample(model, sampler, samples) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.4\r\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\rChains MCMC chain (1000×15×1 Array{Float64, 3}):\rIterations = 501:1:1500\rNumber of chains = 1\rSamples per chain = 1000\rWall duration = 11.59 seconds\rCompute duration = 11.59 seconds\rparameters = phi_1, phi_2, sigma\rinternals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\rSummary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m e\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m \u001b[0m ⋯\rphi_1 -0.3830 0.1047 0.0036 836.6151 762.4445 0.9996 ⋯\rphi_2 0.1587 0.1012 0.0035 838.3014 749.6718 1.0002 ⋯\rsigma 0.1083 0.0079 0.0003 755.4034 743.3822 1.0014 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\rphi_1 -0.5733 -0.4562 -0.3858 -0.3141 -0.1771\rphi_2 -0.0339 0.0913 0.1562 0.2256 0.3549\rsigma 0.0943 0.1030 0.1079 0.1130 0.1257\rVisualize and Summarize the Results Next we can access the MCMC Diagnostics and generate a summary of the results.\nplot(chain) DataFrame(summarystats(chain)) 3×8 DataFrameRowparametersmeanstdmcseess_bulkess_tailrhatess_per_secSymbolFloat64Float64Float64Float64Float64Float64Float641phi_1-0.3830190.1046950.00361324836.615762.4440.99958572.16552phi_20.1586610.1011960.00351463838.301749.6721.0002172.3113sigma0.1083420.007886220.000291067755.403743.3821.0014565.1603\rPredictions Making Predictions To make predictions, the following steps are taken:\nSet the number of time steps into the future, $t_f$ Initialize an empty matrix for the forecasted $X$ values - This will be a matrix because it will be a collection of vectors. Each vector will represent one sample forecast Initialize two steps of each of the sample vectors to be generated - In practical terms, initialize the first number of each column; each column will represent a forecast time series Keep in mind that what will be done here is to create samples of the future behavior of the signal $t_f$ number of time steps into the future. To do this, we will generate signals that use the posterior distributions of the parameters $\\theta$ by calling the function rand(chain[:,Z,Z]) which will randomly pick a number out of the sample pool, effectively \u0026ldquo;sampling\u0026rdquo; from that posterior distribution (sample pool).\ntime_future = 15 X_future = Matrix{Float64}(undef, time_future+2, samples) # Initialize the first two time steps for every forecast X_future[1, :] .= X[time-1] X_future[2, :] .= X[time] # populate the forecast vectors by sampling from the posterior sample pool of the parameters θ for col in 1:samples phi_1_future = rand(chain[:,1,1]) phi_2_future = rand(chain[:,2,1]) error_future = rand(chain[:,3,1]) noise_future = rand(Normal(0, error_future)) for row in 3:(time_future+2) X_future[row, col] = phi_1_future * X_future[row-1, col] + phi_2_future * X_future[row-2, col] + noise_future end end Visualize the forecast Now that we propagated the uncertainty of in the posterior distribution of the parameters $\\theta$, we can plot the posterior predictive distribution of $X$, $P(X^*|\\theta)$.\ntime_predict = time:(time + time_future) for i in 1:samples plot!(p_data, time_predict, X_future[2:end, i], legend = false, # predictions linewidth = 1, color = :green, alpha = 0.1 ) end p_data # visualize mean values for predictions X_future_mean = [mean(X_future[i, 1:samples]) for i in 2:(time_future+2)] plot!(p_data, time_predict, X_future_mean, legend = false, linewidth = 2, color = :red, linestyle = :dot ) ","permalink":"http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/","summary":"This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning.","title":"Bayesian Time Series Analysis with Julia and Turing.jl"},{"content":" In this example, I am following the tutorials found in:\nTuring.jl - Bayesian Poisson Regression PyMC - GLM: Poisson Regression Both examples show the interaction between some variables and a discrete outcome. In this case, the outcome is the number of sneezes per day (i.e. a discrete outcome) in some study subjects, and whether or not they take antihistamine medicine and whether or not they drink alcohol.\nThis example explores how these factors, and more specifically, the combination of these factors, affect the number of times a person sneezes.\nusing CSV, DataFrames, Turing, StatsPlots, Plots, Random Random.seed!(42) TaskLocalRNG()\rCollect (generate) the data In this example, we will generate the data in the same way as in the tutorials:\nNo Alcohol Alcohol No Meds 6 36 Meds 1 3 Those values will be used to create the artificial data by generating Poisson-distributed random samples.\ntheta_noalc_nomed = 6 theta_noalc_med = 1 theta_alc_nomed = 36 theta_alc_med = 3 ns = 500 # number of samples # create a data frame data = DataFrame( hcat( vcat( rand(Poisson(theta_noalc_med), ns), rand(Poisson(theta_alc_med), ns), rand(Poisson(theta_noalc_nomed), ns), rand(Poisson(theta_alc_nomed), ns) ), vcat( falses(ns), trues(ns), falses(ns), trues(ns) ), vcat( falses(ns), falses(ns), trues(ns), trues(ns) ) ), :auto ) # assign names to headers head_names = [:n_sneezes, :alcohol, :nomeds] sneeze_data = DataFrame(data, head_names) first(sneeze_data, 10) 10×3 DataFrameRown_sneezesalcoholnomedsInt64Int64Int6410002100300040005100610071008100920010200\rVisualize the data Now that we have \u0026ldquo;collected\u0026rdquo; some data on the number of sneezes per day from a number of people, we visualize the data.\nThe way we are collecting and plotting these data sub-sets is as follows:\nCall the histogram function Create a histogram of the dataframe \u0026ldquo;sneeze_data\u0026rdquo; we \u0026ldquo;collected\u0026rdquo; previously Select a subset of that dataframe All the rows of the columns where alcohol is false i.e. 0 AND all the rows where no medicine was taken is also false All the rows of the columns where alcohol is false AND all the rows of where medicine is true \u0026hellip; and so on # create separate histograms for each case p1 = histogram(sneeze_data[(sneeze_data[:,:alcohol] .== 0) .\u0026amp; (sneeze_data[:,:nomeds] .== 0), :n_sneezes]; title = \u0026#34;No alcohol + No Meds\u0026#34;, ylabel=\u0026#34;People Count\u0026#34;) p2 = histogram(sneeze_data[(sneeze_data[:,:alcohol] .== 1) .\u0026amp; (sneeze_data[:,:nomeds] .== 0), :n_sneezes]; title = \u0026#34;No alcohol + Meds\u0026#34;) p3 = histogram(sneeze_data[(sneeze_data[:,:alcohol] .== 0) .\u0026amp; (sneeze_data[:,:nomeds] .== 1), :n_sneezes]; title = \u0026#34;Alcohol + No Meds\u0026#34;, xlabel = \u0026#34;Sneezes/Day\u0026#34;, ylabel=\u0026#34;People Count\u0026#34;) p4 = histogram(sneeze_data[(sneeze_data[:,:alcohol] .== 1) .\u0026amp; (sneeze_data[:,:nomeds] .== 1), :n_sneezes]; title = \u0026#34;Alcohol + Meds\u0026#34;, xlabel = \u0026#34;Sneezes/Day\u0026#34;) plot(p1, p2, p3, p4; layout=(2,2), legend = false) Interpreting the data The histograms show that the data from the \u0026ldquo;study\u0026rdquo; resembles a Poisson distribution (as mentioned in the PyMC tutorial, this is obvious, because that\u0026rsquo;s how the data is generated!). Furthermore, the data is telling us something:\nLooking at the plot for \u0026ldquo;no alcohol and medicine\u0026rdquo; it is clear that most people reported very few sneezes; notice how the histogram skews towards large counts (of people) for very few sneezes On the other hand, notice how the \u0026ldquo;alcohol and no medicine\u0026rdquo; seems to tell us that many reported somewhere around 35 sneezes per day Again, we can start thinking of a pattern just by looking at the data, and it seems like the data is telling us that if you don\u0026rsquo;t drink alcohol and take antihistamines, you are less likely to be sneezing around than if you drink alcohol and don\u0026rsquo;t take any allergy meds. Makes sense, right?\nModel We established that the data looks like it could be modelled as a Poisson distribution. Thus, we can define our probabilistic model as follows:\n$$Y_{obs} \\sim Poisson(\\lambda)$$\n$$\\log(\\lambda) = \\theta\u0026rsquo;\\mathbf{x} = \\alpha + \\beta\u0026rsquo; \\mathbf{x}$$\nWhat the above means is that we assume that the observed data outcomes, i.e., the number of sneezes per day, follow a Poisson distribution, which is a discrete probability distribution that models the number of events that occur in a fixed interval of time or space. The rate or intensity of the events, $\\lambda$, depends on the predictor variables (the input data) $\\mathcal{x}$, such as the season, the temperature, or, in our case, whether a person ingested alcohol and whether the person took antihistamines.\nThe linear predictor $\\theta\u0026rsquo; \\mathcal{x}$ is the function that links the predictor variables to the rate parameter, where $\\theta = {\\alpha, \\beta\u0026rsquo;}$ are the parameters of the model.\nLooking at the structure of the linear relationship between the paramters of the model, and the predictors:\n$$\\log(\\lambda) = \\alpha + \\beta\u0026rsquo; \\mathcal{x}$$\nwe can understand that the parameter $\\alpha$ is the intercept, which is the expected number of sneezes when all the predictor variables are zero. The parameter $\\beta\u0026rsquo;$ is a vector of coefficients, which measure the effect of each predictor variable $\\mathcal{x}$ on the number of sneezes. The log link function ensures that the rate parameter $\\lambda$ is always positive and allows for multiplicative effects of the predictor variables on the response variable.\nDefine the model with Turing.jl Now that we know how we are modeling our data, we use the package Turing.jl to define the model. Turing.jl is a tool that helps us write models in Julia and find the best parameters for them.\nThe model has two parts: the prior and the likelihood. The prior is what we think or guess about the parameters before we see the data. The likelihood is how likely the data is under the parameters. The parameters are the numbers that control the model, such as the rate of sneezes.\nWe use the Poisson distribution for the likelihood, because it is good for counting things, like sneezes. The Poisson distribution has one parameter, the rate of sneezes. The higher the rate, the more sneezes we expect.\nWe use any distribution for the prior, depending on how much we know about the parameters. If we know nothing, we use a flat prior, which does not favor any value. The prior affects the final answer, because it is our starting point.\nWe use Bayes’ theorem to combine the prior and the likelihood and get the final answer. The final answer is the posterior, which is what we believe about the parameters after we see the data. The posterior is the best fit for the model and the data.\nLet\u0026rsquo;s crank up the Bayes!\n@model function poisson(x, y) # define the priors alpha ~ Normal(0,1) alcohol ~ Normal(0, 1) nomeds ~ Normal(0, 1) # alc_med ~ Normal(0,1) # define the likelihood for i in 1:length(y) log_lambda = alpha + alcohol * x[i, 1] + nomeds * x[i, 2] lambda = exp(log_lambda) y[i] ~ Poisson(lambda) end end poisson (generic function with 2 methods)\r# pass the data to the model function # pass the predictor data as a Matrix for efficiency model = poisson(Matrix(sneeze_data[!,[:alcohol, :nomeds] ]), sneeze_data[!, :n_sneezes]) # select the sampler sampler = NUTS() # define the number of sampler samples = 1000 # set number of chains num_chains = 8 # crank up the Bayes! chain = sample(model, sampler, MCMCThreads(), samples, num_chains) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.00625\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.00625\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.00625\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.00625\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[32mSampling (8 threads): 100%|█████████████████████████████| Time: 0:00:00\u001b[39m\rChains MCMC chain (1000×15×8 Array{Float64, 3}):\rIterations = 501:1:1500\rNumber of chains = 8\rSamples per chain = 1000\rWall duration = 13.66 seconds\rCompute duration = 100.67 seconds\rparameters = alpha, alcohol, nomeds\rinternals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\rSummary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\ralpha -0.5025 0.0277 0.0005 2943.5608 2841.2874 1.0030 ⋯\ralcohol 1.7333 0.0186 0.0003 3801.1996 3652.2403 1.0022 ⋯\rnomeds 2.3348 0.0236 0.0004 2901.3750 3410.6453 1.0020 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\ralpha -0.5568 -0.5212 -0.5023 -0.4839 -0.4486\ralcohol 1.6974 1.7205 1.7331 1.7458 1.7698\rnomeds 2.2891 2.3189 2.3346 2.3506 2.3824\rNOTE: The above routine employs the MCMCThreads method to sample multiple chains. However, in order to implement this, one needs to change the environment variables for the number of threads Julia can use. These two threads might shed some light as to how to achieve this:\nhttps://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794 Of course, if you don\u0026rsquo;t want to bother, then just change the last two functional lines in the cell above so that they read:\n# set number of chains - comment this out: # num_chains = 8 # crank up the Bayes! - delete MCMCThreads() and num_chains chain = sample(model, sampler, samples) Visualize the results We can see above that we have obtained a sample pool of the posterior distribution of the parameters. This is what we were looking for. What this means is that now we have a posterior distribution (in the form of a sample pool), which we can also summarize with summary statistics.\nLet\u0026rsquo;s look at the diagnostics plots and the summary statistics.\nplot(chain) DataFrame(summarystats(chain)) 3×8 DataFrameRowparametersmeanstdmcseess_bulkess_tailrhatess_per_secSymbolFloat64Float64Float64Float64Float64Float64Float641alpha-0.5025190.02765530.0005110692943.562841.291.0029829.23972alcohol1.73330.01860970.0003016113801.23652.241.0022437.7593nomeds2.33480.02362690.0004363852901.383410.651.0019728.8207\r# taking the first chain c1 = chain[:, :, 1] # Calculating the exponentiated means b0_exp = exp(mean(c1[:alpha])) b1_exp = exp(mean(c1[:alcohol])) b2_exp = exp(mean(c1[:nomeds])) println(\u0026#34;The exponent of the mean of the weights (or coefficients) are: \\n\u0026#34;) println(\u0026#34;b0: \u0026#34;, b0_exp) println(\u0026#34;b1: \u0026#34;, b1_exp) println(\u0026#34;b2: \u0026#34;, b2_exp) The exponent of the mean of the weights (or coefficients) are: b0: 0.604415461752317\rb1: 5.658573583760772\rb2: 10.342642711232362\rNotice how we are not recovering the original $\\lambda$ values that were used to create this data set, i.e.:\ntheta_noalc_nomed = 6 theta_noalc_med = 1 theta_alc_nomed = 36 theta_alc_med = 3 Instead, we are recovering the parameters of the linear function, in other words, $\\theta = {\\alpha, \\beta\u0026rsquo;}$ in the linear relation:\n$$\\log(\\lambda) = \\alpha + \\beta_1 x_{alc} + \\beta_2 x_{meds}$$\nwhere $x_{(\\cdot)}$ represents the binary variable of whether the subject took alcohol/medicine or not.\nConclusion This tutorial shows how to perform Bayesian inference on discrete data, e.g. the record of how many sneezes per day a group of people had, and classified according to their alcohol and medication consumption.\nIn real-world scenarios, we would obviously not know the parameter values, since this is precisely what we want to find out by incorporating whatever we knew about them into what we observed.\n","permalink":"http://localhost:1313/posts/20240217_bayesian_poisson_regression/20240217_bayesian_poisson_regression/","summary":"Explore Bayesian Poisson regression for modeling count data with Julia and Turing.jl. This tutorial includes model setup, implementation, and performance assessment with a practical example.","title":"Bayesian Poisson Regression with Julia and Turing.jl"},{"content":" Problem Statement You are interested in studying the factors that influence the likelihood of heart disease among patients.\nYou have a dataset of 303 patients, each with 14 variables: age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise induced angina, oldpeak, slope, number of major vessels, thalassemia, and diagnosis of heart disease.\nYou want to use Bayesian logistic regression to model the probability of heart disease (the outcome variable) as a function of some or all of the other variables (the predictor variables).\nYou also want to compare different models and assess their fit and predictive performance.\nBayesian Workflow For this project, I will try to follow this workflow:\nData exploration: Explore the data using descriptive statistics and visualizations to get a sense of the distribution, range, and correlation of the variables. Identify any outliers, missing values, or potential errors in the data. Transform or standardize the variables if needed.\nModel specification: Specify a probabilistic model that relates the outcome variable to the predictor variables using a logistic regression equation. Choose appropriate priors for the model parameters, such as normal, student-t, or Cauchy distributions. You can use the brms package in Julia to define and fit Bayesian models using a formula syntax similar to lme4. However, try to use Turing.jl\nModel fitting: Fit the model using a sampling algorithm such as Hamiltonian Monte Carlo (HMC) or No-U-Turn Sampler (NUTS). You can use the DynamicHMC or Turing.jl package in Julia to implement these algorithms. Check the convergence and mixing of the chains using diagnostics such as trace plots, autocorrelation plots, effective sample size, and potential scale reduction factor. You can use the MCMCDiagnostics or the included diagnostics features in Turing.jl package in Julia to compute these diagnostics.\nModel checking: Check the fit and validity of the model using posterior predictive checks, residual analysis, and sensitivity analysis. You can use the PPCheck package in Julia to perform posterior predictive checks, which compare the observed data to data simulated from the posterior predictive distribution. You can use the BayesianRidgeRegression package in Julia to perform residual analysis, which plots the residuals against the fitted values and the predictor variables. You can use the Sensitivity package in Julia to perform sensitivity analysis, which measures how the posterior distribution changes with respect to the prior distribution or the likelihood function.\n# import packages using CSV, Turing, DataFrames, StatsPlots, LaTeXStrings, Distributions using Images, ImageIO using Random: seed! seed!(42) Random.TaskLocalRNG()\rData Exploration After \u0026ldquo;collecting\u0026rdquo; the data, we may import it and arrange it so we can use it further.\nThe data set can be found in this Kaggle link.\ndf = CSV.read(\u0026#34;data/processed_cleveland.csv\u0026#34;, DataFrame) map!(x -\u0026gt; x != 0 ? 1 : 0, df.num, df.num); # make the outcome binary df 303×14 DataFrame278 rows omittedRowagesexcptrestbpscholfbsrestecgthalachexangoldpeakslopecathalnumInt64Int64Int64Int64Int64Int64Int64Int64Int64Float64Int64String1String1Int64163111452331215002.33060267141602860210811.52331367141202290212912.62271437131302500018703.53030541021302040217201.41030656121202360017800.81030762041402680216003.63231857041203540016310.61030963141302540214701.421711053141402031215513.130711157141401920014800.420601256021402940215301.320301356131302561214210.62161\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;\u0026vellip;29255021323420016601.2103029344141201690014412.8306129463141401870214414.0127129563041241970013610.0203129641121201570018200.010302975914164176129001.0226129857041402410012310.2207129945111102640013201.2207130068141441931014103.4227130157141301310011511.2217130257021302360217400.0213130338131381750017300.01?30\rIn the above data frame, the attributes are as follows:\nVariable Name Role Type Demographic Description Units Missing Values age Feature Integer Age years no sex Feature Categorical Sex no cp Feature Categorical no trestbps Feature Integer resting blood pressure (on admission to the hospital) mm Hg no chol Feature Integer serum cholestoral mg/dl no fbs Feature Categorical fasting blood sugar \u0026gt; 120 mg/dl no restecg Feature Categorical no thalach Feature Integer maximum heart rate achieved no exang Feature Categorical exercise induced angina no oldpeak Feature Integer ST depression induced by exercise relative to rest no Complete attribute documentation:\n1. age: age in years\r2. sex: sex (1 = male; 0 = female)\r3. cp: chest pain type\r- Value 1: typical angina\r- Value 2: atypical angina\r- Value 3: non-anginal pain\r- Value 4: asymptomatic\r4. trestbps: resting blood pressure (in mm Hg on admission to the\rhospital)\r5. chol: serum cholestoral in mg/dl\r6.fbs: fasting blood sugar \u0026gt; 120 mg/dl (1 = true; 0 = false)\r7. restecg: resting electrocardiographic results\r- Value 0: normal\r- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of \u0026gt; 0.05 mV)\r- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\r8. thalach: maximum heart rate achieved\r9. exang: exercise induced angina (1 = yes; 0 = no)\r10. oldpeak: ST depression induced by exercise relative to rest\r11. slope: the slope of the peak exercise ST segment\r- Value 1: upsloping\r- Value 2: flat\r- Value 3: downsloping\r12. ca: number of major vessels (0-3) colored by flourosopy (for calcification of vessels)\r13. thal: results of nuclear stress test (3 = normal; 6 = fixed defect; 7 = reversable defect)\r14. num: target variable representing diagnosis of heart disease (angiographic disease status) in any major vessel\r- Value 0: \u0026lt; 50% diameter narrowing\r- Value 1: \u0026gt; 50% diameter narrowing\rData Interpretation After collecting the data, it has been imported as a Data Frame. Now, to understand what we will do with this exercise, we need to analyze the data by means of Bayesian Logistic Regression.\nWith this type of analysis, we can make predictions on (typically) binary outcomes, based on a set of parameters. In this particular case, we are interested in predicting whether a patient will have heart disease based on a set of parameters such as age, chest pain, blood pressure, etc.\nIn terms of the data available, we have a set of 303 observations (303 patients) whose symptoms and circumstances have been recorded, and the outcome is the heart disease diagnosis. To simplify things, this data set has a binary outcome, i.e. heart disease present/not present.\nAdditionally, this study is divided in two parts: first, I will set up the logistic regression model to include only one predictor, i.e., age. Afterwards, an analysis will be performed including two or more predictors.\n# find the range for the age, to set the plot limits below # min_age = minimum(df.age) min_age = 15 max_age = 85 # visualize data p_data = scatter(df.age, df.num, legend = false, xlims = (min_age, max_age), color = :red, markersize = 5, title = \u0026#34;Probability of Heart Disease\u0026#34;, xlabel = \u0026#34;Age (years)\u0026#34;, ylabel = \u0026#34;Probability of Heart Disease\u0026#34;, widen = true, dpi = 150 ) Model Specification In this stage of the workflow, we will specify the Bayesian model and then use Turing.jl to program it in Julia.\nThe model I will use for this analysis is a Bayesian Logistic Regression model, which relates the probability of heart disease to a linear combination of the predictor variables, using a logistic function. The model can be written as:\n$$\\begin{aligned} y_i \u0026amp;\\sim Bernoulli(p_i) \\\\ p_i \u0026amp;= \\frac{1}{1+e^{-\\eta_i}} \\\\ \\eta_i \u0026amp;= \\alpha + {\\beta_1 x_{i,1}} + {\\beta_2 x_{i,2}} + \\ldots + {\\beta_{13} x_{i,13}} \\\\ \\alpha \u0026amp;\\sim \\mathcal{N}(\\mu_\\alpha,\\sigma_\\sigma) \\\\ \\beta_j \u0026amp;\\sim \\mathcal{N}(\\mu_{\\beta},\\sigma_{\\beta}) \\\\ \\end{aligned}$$\nwhere $y_i$ is the outcome for the i-th patient, $p_i$ is the probability of heart disease for the i-th patient, $\\eta_i$ is the linear predictor for the i-th patient, $\\alpha$ and $\\beta_j$ are the intercept and coefficient for the j-th predictor variable, respectively, and $x_{ij}$ is the value of the j-th predictor variable for the i-th patient.\nThe assumptions that I am making are:\nThe outcome variable follows a Bernoulli distribution, i.e. $y_i \\sim Bernoulli(p_i)$, which is appropriate for binary outcomes The predictor variables are linearly related to the log-odds of the outcome variable, i.e. $\\log(\\frac{p}{1-p})$ which is a common assumption for logistic regression models The prior distributions for the model parameters are uniform, which are weakly informative and reflect my prior beliefs about the plausible range of the parameters Regarding point (2):\nThat statement means that the log-odds of the outcome variable (the log of the odds ratio) can be expressed as a linear function of the predictor variables. Mathematically, this can be written as:\n$$\\log(\\frac{p}{1-p}) = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_k x_k$$\nwhere $p$ is the probability of the outcome variable being 1, $x_1, x_2, \\ldots, x_k$ are the predictor variables, and $\\alpha, \\beta_1, \\beta_2, \\ldots, \\beta_k$ are the coefficients (parameters).\nThis assumption implies that the effect of each predictor variable on the log-odds of the outcome variable is contant, regardless of the values of the other predictor variables. It also implies that the relationship between the predictor variables and the probability of the outcome variable is non-linear, as the probability is obtained by applying the inverse of the log-odds function, which is the logistic function:\n$$p = \\frac{1}{1+e^{-(\\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_k x_k)}}$$\nThe logistic function is an S-shaped curve that maps any real number to a value between 0 and 1. It has the property that as the linear predictor increases, the probability approaches 1, and as the linear predictor decreases, the probability approaches 0.\nModel Specification Using Turing.jl # define the Bayesian model @model function logit_model(predictors, disease) # priors α ~ Normal(0.0,10.0) β ~ Normal(0.0,10.0) # likelihood η = α .+ β.*predictors p = 1 ./ (1 .+ exp.(-η)) # remember to include the \u0026#34;.\u0026#34;! for i in eachindex(p) disease[i] ~ Bernoulli(p[i]) end end logit_model (generic function with 2 methods)\rCrank up the Bayes! Run the model using sample(model, sampler, opt_argument, samples, chains)\n# infer posterior probability model = logit_model(df.age, df.num) sampler = NUTS() samples = 1_000 num_chains = 8 # set the number of chains chain = sample(model, sampler, MCMCThreads(), samples, num_chains) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.025\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.025\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.0125\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.025\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.05\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.025\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.025\r\u001b[32mSampling (8 threads): 100%|█████████████████████████████| Time: 0:00:01\u001b[39m\rChains MCMC chain (1000×14×8 Array{Float64, 3}):\rIterations = 501:1:1500\rNumber of chains = 8\rSamples per chain = 1000\rWall duration = 13.18 seconds\rCompute duration = 100.1 seconds\rparameters = α, β\rinternals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\rSummary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\rα -3.0326 0.7453 0.0210 1242.6057 1246.3034 1.0043 ⋯\rβ 0.0524 0.0134 0.0004 1224.4182 1259.7727 1.0037 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\rα -4.4814 -3.5432 -3.0127 -2.5183 -1.5973\rβ 0.0264 0.0432 0.0521 0.0617 0.0789\rNOTE: The above routine employs the MCMCThreads() method to sample multiple chains. However, to implement this, one needs to change the environment variables for the number of threads Julia can use. These two discussions might shed some light as to how to achieve this:\nhttps://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading https://discourse.julialang.org/t/julia-num-threads-in-vs-code-windows-10-wsl/28794 Of course, if you don\u0026rsquo;t want to bother, then just change the last two functional lines in the cell above so that they read:\n# set number of chains - comment this out:\r# num_chains = 8\r# crank up the Bayes! - delete MCMCThreads() and num_chains\rchain = sample(model, sampler, samples)\rPlot the MCMC Diagnostics plot(chain, dpi = 150) Get the Summary Statistics summarystats(chain) Summary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\rα -3.0326 0.7453 0.0210 1242.6057 1246.3034 1.0043 ⋯\rβ 0.0524 0.0134 0.0004 1224.4182 1259.7727 1.0037 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rPlot and Interpret the Results Ok, how do we interpret the results from a Bayesian approach? Let\u0026rsquo;s start by plotting the results. This will help us understand not only the results, but really grasp the power of a Bayesian model in action.\nFrom a frequentist or a machine learning approach, we would expect to find a function that models the data the best possible way, i.e. fit a model. If we were to visualize it, we would see one single sigmoid curve trying its best to explain the data.\nHow about this chart here, though? This chart is a collection of possible outcomes given that the parameters $\\alpha$ and $\\beta$ in this case, are modeled as random variables with some probability distribution. Therefore, there is an uncertainty associated with them. This uncertainty is naturally propagated onto the sigmoid function. Therefore, there is also an uncertainty associated with that sigmoid curve that we are trying to model.\nAgain, below we can see a collection of possible outcomes given the parameter sample space. There is a darker region where most sigmoid functions turned out, and these tend to be the most probable sigmoid functions, or, in other words, these sigmoid functions are the most probable functions that could fit the data, considering the distributions of the parameters too!\nInt(samples/10) 100\rx_line = 15:1:max_age for i in 1:samples b = chain[i, 1, 1] m = chain[i, 2, 1] line(x) = m*x +b p(x) = 1 / (1 + exp(-line(x)) ) plot!(p_data, x_line, p, legend = false, linewidth = 2, color= :blue, alpha = 0.02, dpi = 150 ) end p_data Making Predictions So why go through all this trouble, you might be asking. Well, one of the reasons we want to use probabilistic models is, first, to make predictions. But I would go further than that: these models are useful when making informed decisions. Let\u0026rsquo;s try this out.\nLet\u0026rsquo;s make predictions for different arbitrary ages (50, 60, 70, 80, 20):\nnew_Age = [50, 60, 70, 80, 20] p_disease = fill(missing, length(new_Age)) predictions = predict(logit_model(new_Age, p_disease), chain) summarystats(predictions) Summary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m \u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m \u001b[0m ⋯\rdisease[1] 0.3855 0.4867 0.0055 7711.3762 NaN 0.9998 ⋯\rdisease[2] 0.5258 0.4994 0.0055 8284.1301 NaN 0.9998 ⋯\rdisease[3] 0.6432 0.4791 0.0056 7441.4457 NaN 1.0002 ⋯\rdisease[4] 0.7555 0.4298 0.0050 7352.4368 NaN 0.9998 ⋯\rdisease[5] 0.1224 0.3277 0.0039 7016.6404 NaN 1.0004 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rInterpreting the predictions The last operations make predictions of heart diseased based on age only. What the predictions mean is that, given the data, the probability distribution of an individual of age 50 to have heart disease has a mean of 0.379, and a standard deviation of 0.485 (this is highly uncertain, by the way).\nSimilarly, a 20-year-old individual has a probability with a mean of 0.13 and standard deviation of 0.336 of having heart disease.\nThese statistics are extremely powerful when you are trying to make decisions, such as when diagnosing Heart Disease. It stands to reason that, if you were a physician, you want to know what your model says might be wrong (or not) with your patient, but you also want to know how much you can trust that prediction.\nIf your model classifies Patient X as having heart disease, you would probably want to know how sure you are of this. And this certainty comes partially from\u0026hellip; you guessed it: your priors and the data.\nIn the plot below, we can see the where the predictions lie. Note that these probabilities are on a continuum given by the sigmoid function. But we want our final decision to be a yes or a no. To do that, we need to set a decision threshold.\nWe will do that at the end of the next section.\nfor i in 1:length(new_Age) pred_mean = mean(predictions[:, i, 1]) pred_plot = scatter!(p_data, (new_Age[i], pred_mean), dpi=150) end p_data Model Specification Using Multiple Predictors Some Data Cleaning In this part, I am using the Turing.jl documentation tutorial found in https://turinglang.org/dev/tutorials/02-logistic-regression/.\nIn the tutorial, they quite rightly incorporate a train/test split, and data normalization, which is the recommended practice. I didn\u0026rsquo;t do it in the first part of this tutorial to keep things simple!\nHere is how they handle the split and the data normalization using MLUtils.\nfunction split_data(df, target; at=0.70)\rshuffled = shuffleobs(df)\rreturn trainset, testset = stratifiedobs(row -\u0026gt; row[target], shuffled; p=at)\rend\rfeatures = [:StudentNum, :Balance, :Income]\rnumerics = [:Balance, :Income]\rtarget = :DefaultNum\rtrainset, testset = split_data(data, target; at=0.05)\rfor feature in numerics\rμ, σ = rescale!(trainset[!, feature]; obsdim=1)\rrescale!(testset[!, feature], μ, σ; obsdim=1)\rend\r# Turing requires data in matrix form, not dataframe\rtrain = Matrix(trainset[:, features])\rtest = Matrix(testset[:, features])\rtrain_label = trainset[:, target]\rtest_label = testset[:, target];\rusing MLDataUtils: shuffleobs, stratifiedobs, rescale! using StatsFuns # we introduce this package so we can later call the # logistic function directly instead of defining it manually as before function split_data(df, target; at=0.70) shuffled = shuffleobs(df) return trainset, testset = stratifiedobs(row -\u0026gt; row[target], shuffled; p=at) end features = [:age, :cp, :chol] target = :num trainset, testset = split_data(df, target;) # convert the feature columns to float64 to ensure compatibility with rescale! for feature in features df[!, feature] = float.(df[!, feature]) end for feature in features μ, σ = rescale!(trainset[!, feature]; obsdim=1) rescale!(testset[!, feature], μ, σ; obsdim=1) end # Turing requires data in matrix form, not dataframe train = Matrix(trainset[!, features]) test = Matrix(testset[!, features]) train_label = trainset[!, target] test_label = testset[!, target]; Inference Now that our data is formatted, we can perform our Bayesian logistic regression with multiple predictors: using chest pain (cp), age (age), resting bloodpressure (tresttbps) and cholesterol (chol) levels.\n@model function logreg_multi(X, y) # priors intercept ~ Normal(0.0, 10.0) age ~ Normal(0.0, 10.0) cp ~ Normal(0.0, 10.0) chol ~ Normal(0.0, 10.0) n, _ = size(X) for i in 1:n # call the logistic function directly, instead of manually v = logistic(intercept + age*X[i,1] + cp*X[i,2] + chol*X[i,3]) y[i] ~ Bernoulli(v) end end logreg_multi (generic function with 2 methods)\rX = train y = train_label println(size(train), size(test)) (212, 3)(91, 3)\rNow we build the model and create the chain:\nmodel_multi = logreg_multi(X, y) chain_multi = sample(model_multi, NUTS(), MCMCThreads(), 2_000, 8) # select 2000 samples directly \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 1.6\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.8\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.8\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.8\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.8\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 1.6\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 0.8\r\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 1.6\rChains MCMC chain (2000×16×8 Array{Float64, 3}):\rIterations = 1001:1:3000\rNumber of chains = 8\rSamples per chain = 2000\rWall duration = 11.32 seconds\rCompute duration = 87.27 seconds\rparameters = intercept, age, cp, chol\rinternals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\rSummary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64\u001b[0m ⋯\rintercept -0.2821 0.1647 0.0012 20113.9419 13042.8456 1.0003 ⋯\rage 0.6003 0.1760 0.0013 18327.5449 12926.7418 1.0001 ⋯\rcp 1.0699 0.1922 0.0014 19583.1899 13534.2405 0.9999 ⋯\rchol -0.0073 0.1641 0.0012 18280.4944 12242.8280 1.0004 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\rintercept -0.6118 -0.3923 -0.2817 -0.1711 0.0388\rage 0.2645 0.4792 0.5964 0.7178 0.9575\rcp 0.7106 0.9372 1.0636 1.1963 1.4603\rchol -0.3283 -0.1177 -0.0080 0.1025 0.3151\rPlot the MCMC Diagnostics plot(chain_multi, dpi=150) Summary Statistics summarystats(chain_multi) Summary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64\u001b[0m ⋯\rintercept -0.2821 0.1647 0.0012 20113.9419 13042.8456 1.0003 ⋯\rage 0.6003 0.1760 0.0013 18327.5449 12926.7418 1.0001 ⋯\rcp 1.0699 0.1922 0.0014 19583.1899 13534.2405 0.9999 ⋯\rchol -0.0073 0.1641 0.0012 18280.4944 12242.8280 1.0004 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rThank you! And that concludes this little tutorial showcasing the power of a Bayesian model and the fun of using Julia. Thank you for stopping by!\nVictor Flores\n","permalink":"http://localhost:1313/posts/20240109_bayesian-logistic-regression/20240109_bayesian-logistic-regression/","summary":"Applying Turing.jl package in Julia for a probabilistic approach to a classification problem on a real-world dataset.","title":"Bayesian Logistic Regression with Julia and Turing.jl"},{"content":" Finding a Linear Relationship Between Height and Weight Using Bayesian Methods Problem Statement You have some data on the relationship between the height and weight of some people, and you want to fit a linear model of the form:\n$$y = \\alpha + \\beta x + \\varepsilon$$\nwhere $y$ is the weight, $x$ is the height, $\\alpha$ is the intercept, $\\beta$ is the slope, and $\\varepsilon$ is the error term. You want to use Bayesian inference to estimate the posterior distributions of $\\alpha$ and $\\beta$ given the data and some prior assumptions. You also want to use probabilistic programming to implement the Bayesian model and perform inference using a package like Turing.jl.\nYour task is to write the code in Julia that can generate some synthetic data (or use an existing data set), define the Bayesian linear regression model, and sample from the posterior distributions using Hamiltonian Monte Carlo (HMC).\nCredit This exercise is heavily inspired, and mostly taken from, the doggo\u0026rsquo;s tutorial. Please visit his Youtube channel here, it\u0026rsquo;s an amazing starting point for Julia programming!\nImport the Necessary Packages using LinearAlgebra, Turing, CSV, DataFrames, Plots, StatsPlots, LaTeXStrings Bayesian Workflow For this exercise, I will implement the following workflow:\nCollect data: this will be implemented by downloading the relevant data Build a Bayesian model: will use Turing.jl to build the model Infer the posterior distributions of the parameters $\\alpha$ and $\\beta$ Evaluate the fit of the model Collecting the data The data to be analyzed will be the height vs. weight data from: https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset.\nSince the dataset is too large, we will select only the first 1000 entries.\n# collect data # this data set was downloaded from kaggle: # https://www.kaggle.com/datasets/burnoutminer/heights-and-weights-dataset df = CSV.read(joinpath(\u0026#34;data\u0026#34;, \u0026#34;SOCR-HeightWeight.csv\u0026#34;), DataFrame) # select only 100 entries df = df[1:1000, :] first(df, 5) 5×3 DataFrameRowIndexHeight(Inches)Weight(Pounds)Int64Float64Float641165.7833112.9932271.5152136.4873369.3987153.0274468.2166142.3355567.7878144.297\r# change the column headers for easier access colnames = [\u0026#34;index\u0026#34;,\u0026#34;height\u0026#34;,\u0026#34;weight\u0026#34;]; rename!(df, Symbol.(colnames)) first(df, 5) 5×3 DataFrameRowindexheightweightInt64Float64Float641165.7833112.9932271.5152136.4873369.3987153.0274468.2166142.3355567.7878144.297\rVisualizing the Data plot_data = scatter(df.height, df.weight, legend = false, title = \u0026#34;Height vs. Weight\u0026#34;, xlabel = \u0026#34;Height (in)\u0026#34;, ylabel = \u0026#34;Weight (lb)\u0026#34; ) Building a Bayesian model with Turing.jl. First, we assume that the weight is a variable dependent on the height. Thus, we can express the Bayesian model as:\n$$y\\sim N(\\alpha + \\beta^{T}\\mathbf{X}, \\sigma^2)$$\nThe above means that we assume that the data follows a normal distribution (in this case, a multivariate normal distribution), whose standard deviation is σ and its mean is the linear relationship $\\alpha + \\beta^{T}\\mathbf{X}$.\nNext, we need to assign priors to the variables $\\alpha$, $\\beta$ and $\\sigma^2$. The latter is a measure of the uncertainty in the model.\nSo, the priors will be assigned as follows:\n$$\\alpha \\sim N(0,10)$$ $$\\beta \\sim U(0,50)$$ $$\\sigma^{2} \\sim TN(0,100;0,\\infty)$$\nThe last distribution is a truncated normal distribution bounded from 0 to $\\infty$.\n@model function blr(height, weight) # priors: α ~ Normal(0,10) # intercept β ~ Uniform(0,50) σ ~ truncated(Normal(0, 100); lower=0) # variance standard distribution # likelihood # the likelihood in this case means that I assume that the data follows a # multivariate normal distribution, whose uncertainty is σ, and its mean is the linear relationship: avg_weight = α .+ (β.*height) # build the model weight ~ MvNormal(avg_weight, σ) end blr (generic function with 2 methods)\rThe next step is to perform Bayesian inference. Crank up the Bayes!\n# crank up the bayes! model = blr(df.height, df.weight) samples = 1000 chain = sample(model, NUTS(), samples) \u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound initial step size\r\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m ϵ = 9.765625e-5\r\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:11\u001b[39m9m\rChains MCMC chain (1000×15×1 Array{Float64, 3}):\rIterations = 501:1:1500\rNumber of chains = 1\rSamples per chain = 1000\rWall duration = 31.4 seconds\rCompute duration = 31.4 seconds\rparameters = α, β, σ\rinternals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\rSummary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m \u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m \u001b[0m ⋯\rα -34.8414 7.6414 0.4117 344.5155 365.1189 1.0038 ⋯\rβ 2.3859 0.1124 0.0060 345.5269 345.0618 1.0039 ⋯\rσ 10.3030 0.2239 0.0100 509.4680 389.9078 1.0016 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\rα -49.8948 -39.7950 -34.9188 -29.8116 -19.8403\rβ 2.1673 2.3108 2.3872 2.4580 2.6100\rσ 9.8649 10.1550 10.3018 10.4554 10.7449\rVisualizing the MCMC Diagnostics and Summarizing the Results Now that we have performed Bayesian inference using the NUTS() algorithm, we can visualize the results. Addisionally, call for a summary of the statistics of the inferred posterior distributions of $\\theta$.\nsummarize(chain) \u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m \u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m \u001b[0m ⋯\rα -34.8414 7.6414 0.4117 344.5155 365.1189 1.0038 ⋯\rβ 2.3859 0.1124 0.0060 345.5269 345.0618 1.0039 ⋯\rσ 10.3030 0.2239 0.0100 509.4680 389.9078 1.0016 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rplot(chain) Visualizing the results It is worth noting that the results from a Bayesian Linear Regression is not one single regression line, but many. From PyMC\u0026rsquo;s Generalized Linear Regression tutorial:\nIn GLMs, we do not only have one best fitting regression line, but many. A posterior predictive plot takes multiple samples from the posterior (intercepts and slopes) and plots a regression line for each of them. We can manually generate these regression lines using the posterior samples directly.\nWhat this means is that if we want to visualize all the lines that are generated by the parameter posterior distribution sample pool, we need to generate one line per sample set, and then we can plot them all. This procedure is executed next.\n# plot all the sample regressions # this method was taken from: https://www.youtube.com/watch?v=EgrrtZEVOv0\u0026amp;t=1113s for i in 1:samples α = chain[i,1,1] #chain[row, column, chain_ID] β = chain[i,2,1] σ² = chain[i,3,1] plot!(plot_data, x -\u0026gt; α + β*x, legend = false, # samples linewidth = 2, color = :orange, alpha = 0.02, # error ribbon = σ², fillalpha = 0.002 ) end\tplot_data Using the Regression Model to Make Predictions Select the heights for which we want to predict the weights and then run the prediction command from Turing.\npred_height = [62, 84, 75, 70, 71, 67] predictions = predict(blr(pred_height, missing), chain) Chains MCMC chain (1000×6×1 Array{Float64, 3}):\rIterations = 1:1:1000\rNumber of chains = 1\rSamples per chain = 1000\rparameters = weight[1], weight[2], weight[3], weight[4], weight[5], weight[6]\rinternals = Summary Statistics\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m \u001b[1m std \u001b[0m \u001b[1m mcse \u001b[0m \u001b[1m ess_bulk \u001b[0m \u001b[1m ess_tail \u001b[0m \u001b[1m rhat \u001b[0m \u001b[1m\u001b[0m ⋯\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\rweight[1] 113.6815 10.3344 0.3270 997.5393 947.2109 0.9993 ⋯\rweight[2] 165.3164 10.8352 0.3744 832.5405 818.6640 1.0008 ⋯\rweight[3] 143.8911 10.5355 0.3461 929.5467 874.2977 0.9993 ⋯\rweight[4] 132.3417 10.4836 0.3448 921.6347 943.0320 1.0007 ⋯\rweight[5] 134.7606 10.7046 0.3350 1023.8876 977.6814 1.0025 ⋯\rweight[6] 124.9423 10.2245 0.3247 993.9282 867.7391 0.9991 ⋯\r\u001b[36m 1 column omitted\u001b[0m\rQuantiles\r\u001b[1m parameters \u001b[0m \u001b[1m 2.5% \u001b[0m \u001b[1m 25.0% \u001b[0m \u001b[1m 50.0% \u001b[0m \u001b[1m 75.0% \u001b[0m \u001b[1m 97.5% \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\rweight[1] 93.9378 106.3972 113.6943 120.8093 134.9264\rweight[2] 142.4871 158.4933 165.5406 172.7313 184.7437\rweight[3] 122.8292 137.0108 144.0339 151.1920 164.2645\rweight[4] 111.8872 125.3733 132.1726 139.2690 153.7222\rweight[5] 113.9147 127.4356 135.0149 142.1375 154.5537\rweight[6] 105.3221 118.0098 125.1640 131.6011 145.2976\rVisualize the Distributions of the Predicted Weights plot(predictions) Finally, to obtain a point estimate, compute the mean weight prediction for each height.\nmean_predictions = mean(predictions) Mean\r\u001b[1m parameters \u001b[0m \u001b[1m mean \u001b[0m\r\u001b[90m Symbol \u001b[0m \u001b[90m Float64 \u001b[0m\rweight[1] 113.6815\rweight[2] 165.3164\rweight[3] 143.8911\rweight[4] 132.3417\rweight[5] 134.7606\rweight[6] 124.9423\r","permalink":"http://localhost:1313/posts/20231110_bayesian_linear_regression_julia/20231110_bayesian_linear_regression_julia/","summary":"Learn the basics of Bayesian linear regression using Julia and Turing.jl. This tutorial covers model formulation, implementation, and interpretation through a practical example.","title":"Bayesian Linear Regression with Julia and Turing.jl"},{"content":"Hi! I love learning about new stuff and diving into the world of data science and machine learning. I have been exploring Bayesian modeling, Gaussian processes, and deep learning. I\u0026rsquo;m comfortable working with Julia and Python, and in a past life, MATLAB too. I enjoy creating tutorials and sharing what I learn with others. When I\u0026rsquo;m not learning about Bayesian stuff, you\u0026rsquo;ll find me swimming, running, or experimenting with new recipes in the kitchen, probably while listening to some flavor of metal 🤘.\nI\u0026rsquo;m always looking for hands-on collaborations on data science and machine learning projects. Reach out to discuss what we can build together!\n","permalink":"http://localhost:1313/about/","summary":"Hi! I love learning about new stuff and diving into the world of data science and machine learning. I have been exploring Bayesian modeling, Gaussian processes, and deep learning. I\u0026rsquo;m comfortable working with Julia and Python, and in a past life, MATLAB too. I enjoy creating tutorials and sharing what I learn with others. When I\u0026rsquo;m not learning about Bayesian stuff, you\u0026rsquo;ll find me swimming, running, or experimenting with new recipes in the kitchen, probably while listening to some flavor of metal 🤘.","title":"About me"}]