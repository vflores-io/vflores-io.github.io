<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="noindex, nofollow"><title>Bayesian Time Series Analysis with Julia and Turing.jl | Victor Flores</title>
<meta name=keywords content="Bayesian,Bayesian Regression,Time Series,Regression,Turing,Julia"><meta name=description content="This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/><link crossorigin=anonymous href=/assets/css/stylesheet.min.cc305c161bc6ee4c6ba7ee115b6e10dd6be37f10696b436f93d754dee01c7e81.css integrity="sha256-zDBcFhvG7kxrp+4RW24Q3WvjfxBpa0Nvk9dU3uAcfoE=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=alternate hreflang=en href=http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/><meta name=twitter:title content="Bayesian Time Series Analysis with Julia and Turing.jl | Victor Flores"><meta name=twitter:description content="This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning."><meta property="og:title" content="Bayesian Time Series Analysis with Julia and Turing.jl | Victor Flores"><meta property="og:description" content="This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-02T16:57:07+08:00"><meta property="article:modified_time" content="2024-03-02T16:57:07+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Bayesian Time Series Analysis with Julia and Turing.jl","item":"http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Bayesian Time Series Analysis with Julia and Turing.jl | Victor Flores","name":"Bayesian Time Series Analysis with Julia and Turing.jl","description":"This tutorial covers the fundamentals of Bayesian approaches to time series, model construction, and practical implementation, using real-world data for hands-on learning.","keywords":["Bayesian","Bayesian Regression","Time Series","Regression","Turing","Julia"],"wordCount":"1380","inLanguage":"en","datePublished":"2024-03-02T16:57:07+08:00","dateModified":"2024-03-02T16:57:07+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/20240222_bayesian_time_series_analysis/20240222_bayesian_time_series_analysis/"},"publisher":{"@type":"Organization","name":"Victor Flores","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type=text/x-mathjax-config>
        MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true
        }
        });
    </script></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Victor Flores (Alt + H)">Victor Flores</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://localhost:1313/tags/ title=Tags>Tags</a></li><li><a href=http://localhost:1313/archives/ title=Archive>Archive</a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li><li><a href=http://localhost:1313/about/ title=About>About</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><h1 class=post-title>Bayesian Time Series Analysis with Julia and Turing.jl</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>March 2, 2024</span></span><span class=meta-item>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=http://localhost:1313/tags/bayesian/>Bayesian</a><a href=http://localhost:1313/tags/bayesian-regression/>Bayesian Regression</a><a href=http://localhost:1313/tags/time-series/>Time Series</a><a href=http://localhost:1313/tags/regression/>Regression</a><a href=http://localhost:1313/tags/turing/>Turing</a><a href=http://localhost:1313/tags/julia/>Julia</a></span></span></div></header><div class=post-content><hr><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>Â¶</a></h2><p>In this tutorial, an AR(p) (Autoregressive model of order <em>p</em>) is employed to analyze the trneds of a time series and forecast the behavior of the signal.</p><p>Auto-regressive models are based on the assumption the behavior of a time series or signal depends on past values. The order of the AR model tells &ldquo;how far back&rdquo; the past values will affect the current value.</p><h4 id=credits>Credits<a hidden class=anchor aria-hidden=true href=#credits>Â¶</a></h4><p>This exercise is mostly following <a href="https://youtu.be/vfTYCm_Fr8I?si=D3Grgk82tV_Qzdxw">this tutorial</a>.</p><h3 id=definition>Definition<a hidden class=anchor aria-hidden=true href=#definition>Â¶</a></h3><p>The <em>AR(p)</em> model is defined as:</p><p>$$
X_t = \sum_{i=1}^{p} \phi_i X_{t-i} + \varepsilon_t
$$</p><p>where $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ is the model uncertainty represented as white Gaussian noise, i.e. it follows a normal distribution of mean $\mu=0$ and standard deviation $\sigma$.</p><p>It follows that an <em>AR(2)</em> model is defined as:</p><p>$$
X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \varepsilon_t
$$</p><p>Naturally, we want to find the parameters $\theta={\phi_1, \phi_2,\sigma}$. Since these are unobserved quantities of interest, we need to use an inference method to reveal these parameters. We will use Bayesian inference to achieve this goal.</p><h2 id=data-exploration>Data Exploration<a hidden class=anchor aria-hidden=true href=#data-exploration>Â¶</a></h2><p>For this example, I will generate artificial data. This will be done by first defining some values for the parameters $\theta$ and then we will generate random data using those parameters by initializing the $X_1, X_2$ values, and then applying the AR(2) equation to generate the subsequent values.</p><p>First, we import the relevant packages.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=k>using</span> <span class=n>StatsPlots</span><span class=p>,</span> <span class=n>Turing</span><span class=p>,</span> <span class=n>LaTeXStrings</span><span class=p>,</span> <span class=n>Random</span><span class=p>,</span> <span class=n>DataFrames</span>
</span></span><span class=line><span class=cl><span class=n>Random</span><span class=o>.</span><span class=n>seed!</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>TaskLocalRNG()
</code></pre><p>Now we create some artificial data. The steps involved in this are as follows:</p><ol><li>Define some values for the parameters $\theta$</li><li>Set the number of timesteps <em>t</em></li><li>Initialize an empty vector of size $\mathbb{R}^{t+p}$</li><li>Initialize the first two $X$ values with randomly generated numbers using <code>rand</code></li><li>Populate the vector by using the equation for $X_t$</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=c># define true values for Î¸</span>
</span></span><span class=line><span class=cl><span class=n>true_phi_1</span> <span class=o>=</span> <span class=o>-</span><span class=mf>0.4</span>
</span></span><span class=line><span class=cl><span class=n>true_phi_2</span> <span class=o>=</span> <span class=mf>0.3</span>
</span></span><span class=line><span class=cl><span class=n>true_sigma</span> <span class=o>=</span> <span class=mf>0.12</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># define the time steps</span>
</span></span><span class=line><span class=cl><span class=n>time</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl><span class=c># create an empty X vector</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=kt>Vector</span><span class=p>{</span><span class=kt>Float64</span><span class=p>}(</span><span class=nb>undef</span><span class=p>,</span> <span class=n>time</span><span class=o>+</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># initialize the X vector with two random values at time steps 1 and 2</span>
</span></span><span class=line><span class=cl><span class=c># to do this, use a random normally distributed number with mean zero and standard deviation Ïƒ, i.e., Îµ~N(0, Ïƒ)</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>true_sigma</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>true_sigma</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># populate vector X</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>t</span> <span class=k>in</span> <span class=mi>3</span><span class=o>:</span><span class=p>(</span><span class=n>time</span><span class=o>+</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>X</span><span class=p>[</span><span class=n>t</span><span class=p>]</span> <span class=o>=</span> <span class=n>true_phi_1</span><span class=o>*</span><span class=n>X</span><span class=p>[</span><span class=n>t</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>	<span class=n>true_phi_2</span><span class=o>*</span><span class=n>X</span><span class=p>[</span><span class=n>t</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>	<span class=n>rand</span><span class=p>(</span><span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>true_sigma</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=k>end</span>	
</span></span></code></pre></div><h3 id=visualize-the-artificial-data>Visualize the (Artificial) Data<a hidden class=anchor aria-hidden=true href=#visualize-the-artificial-data>Â¶</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>p_data</span> <span class=o>=</span> <span class=n>plot</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=mi>3</span><span class=o>:</span><span class=k>end</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>legend</span> <span class=o>=</span> <span class=nb>false</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>linewidth</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c># xlims = (0, 60),</span>
</span></span><span class=line><span class=cl>    <span class=c># ylims = (-0.6, 0.6),</span>
</span></span><span class=line><span class=cl>    <span class=n>title</span> <span class=o>=</span> <span class=s>&#34;Bayesian Autoregressive AR(2) Model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>xlabel</span> <span class=o>=</span> <span class=sa>L</span><span class=s>&#34;t&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>ylabel</span> <span class=o>=</span> <span class=sa>L</span><span class=s>&#34;X_t&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>widen</span> <span class=o>=</span> <span class=nb>true</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=/images/20240222_Bayesian_Time_Series_Analysis/output_5_0.svg type alt=svg></p><h2 id=modeling>Modeling<a hidden class=anchor aria-hidden=true href=#modeling>Â¶</a></h2><p>The next step is to construct our probabilistic model. Again, the goal here is to infer the values of the model parameters $\theta$. Once we have inferred these parameters, we can make probabilistic predictions on the future behavior of the signal $X$.</p><h3 id=bayesian-model>Bayesian model<a hidden class=anchor aria-hidden=true href=#bayesian-model>Â¶</a></h3><p>Since we are using a Bayesian approach, our goal, in Bayesian terms, is to find the <em>posterior distribution</em> of the parameters $\theta$, given a prior distribution, or prior knowledge, of the parameters before making any observations, i.e., seeing any data, and also a likelihood function, which reflects what kind of distribution (we assume) that the data is sourced from. Another way of understanding the likelihood function is the probability of making a set of observations $X$ given the parameters $\theta$.</p><p>This relationship is established by Bayes&rsquo; Theorem:</p><p>$$
P(\theta | X) \propto P(X | \theta)P(\theta)
$$</p><p>In summary, constructing the Bayesian model in this case comprises a selection of prior distributions for our unknown parameters $\theta$ and a likelihood function. We will do this using the <code>Turing.jl</code> package.</p><p>The model therefore will consist of the prior distributions:</p><p>$$
\begin{align*}
\phi_1 & \sim \mathcal{N}(0, 1) \
\phi_2 & \sim \mathcal{N}(0, 1) \
\sigma & \sim \text{Exp}(1)
\end{align*}
$$</p><p>And the likelihood:</p><p>$$
X_t \sim \mathcal{N}(\mu_t, \sigma)
$$</p><p>where $\mu_t = \sum_{i=1}^{p} \phi_i X_{t-i}$ is the mean function of the distribution that governs X_t.</p><h4 id=a-comment-on-the-choice-of-priors>A comment on the choice of priors<a hidden class=anchor aria-hidden=true href=#a-comment-on-the-choice-of-priors>Â¶</a></h4><p>For autoregressive parameters, using a normal distribution is a common choice. This is because the normal distribution is convenient and allows for a range of plausible values.</p><p>For the prior on the model uncertainty, the exponential distribution is sometimes used for non-negative parameters and has a similar role to the inverse gamma.</p><p>Furthermore, the inverse gamma distribution is often chosen as a prior for the standard deviation because it is conjugate to the normal likelihood. This means that the posterior distribution will have a known form, making computations more tractable.</p><h3 id=bayesian-model-using-turingjl>Bayesian model using <code>Turing.jl</code><a hidden class=anchor aria-hidden=true href=#bayesian-model-using-turingjl>Â¶</a></h3><p>Now we proceed to set up the model using the <code>Turing.jl</code> package.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=nd>@model</span> <span class=k>function</span> <span class=n>ar</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>time</span><span class=p>)</span>    <span class=c># pass the data X and the time vector</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=c># priors</span>
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		<span class=n>phi_1</span> <span class=o>~</span> <span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>phi_2</span> <span class=o>~</span> <span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>sigma</span> <span class=o>~</span> <span class=n>Exponential</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=c># likelihood</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=c># initialize with random initial values</span>
</span></span><span class=line><span class=cl>		<span class=n>X</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>~</span> <span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>sigma</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>X</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>~</span> <span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>sigma</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=c># populate with samples</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=n>i</span> <span class=k>in</span> <span class=mi>3</span><span class=o>:</span><span class=p>(</span><span class=n>time</span><span class=o>+</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>mu</span> <span class=o>=</span> <span class=n>phi_1</span><span class=o>*</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>phi_2</span><span class=o>*</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>			<span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>~</span> <span class=n>Normal</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>end</span>
</span></span><span class=line><span class=cl>	<span class=k>end</span>
</span></span></code></pre></div><pre><code>ar (generic function with 2 methods)
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>ar</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>time</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sampler</span> <span class=o>=</span> <span class=n>NUTS</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>samples</span> <span class=o>=</span> <span class=mi>1_000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>sample</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>sampler</span><span class=p>,</span> <span class=n>samples</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>[36m[1mâ”Œ [22m[39m[36m[1mInfo: [22m[39mFound initial step size
[36m[1mâ”” [22m[39m  Ïµ = 0.4
[32mSampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[39m





Chains MCMC chain (1000Ã—15Ã—1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 11.59 seconds
Compute duration  = 11.59 seconds
parameters        = phi_1, phi_2, sigma
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m â‹¯
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m â‹¯

       phi_1   -0.3830    0.1047    0.0036   836.6151   762.4445    0.9996     â‹¯
       phi_2    0.1587    0.1012    0.0035   838.3014   749.6718    1.0002     â‹¯
       sigma    0.1083    0.0079    0.0003   755.4034   743.3822    1.0014     â‹¯
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

       phi_1   -0.5733   -0.4562   -0.3858   -0.3141   -0.1771
       phi_2   -0.0339    0.0913    0.1562    0.2256    0.3549
       sigma    0.0943    0.1030    0.1079    0.1130    0.1257
</code></pre><h3 id=visualize-and-summarize-the-results>Visualize and Summarize the Results<a hidden class=anchor aria-hidden=true href=#visualize-and-summarize-the-results>Â¶</a></h3><p>Next we can access the MCMC Diagnostics and generate a summary of the results.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>plot</span><span class=p>(</span><span class=n>chain</span><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=/images/20240222_Bayesian_Time_Series_Analysis/output_10_0.svg type alt=svg></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>DataFrame</span><span class=p>(</span><span class=n>summarystats</span><span class=p>(</span><span class=n>chain</span><span class=p>))</span>
</span></span></code></pre></div><div><div style=float:left><span>3Ã—8 DataFrame</span></div><div style=clear:both></div></div><div class=data-frame style=overflow-x:scroll><table class=data-frame style=margin-bottom:6px><thead><tr class=header><th class=rowNumber style=font-weight:700;text-align:right>Row</th><th style=text-align:left>parameters</th><th style=text-align:left>mean</th><th style=text-align:left>std</th><th style=text-align:left>mcse</th><th style=text-align:left>ess_bulk</th><th style=text-align:left>ess_tail</th><th style=text-align:left>rhat</th><th style=text-align:left>ess_per_sec</th></tr><tr class="subheader headerLastRow"><th class=rowNumber style=font-weight:700;text-align:right></th><th title=Symbol style=text-align:left>Symbol</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th><th title=Float64 style=text-align:left>Float64</th></tr></thead><tbody><tr><td class=rowNumber style=font-weight:700;text-align:right>1</td><td style=text-align:left>phi_1</td><td style=text-align:right>-0.383019</td><td style=text-align:right>0.104695</td><td style=text-align:right>0.00361324</td><td style=text-align:right>836.615</td><td style=text-align:right>762.444</td><td style=text-align:right>0.999585</td><td style=text-align:right>72.1655</td></tr><tr><td class=rowNumber style=font-weight:700;text-align:right>2</td><td style=text-align:left>phi_2</td><td style=text-align:right>0.158661</td><td style=text-align:right>0.101196</td><td style=text-align:right>0.00351463</td><td style=text-align:right>838.301</td><td style=text-align:right>749.672</td><td style=text-align:right>1.00021</td><td style=text-align:right>72.311</td></tr><tr><td class=rowNumber style=font-weight:700;text-align:right>3</td><td style=text-align:left>sigma</td><td style=text-align:right>0.108342</td><td style=text-align:right>0.00788622</td><td style=text-align:right>0.000291067</td><td style=text-align:right>755.403</td><td style=text-align:right>743.382</td><td style=text-align:right>1.00145</td><td style=text-align:right>65.1603</td></tr></tbody></table></div><h2 id=predictions>Predictions<a hidden class=anchor aria-hidden=true href=#predictions>Â¶</a></h2><h3 id=making-predictions>Making Predictions<a hidden class=anchor aria-hidden=true href=#making-predictions>Â¶</a></h3><p>To make predictions, the following steps are taken:</p><ol><li>Set the number of time steps into the future, $t_f$</li><li>Initialize an empty matrix for the forecasted $X$ values - This will be a matrix because it will be a collection of vectors. Each vector will represent one sample forecast</li><li>Initialize two steps of each of the sample vectors to be generated - In practical terms, initialize the first number of each column; each <em>column</em> will represent a forecast time series</li></ol><p>Keep in mind that what will be done here is to create samples of the future behavior of the signal $t_f$ number of time steps into the future. To do this, we will generate signals that use the posterior distributions of the parameters $\theta$ by calling the function <code>rand(chain[:,Z,Z])</code> which will randomly pick a number out of the sample pool, effectively &ldquo;sampling&rdquo; from that posterior distribution (sample pool).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>time_future</span> <span class=o>=</span> <span class=mi>15</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_future</span> <span class=o>=</span> <span class=kt>Matrix</span><span class=p>{</span><span class=kt>Float64</span><span class=p>}(</span><span class=nb>undef</span><span class=p>,</span> <span class=n>time_future</span><span class=o>+</span><span class=mi>2</span><span class=p>,</span> <span class=n>samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># Initialize the first two time steps for every forecast</span>
</span></span><span class=line><span class=cl><span class=n>X_future</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=o>:</span><span class=p>]</span> <span class=o>.=</span> <span class=n>X</span><span class=p>[</span><span class=n>time</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>X_future</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=o>:</span><span class=p>]</span> <span class=o>.=</span> <span class=n>X</span><span class=p>[</span><span class=n>time</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># populate the forecast vectors by sampling from the posterior sample pool of the parameters Î¸</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>col</span> <span class=k>in</span> <span class=mi>1</span><span class=o>:</span><span class=n>samples</span>
</span></span><span class=line><span class=cl>	<span class=n>phi_1_future</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>chain</span><span class=p>[</span><span class=o>:</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>	<span class=n>phi_2_future</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>chain</span><span class=p>[</span><span class=o>:</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>	<span class=n>error_future</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>chain</span><span class=p>[</span><span class=o>:</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>	<span class=n>noise_future</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>Normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>error_future</span><span class=p>))</span>
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>row</span> <span class=k>in</span> <span class=mi>3</span><span class=o>:</span><span class=p>(</span><span class=n>time_future</span><span class=o>+</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>X_future</span><span class=p>[</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>]</span> <span class=o>=</span> 
</span></span><span class=line><span class=cl>			<span class=n>phi_1_future</span> <span class=o>*</span> <span class=n>X_future</span><span class=p>[</span><span class=n>row</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>col</span><span class=p>]</span> <span class=o>+</span> 
</span></span><span class=line><span class=cl>			<span class=n>phi_2_future</span> <span class=o>*</span> <span class=n>X_future</span><span class=p>[</span><span class=n>row</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=n>col</span><span class=p>]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>			<span class=n>noise_future</span>
</span></span><span class=line><span class=cl>	<span class=k>end</span>
</span></span><span class=line><span class=cl><span class=k>end</span>
</span></span></code></pre></div><h4 id=visualize-the-forecast>Visualize the forecast<a hidden class=anchor aria-hidden=true href=#visualize-the-forecast>Â¶</a></h4><p>Now that we <em>propagated the uncertainty</em> of in the posterior distribution of the parameters $\theta$, we can plot the posterior predictive distribution of $X$, $P(X^*|\theta)$.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia><span class=line><span class=cl><span class=n>time_predict</span> <span class=o>=</span> <span class=n>time</span><span class=o>:</span><span class=p>(</span><span class=n>time</span> <span class=o>+</span> <span class=n>time_future</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=k>in</span> <span class=mi>1</span><span class=o>:</span><span class=n>samples</span>
</span></span><span class=line><span class=cl>	<span class=n>plot!</span><span class=p>(</span><span class=n>p_data</span><span class=p>,</span> <span class=n>time_predict</span><span class=p>,</span> <span class=n>X_future</span><span class=p>[</span><span class=mi>2</span><span class=o>:</span><span class=k>end</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=n>legend</span> <span class=o>=</span> <span class=nb>false</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=c># predictions</span>
</span></span><span class=line><span class=cl>	<span class=n>linewidth</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span> <span class=n>color</span> <span class=o>=</span> <span class=ss>:green</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.1</span>
</span></span><span class=line><span class=cl>	<span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>end</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>p_data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># visualize mean values for predictions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_future_mean</span> <span class=o>=</span> <span class=p>[</span><span class=n>mean</span><span class=p>(</span><span class=n>X_future</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>1</span><span class=o>:</span><span class=n>samples</span><span class=p>])</span> <span class=k>for</span> <span class=n>i</span> <span class=k>in</span> <span class=mi>2</span><span class=o>:</span><span class=p>(</span><span class=n>time_future</span><span class=o>+</span><span class=mi>2</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot!</span><span class=p>(</span><span class=n>p_data</span><span class=p>,</span> <span class=n>time_predict</span><span class=p>,</span> <span class=n>X_future_mean</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>	<span class=n>legend</span> <span class=o>=</span> <span class=nb>false</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=n>linewidth</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>	<span class=n>color</span> <span class=o>=</span> <span class=ss>:red</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>	<span class=n>linestyle</span> <span class=o>=</span> <span class=ss>:dot</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=/images/20240222_Bayesian_Time_Series_Analysis/output_15_0.svg type alt=svg></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-julia data-lang=julia></code></pre></div></div><footer class=post-footer><nav class=paginav><a class=prev href=http://localhost:1313/posts/20240509_election_dash_part_2-dashboard/20240509_election_dash_part_2-dashboard/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>Election Data Dashboard Pt. 2: Dashboard with Dash</span>
</a><a class=next href=http://localhost:1313/posts/20240217_bayesian_poisson_regression/20240217_bayesian_poisson_regression/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>Bayesian Poisson Regression with Julia and Turing.jl</span></a></nav></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Victor Flores</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span><span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script><script>(function(){const a=""=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>